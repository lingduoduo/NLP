{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test10 = pd.read_csv('test10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>details_search_value</th>\n",
       "      <th>caption</th>\n",
       "      <th>finalScore</th>\n",
       "      <th>resPos</th>\n",
       "      <th>max_score</th>\n",
       "      <th>scaled_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benefits implementation</td>\n",
       "      <td>Manage Benefits Supplemental Fields</td>\n",
       "      <td>426.125743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.125743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My upcoming holidays</td>\n",
       "      <td>View Time Reports</td>\n",
       "      <td>29.706916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.707098</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import compensation</td>\n",
       "      <td>View Your Compensation</td>\n",
       "      <td>670.469531</td>\n",
       "      <td>2.0</td>\n",
       "      <td>670.469531</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manage company time  o</td>\n",
       "      <td>Manage Your Company's Compensation</td>\n",
       "      <td>335.970555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.970555</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My upcoming holidays</td>\n",
       "      <td>View and Manage Benefits</td>\n",
       "      <td>35.105762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.105762</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I really want to pr</td>\n",
       "      <td>Manage Associates' Pay Data</td>\n",
       "      <td>30.853407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.853407</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>View People Movements</td>\n",
       "      <td>Configure Movement Reasons</td>\n",
       "      <td>577.311203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>577.391877</td>\n",
       "      <td>0.999860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>employment verification</td>\n",
       "      <td>Import Legacy System Data</td>\n",
       "      <td>227.350976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.350976</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>View People Movements</td>\n",
       "      <td>View People Movements</td>\n",
       "      <td>1225.654355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1225.806040</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>associate directory</td>\n",
       "      <td>Export Associate Details</td>\n",
       "      <td>420.549146</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.938029</td>\n",
       "      <td>0.999076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       details_search_value                              caption   finalScore  \\\n",
       "0   benefits implementation  Manage Benefits Supplemental Fields   426.125743   \n",
       "1      My upcoming holidays                    View Time Reports    29.706916   \n",
       "2       import compensation               View Your Compensation   670.469531   \n",
       "3    manage company time  o   Manage Your Company's Compensation   335.970555   \n",
       "4      My upcoming holidays             View and Manage Benefits    35.105762   \n",
       "..                      ...                                  ...          ...   \n",
       "95      I really want to pr          Manage Associates' Pay Data    30.853407   \n",
       "96    View People Movements           Configure Movement Reasons   577.311203   \n",
       "97  employment verification            Import Legacy System Data   227.350976   \n",
       "98    View People Movements                View People Movements  1225.654355   \n",
       "99      associate directory             Export Associate Details   420.549146   \n",
       "\n",
       "    resPos    max_score  scaled_score  \n",
       "0      1.0   426.125743      1.000000  \n",
       "1      2.0    29.707098      0.999994  \n",
       "2      2.0   670.469531      1.000000  \n",
       "3      1.0   335.970555      1.000000  \n",
       "4      1.0    35.105762      1.000000  \n",
       "..     ...          ...           ...  \n",
       "95     2.0    30.853407      1.000000  \n",
       "96     1.0   577.391877      0.999860  \n",
       "97     0.0   227.350976      1.000000  \n",
       "98     0.0  1225.806040      0.999876  \n",
       "99     2.0   420.938029      0.999076  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import numpy as np\n",
    "from typing import List, Literal, Optional\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers.evaluation import SentenceEvaluator, SimilarityFunction\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Custom_EmbeddingSimilarityEvaluator(SentenceEvaluator):\n",
    "    \"\"\"\n",
    "    Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation\n",
    "    in comparison to the gold standard labels.\n",
    "    The metrics are the cosine similarity as well as euclidean and Manhattan distance.\n",
    "    The returned score is the Spearman correlation with a specified metric.\n",
    "\n",
    "    The results are written in a CSV. If a CSV already exists, then values are appended.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentences1: List[str],\n",
    "        sentences2: List[str],\n",
    "        scores: List[float],\n",
    "        batch_size: int = 16,\n",
    "        main_similarity: SimilarityFunction = SimilarityFunction.COSINE,\n",
    "        name: str = \"\",\n",
    "        show_progress_bar: bool = False,\n",
    "        write_csv: bool = True,\n",
    "        precision: Optional[Literal[\"float32\", \"int8\", \"uint8\", \"binary\", \"ubinary\"]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructs an evaluator for the dataset.\n",
    "\n",
    "        The labels need to indicate the similarity between the sentences.\n",
    "\n",
    "        :param sentences1:  List with the first sentence in a pair\n",
    "        :param sentences2: List with the second sentence in a pair\n",
    "        :param scores: Similarity score between sentences1[i] and sentences2[i]\n",
    "        :param write_csv: Write results to a CSV file\n",
    "        :param precision: The precision to use for the embeddings. Can be \"float32\", \"int8\", \"uint8\", \"binary\", or\n",
    "            \"ubinary\". Defaults to None.\n",
    "        \"\"\"\n",
    "        self.sentences1 = sentences1\n",
    "        self.sentences2 = sentences2\n",
    "        self.scores = scores\n",
    "        self.write_csv = write_csv\n",
    "        self.precision = precision\n",
    "\n",
    "        assert len(self.sentences1) == len(self.sentences2)\n",
    "        assert len(self.sentences1) == len(self.scores)\n",
    "\n",
    "        self.main_similarity = main_similarity\n",
    "        self.name = name\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        if show_progress_bar is None:\n",
    "            show_progress_bar = (\n",
    "                logger.getEffectiveLevel() == logging.INFO or logger.getEffectiveLevel() == logging.DEBUG\n",
    "            )\n",
    "        self.show_progress_bar = show_progress_bar\n",
    "\n",
    "        self.csv_file = (\n",
    "            \"similarity_evaluation\"\n",
    "            + (\"_\" + name if name else \"\")\n",
    "            + (\"_\" + precision if precision else \"\")\n",
    "            + \"_results.csv\"\n",
    "        )\n",
    "        self.csv_headers = [\n",
    "            \"epoch\",\n",
    "            \"steps\",\n",
    "            \"cosine_pearson\",\n",
    "            \"cosine_spearman\",\n",
    "            \"euclidean_pearson\",\n",
    "            \"euclidean_spearman\",\n",
    "            \"manhattan_pearson\",\n",
    "            \"manhattan_spearman\",\n",
    "            \"dot_pearson\",\n",
    "            \"dot_spearman\",\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def from_input_examples(cls, examples: List[InputExample], **kwargs):\n",
    "        sentences1 = []\n",
    "        sentences2 = []\n",
    "        scores = []\n",
    "\n",
    "        for example in examples:\n",
    "            sentences1.append(example.texts[0])\n",
    "            sentences2.append(example.texts[1])\n",
    "            scores.append(example.label)\n",
    "        return cls(sentences1, sentences2, scores, **kwargs)\n",
    "\n",
    "    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
    "        if epoch != -1:\n",
    "            if steps == -1:\n",
    "                out_txt = \" after epoch {}:\".format(epoch)\n",
    "            else:\n",
    "                out_txt = \" in epoch {} after {} steps:\".format(epoch, steps)\n",
    "        else:\n",
    "            out_txt = \":\"\n",
    "\n",
    "        logger.info(\"EmbeddingSimilarityEvaluator: Evaluating the model on \" + self.name + \" dataset\" + out_txt)\n",
    "\n",
    "        embeddings1 = model.encode(\n",
    "            self.sentences1,\n",
    "            batch_size=self.batch_size,\n",
    "            show_progress_bar=self.show_progress_bar,\n",
    "            convert_to_numpy=True,\n",
    "            precision=self.precision,\n",
    "            normalize_embeddings=bool(self.precision),\n",
    "        )\n",
    "        embeddings2 = model.encode(\n",
    "            self.sentences2,\n",
    "            batch_size=self.batch_size,\n",
    "            show_progress_bar=self.show_progress_bar,\n",
    "            convert_to_numpy=True,\n",
    "            precision=self.precision,\n",
    "            normalize_embeddings=bool(self.precision),\n",
    "        )\n",
    "        # Binary and ubinary embeddings are packed, so we need to unpack them for the distance metrics\n",
    "        if self.precision == \"binary\":\n",
    "            embeddings1 = (embeddings1 + 128).astype(np.uint8)\n",
    "            embeddings2 = (embeddings2 + 128).astype(np.uint8)\n",
    "        if self.precision in (\"ubinary\", \"binary\"):\n",
    "            embeddings1 = np.unpackbits(embeddings1, axis=1)\n",
    "            embeddings2 = np.unpackbits(embeddings2, axis=1)\n",
    "\n",
    "        labels = self.scores\n",
    "\n",
    "        cosine_scores = 1 - (paired_cosine_distances(embeddings1, embeddings2))\n",
    "        manhattan_distances = -paired_manhattan_distances(embeddings1, embeddings2)\n",
    "        euclidean_distances = -paired_euclidean_distances(embeddings1, embeddings2)\n",
    "        dot_products = [np.dot(emb1, emb2) for emb1, emb2 in zip(embeddings1, embeddings2)]\n",
    "\n",
    "        eval_pearson_cosine, _ = pearsonr(labels, cosine_scores)\n",
    "        eval_spearman_cosine, _ = spearmanr(labels, cosine_scores)\n",
    "\n",
    "        eval_pearson_manhattan, _ = pearsonr(labels, manhattan_distances)\n",
    "        eval_spearman_manhattan, _ = spearmanr(labels, manhattan_distances)\n",
    "\n",
    "        eval_pearson_euclidean, _ = pearsonr(labels, euclidean_distances)\n",
    "        eval_spearman_euclidean, _ = spearmanr(labels, euclidean_distances)\n",
    "\n",
    "        eval_pearson_dot, _ = pearsonr(labels, dot_products)\n",
    "        eval_spearman_dot, _ = spearmanr(labels, dot_products)\n",
    "\n",
    "        if output_path is not None and self.write_csv:\n",
    "            csv_path = os.path.join(output_path, self.csv_file)\n",
    "            output_file_exists = os.path.isfile(csv_path)\n",
    "            with open(csv_path, newline=\"\", mode=\"a\" if output_file_exists else \"w\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                if not output_file_exists:\n",
    "                    writer.writerow(self.csv_headers)\n",
    "\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        epoch,\n",
    "                        steps,\n",
    "                        eval_pearson_cosine,\n",
    "                        eval_spearman_cosine,\n",
    "                        eval_pearson_euclidean,\n",
    "                        eval_spearman_euclidean,\n",
    "                        eval_pearson_manhattan,\n",
    "                        eval_spearman_manhattan,\n",
    "                        eval_pearson_dot,\n",
    "                        eval_spearman_dot,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        # Return a dictionary of the evaluation metrics\n",
    "        metrics = {\n",
    "            \"pearson_cosine\": eval_pearson_cosine, \"spearman_cosine\": eval_spearman_cosine,\n",
    "            \"pearson_manhattan\": eval_pearson_manhattan, \"spearman_manhattan\": eval_spearman_manhattan,\n",
    "            \"pearson_euclidean\": eval_pearson_euclidean, \"spearman_euclidean\": eval_spearman_euclidean,\n",
    "            \"pearson_dot\": eval_pearson_dot, \"spearman_dot\": eval_spearman_dot,\n",
    "            \"pearson_max\": max(eval_pearson_cosine, eval_pearson_manhattan, eval_pearson_euclidean, eval_pearson_dot),\n",
    "            \"spearman_max\": max(eval_spearman_cosine, eval_spearman_manhattan, eval_spearman_euclidean, eval_spearman_dot),\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7489894361340346,\n",
       " 'spearman_cosine': 0.6689952849071136,\n",
       " 'pearson_manhattan': 0.751459994600592,\n",
       " 'spearman_manhattan': 0.650750362208899,\n",
       " 'pearson_euclidean': 0.7529103789439922,\n",
       " 'spearman_euclidean': 0.6500901832914233,\n",
       " 'pearson_dot': 0.790715130140925,\n",
       " 'spearman_dot': 0.6625335797756161,\n",
       " 'pearson_max': 0.790715130140925,\n",
       " 'spearman_max': 0.6689952849071136}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-minilm-l12-v2\")\n",
    "dev_evaluator = Custom_EmbeddingSimilarityEvaluator(\n",
    "    sentences1=test10[\"details_search_value\"],\n",
    "    sentences2=test10[\"caption\"],\n",
    "    scores=test10[\"finalScore\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"test10\",\n",
    ")\n",
    "dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
