{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ L1 - Semantic Kernel is like\u000b\n",
    "your AI cooking kitchen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¥ Get a kernel ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'semantic_kernel' has no attribute 'openai_settings_from_dot_env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     kernel\u001b[38;5;241m.\u001b[39madd_text_completion_service(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazureopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m, AzureChatCompletion(deployment, endpoint, api_key))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     api_key, org_id \u001b[38;5;241m=\u001b[39m \u001b[43msk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenai_settings_from_dot_env\u001b[49m()\n\u001b[1;32m     13\u001b[0m     kernel\u001b[38;5;241m.\u001b[39madd_text_completion_service(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenAIChatCompletion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-0301\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key, org_id))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou made a kernel!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'semantic_kernel' has no attribute 'openai_settings_from_dot_env'"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenai\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "\n",
    "print(\"You made a kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Kernel' object has no attribute 'add_text_completion_service'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msemantic_kernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhugging_face\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceTextCompletion\n\u001b[1;32m      4\u001b[0m kernel \u001b[38;5;241m=\u001b[39m sk\u001b[38;5;241m.\u001b[39mKernel()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_text_completion_service\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuggingface\u001b[39m\u001b[38;5;124m\"\u001b[39m, HuggingFaceTextCompletion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou made an open source kernel using an open source AI model!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.11/site-packages/pydantic/main.py:767\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Kernel' object has no attribute 'add_text_completion_service'"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "kernel.add_text_completion_service(\"huggingface\", HuggingFaceTextCompletion(\"gpt2\", task=\"text-generation\"))\n",
    "\n",
    "print(\"You made an open source kernel using an open source AI model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”– Reminder: A kernel is like the stove in a kitchen. It doesn't do anything unless you start to cook with it. Let's proceed to get it a few functions to ðŸ”¥ cook up for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, AzureChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_id=\"chat-gpt-3.5\"\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-3.5-turbo\",\n",
    "        api_key=api_key\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request settings\n",
    "req_settings = kernel.get_prompt_execution_settings_from_service_id(service_id)\n",
    "req_settings.max_tokens = 2000\n",
    "req_settings.temperature = 0.7\n",
    "req_settings.top_p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'semantic_kernel' has no attribute 'PromptTemplateConfig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m1) A robot may not injure a human being or, through inaction,\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mallow a human being to come to harm.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mGive me the TLDR in exactly 5 words.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m prompt_template_config \u001b[38;5;241m=\u001b[39m \u001b[43msk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPromptTemplateConfig\u001b[49m(\n\u001b[1;32m     14\u001b[0m     template\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     15\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtldr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     template_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemantic-kernel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     execution_settings\u001b[38;5;241m=\u001b[39mreq_settings,\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'semantic_kernel' has no attribute 'PromptTemplateConfig'"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "1) A robot may not injure a human being or, through inaction,\n",
    "allow a human being to come to harm.\n",
    "\n",
    "2) A robot must obey orders given it by human beings except where\n",
    "such orders would conflict with the First Law.\n",
    "\n",
    "3) A robot must protect its own existence as long as such protection\n",
    "does not conflict with the First or Second Law.\n",
    "\n",
    "Give me the TLDR in exactly 5 words.\"\"\"\n",
    "\n",
    "prompt_template_config = sk.PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"tldr\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    execution_settings=req_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
