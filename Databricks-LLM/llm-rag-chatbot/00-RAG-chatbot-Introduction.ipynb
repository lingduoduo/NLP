{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83b7289b-dd9e-4aa9-a319-2a75ddfafd53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Scaling your business with a GenAI-Powered Assistant\n",
    "\n",
    "LLMs are disrupting the way we interact with information, from internal knowledge bases to external, customer-facing documentation or support.\n",
    " \n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/moisaic-logo.png?raw=true\" width=\"100px\" style=\"float: right\" />\n",
    "\n",
    "While ChatGPT democratized LLM-based chatbots for consumer use, companies need to deploy personalized models that answer their needs:\n",
    "\n",
    "- Privacy requirements on sensitive information\n",
    "- Preventing hallucination\n",
    "- Specialized content, not available on the Internet\n",
    "- Specific behavior for customer tasks\n",
    "- Control over speed and cost\n",
    "- Deploy models on private infrastructure for security reasons\n",
    "\n",
    "## Introducing Databricks AI\n",
    "\n",
    "To solve these challenges, custom knowledge bases and models need to be deployed. However, doing so at scale isn't simple and requires:\n",
    "\n",
    "- Ingesting and transforming massive amounts of data \n",
    "- Ensuring privacy and security across your data pipeline\n",
    "- Deploying systems such as Vector Search Index \n",
    "- Having access to GPUs and deploying efficient LLMs for inference serving\n",
    "- Training and deploying custom models\n",
    "\n",
    "This is where the Databricks  AI comes in. Databricks simplifies all these steps so that you can focus on building your final model, with the best prompts and performance.\n",
    "\n",
    "\n",
    "## GenAI & Maturity curve\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-maturity.png?raw=true\" width=\"600px\" style=\"float:right\"/>\n",
    "\n",
    "Deploying GenAI can be done in multiple ways:\n",
    "\n",
    "- **Prompt engineering on public APIs (e.g. LLama 2, openAI)**: answer from public information, retail (think ChatGPT)\n",
    "- **Retrieval Augmented Generation (RAG)**: specialize your model with additional content. *This is what we'll focus on in this demo*\n",
    "- **OSS model Fine tuning**: when you have a large corpus of custom data and need specific model behavior (execute a task)\n",
    "- **Train your own LLM**: for full control on the underlying data sources of the model (biomedical, Code, Finance...)\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=local&notebook=%2F00-RAG-chatbot-Introduction&demo_name=llm-rag-chatbot&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fllm-rag-chatbot%2F00-RAG-chatbot-Introduction&version=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c802e2cf-d7b6-4318-b88b-1db5d2c10b05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## What is Retrieval Augmented Generation (RAG) for LLMs?\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-marchitecture.png?raw=true\" width=\"700px\" style=\"float: right\" />\n",
    "\n",
    "RAG is a powerful and efficient GenAI technique that allows you to improve model performance by leveraging your own data (e.g., documentation specific to your business), without the need to fine-tune the model.\n",
    "\n",
    "This is done by providing your custom information as context to the LLM. This reduces hallucination and allows the LLM to produce results that provide company-specific data, without making any changes to the original LLM.\n",
    "\n",
    "RAG has shown success in chatbots and Q&A systems that need to maintain up-to-date information or access domain-specific knowledge.\n",
    "\n",
    "### RAG and Vector Search\n",
    "\n",
    "To be able to provide additional context to our LLM, we need to search for documents/articles where the answer to our user question might be.\n",
    "To do so,  a common solution is to deploy a vector database. This involves the creation of document embeddings, vectors of fixed size representing your document.<br/>\n",
    "The vectors will then be used to perform real-time similarity search during inference.\n",
    "\n",
    "### Implementing RAG with Databricks AI Foundation models\n",
    "\n",
    "In this demo, we will show you how to build and deploy your custom chatbot, answering questions on any custom or private information.\n",
    "\n",
    "As an example, we will specialize this chatbot to answer questions over Databricks, feeding databricks.com documentation articles to the model for accurate answers.\n",
    "\n",
    "Here is the flow we will implement:\n",
    "\n",
    "<!-- \n",
    "<div style=\"width: 400px; float: left; margin: 10px 20px 10px 10px; box-shadow: 0px 0px 10px #b5b5b5; padding:10px; min-height: 240px\">\n",
    "<h4 style=\"margin-left: 10px\">1: Data prepration:</h4>\n",
    "<ul>\n",
    "  <li> Download databricks.com documentation articles</li>\n",
    "  <li> Prepare the articles for our model (split into chunks)</li>\n",
    "  <li> Compute the chunks embeddings using Databricks Foundation model (bge) and save them to a Delta table</li>\n",
    "  <li> Add a Vector Search Index on our Delta table</li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 400px; float: left; margin: 10px; box-shadow: 0px 0px 10px #b5b5b5; padding:10px; min-height: 240px\">\n",
    "<h4 style=\"margin-left: 10px\">2: Inferences:</h4>\n",
    "<ul>\n",
    "  <li>Build a langchain model using Databricks llama2-70 foundation model</li>\n",
    "  <li>Retrieve simliar document from our Vector search index</li>\n",
    "  <li>Deploy the chain using a Model Serving Endpoint</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br style=\"clear: both\"> -->\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-self-managed-flow-0.png?raw=true\" style=\"margin-left: 10px\"  width=\"1100px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fef8bdb-fbf6-4345-a996-c3b9d6e7068b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1/ Ingest data and create your Vector Search index\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-self-managed-prep-0.png?raw=true\" style=\"float: right; width: 500px; margin-left: 10px\">\n",
    "\n",
    "The first step is to ingest and prepare the data before we can make use of our Vector Search index.\n",
    "\n",
    "We'll use the Data Engineering Lakehouse capabilities to ingest our documentation pages, split them into smaller chunks, compute the chunk embeddings and save them as a Delta Lake table.\n",
    "\n",
    "**What you will learn:**\n",
    "- Use langchain and your LLM tokenizer to create chunks from your documents\n",
    "- Compute embeddings (array&ltfloat&gt) representing our chunks with Databricks Foundation Models\n",
    "- Create a Vector Search Index on top of your data to provide real-time similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e3e8a8f-f3ca-4bd7-811d-7fb40a7950cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Start the data ingestion and create a Vector Search Index: open the [01-Data-Preparation-and-Index]($./01-Data-Preparation-and-Index) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87502cc1-9dbf-4ee1-83e5-447e4d12af86",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 2/ Deploying a RAG chatbot endpoint with databricks-llama-2-70b-chat Foundation Endpoint\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/llm-rag-self-managed-model-0.png?raw=true\" style=\"float: right; width: 500px; margin-left: 10px\">\n",
    "\n",
    "Our data is ready and our Vector Search Index can answer similarity queries, finding documentation related to our user question.\n",
    "\n",
    "We can now create a langchain model with an augmented prompt, accessing the LLama2 70B model to answer advanced Databricks questions.\n",
    "\n",
    "**What you will learn:**\n",
    "- Search documents with Databricks Langchain retriever\n",
    "- Build a langchain chain with a custom prompt\n",
    "- Deploy your chain as a serverless endpoint model and answer customer questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21a2721e-b310-45eb-9f5a-091a2d1b12f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Build & Deploy your RAG chatbot : open the [02-Deploy-RAG-Chatbot-Model]($./02-Deploy-RAG-Chatbot-Model) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ef85157-5986-4438-a5f0-7a033885da4f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We've seen how Databricks AI is uniquely positioned to help you solve your GenAI challenge:\n",
    "\n",
    "- Simplify Data Ingestion and preparation with Databricks Data Engineering capabilities\n",
    "- Accelerate Vector Search Index deployment with fully managed indexes\n",
    "- Leverages Open models, easy to fine-tune for custom requirements\n",
    "- Access a Databricks AI LLama2-70B endpoint\n",
    "- Deploy real-time model endpoints to generate answers which leverage your custom data\n",
    "\n",
    "Interested in deploying your own models? Reach out to your account team!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00-RAG-chatbot-Introduction",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
