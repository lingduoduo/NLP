{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd32ff2-6fa5-4d75-bde5-7fd88cbbeef5",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f8a129-73dd-4891-a5a8-a65e72216ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertModel\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c3a28-bd0e-4499-9069-574a45115ccb",
   "metadata": {},
   "source": [
    "### Search semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be43f978-986b-4f01-beb7-7e2a1c70bcce",
   "metadata": {},
   "source": [
    "The Hugging Face summarization task page lists models that support summarization. In this section, we will the following resources:\n",
    "\n",
    "- data: We will work with the 'xsum dataset,' containing a collection of BBC articles and their corresponding summaries. This dataset serves as the foundation for our tasks.\n",
    "\n",
    "- model: Our chosen model is the 't5-small model,' with 60 million parameters (equivalent to 242MB for PyTorch). T5, an encoder-decoder model developed by Google, boasts versatility, supporting various tasks including summarization, translation, question-answering, and text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08e40f8-a60a-4905-83f9-78aa158392c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linghuang/miniconda3/envs/transformers/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xsum_dataset = load_dataset(\n",
    "    \"xsum\", version=\"1.2.0\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397a4f0-aab2-4211-b9cc-f0e06dc5c390",
   "metadata": {},
   "source": [
    "This dataset provides 3 columns:\n",
    "\n",
    "- document: the BBC article text\n",
    "- summary: a \"ground-truth\" summary --> Note how subjective this \"ground-truth\" is. Is this the same summary you would write? This a great example of how many LLM applications do not have obvious \"right\" answers.\n",
    "- id: article ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbab8df-467b-4004-8ad1-9aecdd5ac626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a sample of 100 rows\n",
    "xsum_sample = xsum_dataset[\"train\"].select(range(1000)).to_pandas()\n",
    "\n",
    "# Combining 'document' and 'summary' columns\n",
    "xsum_sample[\"combined\"] = (\n",
    "    \"Document: \" + xsum_sample.document.str.strip() + \"; Summary: \" + xsum_sample.summary.str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ddf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#encoding the data\n",
    "encoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n",
    "encoded_data = encoder.encode(xsum_sample[\"combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ea4500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12973613, -0.07995621, -0.02103525, ...,  0.01458147,\n",
       "        -0.04181118,  0.05969834],\n",
       "       [-0.10183043, -0.00813398,  0.01535375, ...,  0.03995895,\n",
       "        -0.10245819,  0.08624592],\n",
       "       [-0.06544365, -0.22466174,  0.01042669, ...,  0.06865789,\n",
       "         0.0731439 ,  0.01244215],\n",
       "       ...,\n",
       "       [ 0.04156043,  0.15200093,  0.04194619, ...,  0.05652885,\n",
       "         0.0718336 , -0.05565466],\n",
       "       [-0.06733167,  0.10981705, -0.07706451, ...,  0.05933914,\n",
       "        -0.0320871 , -0.04915017],\n",
       "       [-0.1334438 , -0.14712858,  0.00372515, ...,  0.01369817,\n",
       "         0.0259726 , -0.09492668]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d4dc80-4f67-4f55-98ce-63b8ad737ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7c5f7b-b546-4986-aad5-f289efc713ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1883d64c-fed8-46e0-b808-e59bc5300c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(encoded_data)\n",
    "index.add_with_ids(encoded_data, np.arange(len(encoded_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3c08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_text = \"harry potter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_vector = encoder.encode(search_text)\n",
    "_vector = np.array([search_vector])\n",
    "faiss.normalize_L2(_vector)\n",
    "\n",
    "k = 2\n",
    "distances, ann = index.search(_vector, k=k)\n",
    "results = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce097a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84623a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a14265",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716c604",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e051c8e-7fb7-47c9-9164-78490e6331c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=60,\n",
    "    truncation=True,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68ff9cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1ed3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d546c1e-421a-4e48-a9f1-5cef0e6e63fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49c7fb3d-a209-4b3a-bed0-7df30a3f9a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471    bale and Ronaldo meet in a semi-final at a maj...\n",
       "882    police responded to reports of cars being driv...\n",
       "87     the reef is experiencing its worst coral bleac...\n",
       "101    the 77th Brigade will be formally created in A...\n",
       "768    president's long-time rival is on trial for wa...\n",
       "364    universities Wales will publish its manifesto ...\n",
       "880    the 14 men, from across England and Northern I...\n",
       "91     cancer research UK found 39% of Scots consumed...\n",
       "967    the body parts and tissue samples were retaine...\n",
       "225    the independent police Complaints Commission h...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to a batch of articles\n",
    "def summarize(input):\n",
    "    output = summarizer(input)\n",
    "    return output[0]['summary_text']\n",
    "    \n",
    "xsum_sample[\"document\"].sample(10).apply(summarize)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e428da-bb6a-4757-b341-0e90a6c02b2f",
   "metadata": {},
   "source": [
    "### Search and sampling in inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15021d61-8839-4d7a-b8db-7d9335178fdc",
   "metadata": {},
   "source": [
    "You may see parameters like `num_beams`, `do_sample`, etc. specified in Hugging Face pipelines.  These are inference configurations.\n",
    "\n",
    "LLMs work by predicting (generating) the next token, then the next, and so on.  The goal is to generate a high probability sequence of tokens, which is essentially a search through the (enormous) space of potential sequences.\n",
    "\n",
    "To do this search, LLMs use one of two main methods:\n",
    "* **Search**: Given the tokens generated so far, pick the next most likely token in a \"search.\"\n",
    "   * **Greedy search** (default): Pick the single next most likely token in a greedy search.\n",
    "   * **Beam search**: Greedy search can be extended via beam search, which searches down several sequence paths, via the parameter `num_beams`.\n",
    "* **Sampling**: Given the tokens generated so far, pick the next token by sampling from the predicted distribution of tokens.\n",
    "   * **Top-K sampling**: The parameter `top_k` modifies sampling by limiting it to the `k` most likely tokens.\n",
    "   * **Top-p sampling**: The parameter `top_p` modifies sampling by limiting it to the most likely tokens up to probability mass `p`.\n",
    "\n",
    "You can toggle between search and sampling via parameter `do_sample`.\n",
    "\n",
    "For more background on search and sampling, see [this Hugging Face blog post](https://huggingface.co/blog/how-to-generate).\n",
    "\n",
    "We will illustrate these various options below using our summarization pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d39ed141-bdd3-42fc-81e2-05c759939c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can instead do a beam search by specifying num_beams.\n",
    "summarizer(xsum_sample[\"document\"][0], num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "212e9573-1594-4c99-a641-cf4c93de77e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the waters breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we could use sampling.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a885e929-8161-4ded-bf31-9a46ac392000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True, top_k=10, top_p=0.8)›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
