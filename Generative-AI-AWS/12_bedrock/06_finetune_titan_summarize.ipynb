{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308a0e04-6066-4405-8a13-8b060e552a8a",
   "metadata": {},
   "source": [
    "# Introduction to Bedrock - Fine-Tuning\n",
    "\n",
    "> *If you see errors, you may need to be allow-listed for the Bedrock models used by this notebook*\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9a3e6-4d64-4da4-8a85-d5c12ae70978",
   "metadata": {},
   "source": [
    "In this demo notebook, we demonstrate how to use the Bedrock Python SDK for fine-tuning Bedrock models with your own data. If you have text samples to train and want to adapt the Bedrock models to your domain, you can further fine-tune the Bedrock foundation models by providing your own training datasets. You can upload your datasets to Amazon S3, and provide the S3 bucket path while configuring a Bedrock fine-tuning job. You can also adjust hyper parameters (learning rate, epoch, and batch size) for fine-tuning. After the fine-tuning job of the model with your dataset has completed, you can start using the model for inference in the Bedrock playground application. You can select the fine-tuned model and submit a prompt to the fine-tuned model along with a set of model parameters. The fine-tuned model should generate texts to be more alike your text samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26768f-3775-436d-8b77-dee584420aff",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0821c-2d18-4698-8efc-df81030bcdc8",
   "metadata": {},
   "source": [
    "1. Setup\n",
    "2. Fine-tuning\n",
    "3. Testing the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889b27f-7d55-4c07-81fc-3f00d55e5544",
   "metadata": {},
   "source": [
    " Note: This notebook was tested in Amazon SageMaker Studio with Python 3 (Data Science 2.0) kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb89f-2b60-41e4-8ea7-8cace718bed5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c5e24-b7c8-4932-b8d1-729ff52c6fb1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ddbd728-aa90-4431-9b1c-9dc2f9214140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.1.2\n",
      "  Obtaining dependency information for pandas==2.1.2 from https://files.pythonhosted.org/packages/02/52/815f643ed3afb3365354548b3c8b557dbf926a65c40ad5b6d9e455147c7e/pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from pandas==2.1.2)\n",
      "  Obtaining dependency information for numpy<2,>=1.22.4 from https://files.pythonhosted.org/packages/2d/5e/cb38e3d1916cc29880c84a9332a9122a8f49a7b57ec7aea63e0f678587a2/numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas==2.1.2)\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.1.2)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.1.2)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.1.2)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Using cached numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3.post1\n",
      "    Uninstalling pytz-2023.3.post1:\n",
      "      Successfully uninstalled pytz-2023.3.post1\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2023.3\n",
      "    Uninstalling tzdata-2023.3:\n",
      "      Successfully uninstalled tzdata-2023.3\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.1\n",
      "    Uninstalling numpy-1.26.1:\n",
      "      Successfully uninstalled numpy-1.26.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.2\n",
      "    Uninstalling pandas-2.1.2:\n",
      "      Successfully uninstalled pandas-2.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.1.2 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.2 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "notebook 6.5.6 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.4.0 which is incompatible.\n",
      "notebook 6.5.6 requires pyzmq<25,>=17, but you have pyzmq 25.1.1 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.1 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.1 pandas-2.1.2 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 tzdata-2023.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --force-reinstall pandas==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaf9999-7c02-4c00-ac93-0e0f8ba6553b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.14.6 in /opt/conda/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (0.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.6) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets==2.14.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17f96e1-7c93-44be-9e4c-542fa0254673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "notebook 6.5.6 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.4.0 which is incompatible.\n",
      "notebook 6.5.6 requires pyzmq<25,>=17, but you have pyzmq 25.1.1 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "pyasn1-modules 0.2.8 requires pyasn1<0.5.0,>=0.4.6, but you have pyasn1 0.5.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U EMBARGO/boto3-1.28.60-py3-none-any.whl \\\n",
    "               EMBARGO/botocore-1.31.60-py3-none-any.whl \\\n",
    "               EMBARGO/awscli-1.29.60-py3-none-any.whl \\\n",
    "               --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfaf752-e11b-4e69-ba9f-c934537360dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3                                1.28.60\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d966521-f63a-4c96-8494-68d6d2367938",
   "metadata": {},
   "source": [
    "#### Now let's set up our connection to the Amazon Bedrock SDK using Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785b3b10-2c66-4adc-a4ac-747c214fd9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "#import os\n",
    "#os.environ['BEDROCK_ASSUME_ROLE'] = '<YOUR_VALUES>'\n",
    "#os.environ['AWS_PROFILE'] = '<YOUR_VALUES>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ad566f-2a15-46ac-aeeb-346f9db0a10e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-west-2.amazonaws.com)\n",
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "bedrock_admin = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=False  # Needed for control plane\n",
    ")\n",
    "\n",
    "bedrock_runtime = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=True  # Needed for control plane\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f4a497-d0f3-4be1-8c67-04cd1f0a6d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ffacc8d1-05e2-4a8c-8ece-73fce868e867',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 20:30:33 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '6095',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'ffacc8d1-05e2-4a8c-8ece-73fce868e867'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large',\n",
       "   'modelName': 'Titan Text Large',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium',\n",
       "   'modelName': 'Titan Text Embeddings',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-g1-text-02',\n",
       "   'modelId': 'amazon.titan-embed-g1-text-02',\n",
       "   'modelName': 'Titan Text Embeddings v2',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1',\n",
       "   'modelId': 'amazon.titan-text-lite-v1',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1',\n",
       "   'modelId': 'amazon.titan-text-express-v1',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v1',\n",
       "   'modelId': 'amazon.titan-embed-text-v1',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl',\n",
       "   'modelName': 'Stable Diffusion XL',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl-v0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v0',\n",
       "   'modelName': 'Stable Diffusion XL',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct',\n",
       "   'modelName': 'J2 Grande Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct',\n",
       "   'modelName': 'J2 Jumbo Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-mid-v1',\n",
       "   'modelId': 'ai21.j2-mid-v1',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-ultra-v1',\n",
       "   'modelId': 'ai21.j2-ultra-v1',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-text-v14',\n",
       "   'modelId': 'cohere.command-text-v14',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_admin.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48703d82-bb32-44fa-916e-6cc5040a67cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c1fa8-657c-4e45-94e8-e907857d145a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Invoke Model before Fine-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1684e7-8b0f-436d-a8a0-2a2b45ffe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"amazon.titan-text-express-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ca1873-eebc-43b1-b910-32d4796c5b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inputTextTokenCount\":221,\"results\":[{\"tokenCount\":41,\"outputText\":\"John Sandals has made a reservation and is in room 507, nonsmoking, with a queen-size bed. He has a VISA and a key to dial zero if needed.\",\"completionReason\":\"FINISH\"}]}\n",
      "John Sandals has made a reservation and is in room 507, nonsmoking, with a queen-size bed. He has a VISA and a key to dial zero if needed.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    # modelId needs to be Provisioned Throughput Model ARN\n",
    "    modelId=base_model_id,\n",
    "    body=\"\"\"\n",
    "{\n",
    "  \"inputText\": \"Summarize the following conversation.\\\\n\\\\n#Person1#: Hello. My name is John Sandals, and I've got a reservation.\\\\n#Person2#: May I see some identification, sir, please?\\\\n#Person1#: Sure. Here you are.\\\\n#Person2#: Thank you so much. Have you got a credit card, Mr. Sandals?\\\\n#Person1#: I sure do. How about American Express?\\\\n#Person2#: Unfortunately, at the present time we take only MasterCard or VISA.\\\\n#Person1#: No American Express? Okay, here's my VISA.\\\\n#Person2#: Thank you, sir. You'll be in room 507, nonsmoking, with a queen-size bed. Do you approve, sir?\\\\n#Person1#: Yeah, that'll be fine.\\\\n#Person2#: That's great. This is your key, sir. If you need anything at all, anytime, just dial zero.\\\\n\\\\nSummary: \",\n",
    "  \"textGenerationConfig\":{\n",
    "    \"maxTokenCount\": 50, \n",
    "    \"stopSequences\": [],\n",
    "    \"temperature\": 0.1,\n",
    "    \"topP\": 0.9\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(response_body)\n",
    "\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa6614-7080-4dbb-af08-cd67ce6a8706",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert the dataset into jsonlines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f96f947-e885-48a1-8530-b70b8fefc073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cef0311-b45f-481b-bdbe-a14d4baa1359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrap_instruction_fn(example):\n",
    "    prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    example[\"instruction\"] = prompt + example[\"dialogue\"] + end_prompt\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94a8473-2226-4f0e-9890-03635534156b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3241432845041718e12072dabdce700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae6fa3870e647079b0b808c63e7eba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c11e699da6a4d438e501af871911a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1439339"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']\\\n",
    "  .select(range(1000))\\\n",
    "  .select_columns(['dialogue', 'summary'])\\\n",
    "  .map(wrap_instruction_fn)\\\n",
    "  .remove_columns(['dialogue'])\\\n",
    "  .rename_column('instruction', 'input')\\\n",
    "  .rename_column('summary', 'output')\\\n",
    "  .to_json('./train-summarization.jsonl', index=False)\n",
    "\n",
    "dataset['validation']\\\n",
    "  .select_columns(['dialogue', 'summary'])\\\n",
    "  .map(wrap_instruction_fn)\\\n",
    "  .remove_columns(['dialogue'])\\\n",
    "  .rename_column('instruction', 'input')\\\n",
    "  .rename_column('summary', 'output')\\\n",
    "  .to_json('./validation-summarization.jsonl', index=False)\n",
    "\n",
    "dataset['test']\\\n",
    "  .select_columns(['dialogue', 'summary'])\\\n",
    "  .map(wrap_instruction_fn)\\\n",
    "  .remove_columns(['dialogue'])\\\n",
    "  .rename_column('instruction', 'input')\\\n",
    "  .rename_column('summary', 'output')\\\n",
    "  .to_json('./test-summarization.jsonl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c60adba-f766-47ac-8bac-95f6fed26028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>In terms of the sandstorm, #Person1# prefers t...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>#Person2# invites two people that fill the abs...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Claire is pretty stressed and the stress serio...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Marian and Jeanine are shopping, but Marian is...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>#Person1# and #Person2# are sharing their diff...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                output  \\\n",
       "0    Mr. Smith's getting a check-up, and Doctor Haw...   \n",
       "1    Mrs Parker takes Ricky for his vaccines. Dr. P...   \n",
       "2    #Person1#'s looking for a set of keys and asks...   \n",
       "3    #Person1#'s angry because #Person2# didn't tel...   \n",
       "4    Malik invites Nikki to dance. Nikki agrees if ...   \n",
       "..                                                 ...   \n",
       "995  In terms of the sandstorm, #Person1# prefers t...   \n",
       "996  #Person2# invites two people that fill the abs...   \n",
       "997  Claire is pretty stressed and the stress serio...   \n",
       "998  Marian and Jeanine are shopping, but Marian is...   \n",
       "999  #Person1# and #Person2# are sharing their diff...   \n",
       "\n",
       "                                                 input  \n",
       "0    Summarize the following conversation.\\n\\n#Pers...  \n",
       "1    Summarize the following conversation.\\n\\n#Pers...  \n",
       "2    Summarize the following conversation.\\n\\n#Pers...  \n",
       "3    Summarize the following conversation.\\n\\n#Pers...  \n",
       "4    Summarize the following conversation.\\n\\n#Pers...  \n",
       "..                                                 ...  \n",
       "995  Summarize the following conversation.\\n\\n#Pers...  \n",
       "996  Summarize the following conversation.\\n\\n#Pers...  \n",
       "997  Summarize the following conversation.\\n\\n#Pers...  \n",
       "998  Summarize the following conversation.\\n\\n#Pers...  \n",
       "999  Summarize the following conversation.\\n\\n#Pers...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"./train-summarization.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215843b6-9c4e-4c82-b3c1-c8cc99d01488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"./train-summarization.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de721f4-3f65-4aa4-84ce-19f7a7c47778",
   "metadata": {},
   "source": [
    "Read the JSON line file into an object like any normal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa423f6-7827-45fc-bd49-39c1b6f9759a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(data) as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2ea85-a95b-4cfb-9463-692b9a642897",
   "metadata": {},
   "source": [
    "#### Load the ‘lines’ object into a pandas Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7da61e9b-ac1f-4f69-8cb6-b525a737cba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_inter = pd.DataFrame(lines)\n",
    "df_inter.columns = ['json_element']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf4879-a796-4359-ba80-f7a54dc05cd6",
   "metadata": {},
   "source": [
    "This intermediate data frame will have only one column with each json object in a row. A sample output is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a8528c-d478-48a9-acef-ac135b3090d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'output': 'Mr. Smith's getting a check-up, an...\n",
       "1      {'output': 'Mrs Parker takes Ricky for his vac...\n",
       "2      {'output': '#Person1#'s looking for a set of k...\n",
       "3      {'output': '#Person1#'s angry because #Person2...\n",
       "4      {'output': 'Malik invites Nikki to dance. Nikk...\n",
       "                             ...                        \n",
       "995    {'output': 'In terms of the sandstorm, #Person...\n",
       "996    {'output': '#Person2# invites two people that ...\n",
       "997    {'output': 'Claire is pretty stressed and the ...\n",
       "998    {'output': 'Marian and Jeanine are shopping, b...\n",
       "999    {'output': '#Person1# and #Person2# are sharin...\n",
       "Name: json_element, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter['json_element'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc711d5-6522-47be-b4b6-fe292d70e6e8",
   "metadata": {},
   "source": [
    "Now we will apply json loads function on each row of the ‘json_element’ column. ‘json.loads’ is a decoder function in python which is used to decode a json object into a dictionary. ‘apply’ is a popular function in pandas that takes any function and applies to each row of the pandas dataframe or series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "600eac79-5830-4422-a39a-19b6770827a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2430c-c36f-43a7-8ce6-e17b0efdbd20",
   "metadata": {},
   "source": [
    "Once decoding is done we will apply the json normalize function to the above result. json normalize will convert any semi-structured json data into a flat table. Here it converts the JSON ‘keys’ to columns and its corresponding values to row elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2061f7a-eb1a-4089-96c1-7bfc8dd3d741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>In terms of the sandstorm, #Person1# prefers t...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>#Person2# invites two people that fill the abs...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Claire is pretty stressed and the stress serio...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Marian and Jeanine are shopping, but Marian is...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>#Person1# and #Person2# are sharing their diff...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                output  \\\n",
       "0    Mr. Smith's getting a check-up, and Doctor Haw...   \n",
       "1    Mrs Parker takes Ricky for his vaccines. Dr. P...   \n",
       "2    #Person1#'s looking for a set of keys and asks...   \n",
       "3    #Person1#'s angry because #Person2# didn't tel...   \n",
       "4    Malik invites Nikki to dance. Nikki agrees if ...   \n",
       "..                                                 ...   \n",
       "995  In terms of the sandstorm, #Person1# prefers t...   \n",
       "996  #Person2# invites two people that fill the abs...   \n",
       "997  Claire is pretty stressed and the stress serio...   \n",
       "998  Marian and Jeanine are shopping, but Marian is...   \n",
       "999  #Person1# and #Person2# are sharing their diff...   \n",
       "\n",
       "                                                 input  \n",
       "0    Summarize the following conversation.\\n\\n#Pers...  \n",
       "1    Summarize the following conversation.\\n\\n#Pers...  \n",
       "2    Summarize the following conversation.\\n\\n#Pers...  \n",
       "3    Summarize the following conversation.\\n\\n#Pers...  \n",
       "4    Summarize the following conversation.\\n\\n#Pers...  \n",
       "..                                                 ...  \n",
       "995  Summarize the following conversation.\\n\\n#Pers...  \n",
       "996  Summarize the following conversation.\\n\\n#Pers...  \n",
       "997  Summarize the following conversation.\\n\\n#Pers...  \n",
       "998  Summarize the following conversation.\\n\\n#Pers...  \n",
       "999  Summarize the following conversation.\\n\\n#Pers...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546f2e9-000b-4c87-807e-2a63554bcc8c",
   "metadata": {},
   "source": [
    "### Uploading data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91c8bc-cb24-4b04-8de8-25c03c3490df",
   "metadata": {},
   "source": [
    "Next, we need to upload our training dataset to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49e9547f-127d-444e-89ed-6403781c83a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/train-summarization.jsonl\"\n",
    "s3_output = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fb873b6-c50b-46fb-bd1f-a050bf523221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train-summarization.jsonl to s3://sagemaker-us-west-2-079002598131/bedrock/finetuning/train-summarization.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./train-summarization.jsonl $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb85e28-aec1-46bc-aa6c-ba9b04cbc106",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create the fine-tuning job. \n",
    "\n",
    "### ^^ **Note:** Make sure the IAM role you're using has these [IAM policies](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-iam-role.html) attached that allow Amazon Bedrock access to the specified S3 buckets ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04f82b-a918-4226-bf88-3ce567e50bcc",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "093e54cf-f0f3-403f-8ef5-84e0cbb40d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc3af82-7cd6-44bd-bf14-e3e455c15e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titan-1698870642'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = \"titan-{}\".format(timestamp)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adfbd806-cb7e-4414-97a6-9239e98e5604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-titan-1698870642'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_name = \"custom-{}\".format(job_name)\n",
    "custom_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4f0ead8-31d2-4146-82c8-2d4d5fa07397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1c65efd7-2a1f-4658-b1db-c6488f9d6aaa',\n",
       "  'HTTPStatusCode': 201,\n",
       "  'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 20:30:42 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '122',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '1c65efd7-2a1f-4658-b1db-c6488f9d6aaa'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/5b0zpxc2x2n7'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_admin.create_model_customization_job(\n",
    "    jobName=job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"10\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.000001\",\n",
    "        \"learningRateWarmupSteps\": \"0\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": s3_location},\n",
    "    outputDataConfig={\"s3Uri\": s3_output},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b1a6b37-6a22-4f63-8729-185642acc1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InProgress'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = bedrock_admin.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e0489-c5e3-4cc7-981b-6706497c6527",
   "metadata": {},
   "source": [
    "# Let's periodically check in on the progress.\n",
    "### The next cell might run for ~40min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f87f790-8ee0-4485-b090-1be7af0f0554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = bedrock_admin.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "    status = bedrock_admin.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9813589e-901f-49d5-9a1b-82609a405da9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '26abad81-d952-4a55-8ee2-d75d45c37b54',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 22:50:50 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1236',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '26abad81-d952-4a55-8ee2-d75d45c37b54'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/5b0zpxc2x2n7',\n",
       " 'jobName': 'titan-1698870642',\n",
       " 'outputModelName': 'custom-titan-1698870642',\n",
       " 'outputModelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/oqzaoaay5ymd',\n",
       " 'clientRequestToken': 'f993acf5-86df-4061-a5f7-efce62ee8d31',\n",
       " 'roleArn': 'arn:aws:iam::079002598131:role/service-role/AmazonSageMaker-ExecutionRole-20220804T150518',\n",
       " 'status': 'Completed',\n",
       " 'creationTime': datetime.datetime(2023, 11, 1, 20, 30, 42, 742000, tzinfo=tzlocal()),\n",
       " 'lastModifiedTime': datetime.datetime(2023, 11, 1, 22, 50, 23, 987000, tzinfo=tzlocal()),\n",
       " 'endTime': datetime.datetime(2023, 11, 1, 22, 50, 23, 102000, tzinfo=tzlocal()),\n",
       " 'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       " 'hyperParameters': {'batchSize': '1',\n",
       "  'epochCount': '10',\n",
       "  'learningRate': '0.000001',\n",
       "  'learningRateWarmupSteps': '0'},\n",
       " 'trainingDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/train-summarization.jsonl'},\n",
       " 'outputDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/output'},\n",
       " 'customizationType': 'FINE_TUNING',\n",
       " 'validationMetrics': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_job = bedrock_admin.get_model_customization_job(jobIdentifier=job_name)\n",
    "completed_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b47ec7-9933-45d1-9ad6-67be8fb318f9",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13364c0-17a8-4a30-b354-100c7b43a81b",
   "metadata": {},
   "source": [
    "Now we can test the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42f5bdf2-29a9-4041-8a62-b1f69ddbf129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '7fa0b26e-8777-4c47-8d63-f8a17ea7fe41',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 22:50:50 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '3737',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '7fa0b26e-8777-4c47-8d63-f8a17ea7fe41'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/oqzaoaay5ymd',\n",
       "   'modelName': 'custom-titan-1698870642',\n",
       "   'creationTime': datetime.datetime(2023, 11, 1, 20, 30, 42, 742000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/exz6ndzq3nol',\n",
       "   'modelName': 'custom-titan-1698866630',\n",
       "   'creationTime': datetime.datetime(2023, 11, 1, 19, 23, 50, 736000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/vf6y31mfu5rp',\n",
       "   'modelName': 'custom-titan-1698810242',\n",
       "   'creationTime': datetime.datetime(2023, 11, 1, 3, 44, 2, 851000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/emo6bgsjnccp',\n",
       "   'modelName': 'custom-titan-1698810069',\n",
       "   'creationTime': datetime.datetime(2023, 11, 1, 3, 41, 9, 732000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/ooo8k17tlqca',\n",
       "   'modelName': 'custom-titan-1698720373',\n",
       "   'creationTime': datetime.datetime(2023, 10, 31, 2, 46, 13, 975000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/dprv4g1wcz5l',\n",
       "   'modelName': 'custom-titan-1698714267',\n",
       "   'creationTime': datetime.datetime(2023, 10, 31, 1, 4, 29, 688000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/gvg2yfk3p3z8',\n",
       "   'modelName': 'custom-titan-1698687935',\n",
       "   'creationTime': datetime.datetime(2023, 10, 30, 17, 45, 35, 991000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/iean6zy959j7',\n",
       "   'modelName': 'custom-titan-1698436673',\n",
       "   'creationTime': datetime.datetime(2023, 10, 27, 19, 57, 54, 497000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/pfio1mlb9zvs',\n",
       "   'modelName': 'custom-titan-1698428607',\n",
       "   'creationTime': datetime.datetime(2023, 10, 27, 17, 43, 33, 283000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/dwe144t3byoy',\n",
       "   'modelName': 'custom-titan-1698424402',\n",
       "   'creationTime': datetime.datetime(2023, 10, 27, 16, 33, 25, 669000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4',\n",
       "   'modelName': 'custom-titan-1698257909',\n",
       "   'creationTime': datetime.datetime(2023, 10, 25, 18, 20, 20, 815000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/rfs7atdiuu9m',\n",
       "   'modelName': 'my-finetuned-model-small-10',\n",
       "   'creationTime': datetime.datetime(2023, 10, 14, 15, 56, 53, 673000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_admin.list_custom_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7be0a01-1a4a-41e9-8c39-89f4d36942f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/5b0zpxc2x2n7\n",
      "jobName: titan-1698870642\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698870642\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/pg91fbovk6na\n",
      "jobName: titan-1698866630\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698866630\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/8rz3vmqhij26\n",
      "jobName: titan-1698810242\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698810242\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/rlxh6hn980ef\n",
      "jobName: titan-1698810069\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698810069\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/u6lh0glwc99k\n",
      "jobName: titan-1698720373\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698720373\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/thnjtypgzz8r\n",
      "jobName: titan-1698714267\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698714267\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/5bcge4pbs4ja\n",
      "jobName: titan-1698687935\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698687935\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/9yp1rpwdhbqc\n",
      "jobName: titan-1698620445\n",
      "status: Failed\n",
      "customModelName: custom-titan-1698620445\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/qqu9jug6yicq\n",
      "jobName: titan-1698619818\n",
      "status: Failed\n",
      "customModelName: custom-titan-1698619818\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/qt8xp1kqxcev\n",
      "jobName: titan-1698615542\n",
      "status: Failed\n",
      "customModelName: custom-titan-1698615542\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/9iib3tdtyv9n\n",
      "jobName: titan-1698436673\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698436673\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/7qdxbvgukutb\n",
      "jobName: titan-1698428607\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698428607\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/h1dfedum8pjt\n",
      "jobName: titan-1698424402\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698424402\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/ycbprb70zy42\n",
      "jobName: titan-1698257909\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698257909\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/qogsvgm6j43o\n",
      "jobName: finetune-small-10\n",
      "status: Completed\n",
      "customModelName: my-finetuned-model-small-10\n"
     ]
    }
   ],
   "source": [
    "for job in bedrock_admin.list_model_customization_jobs()[\"modelCustomizationJobSummaries\"]:\n",
    "    print(\"-----\\n\" + \"jobArn: \" + job[\"jobArn\"] + \"\\njobName: \" + job[\"jobName\"] + \"\\nstatus: \" + job[\"status\"] + \"\\ncustomModelName: \" + job[\"customModelName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf92c4-e2d3-48d4-83ab-592770e6aa61",
   "metadata": {},
   "source": [
    "## GetCustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0456a56-8bc3-47d2-8d69-4205ad0b1cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '9e279764-a9c8-4bd3-8e6e-c3d6b02a4cb1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 22:50:51 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '897',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '9e279764-a9c8-4bd3-8e6e-c3d6b02a4cb1'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/oqzaoaay5ymd',\n",
       " 'modelName': 'custom-titan-1698870642',\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/5b0zpxc2x2n7',\n",
       " 'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       " 'customizationType': 'FINE_TUNING',\n",
       " 'hyperParameters': {'batchSize': '1',\n",
       "  'epochCount': '10',\n",
       "  'learningRate': '0.000001',\n",
       "  'learningRateWarmupSteps': '0'},\n",
       " 'trainingDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/train-summarization.jsonl'},\n",
       " 'outputDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/output'},\n",
       " 'trainingMetrics': {'trainingLoss': 0.7109375},\n",
       " 'validationMetrics': [],\n",
       " 'creationTime': datetime.datetime(2023, 11, 1, 20, 30, 42, 742000, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_admin.get_custom_model(modelIdentifier=custom_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03bb02cd-0624-43f1-b3bc-2369333640d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/oqzaoaay5ymd'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_arn = bedrock_admin.get_custom_model(modelIdentifier=custom_model_name)['modelArn']\n",
    "custom_model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a6a7e0b-2ee9-4c58-9db7-9d504b35d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_arn = bedrock_admin.get_custom_model(modelIdentifier=custom_model_name)['baseModelArn']\n",
    "base_model_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e23e8-c4ee-4598-95ec-65620abb3631",
   "metadata": {},
   "source": [
    "## **Note:** To invoke custom models, you need to first create a provisioned throughput resource and make requests using that resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd028a6c-f13b-4d58-9b4f-ce8a18aecd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-titan-1698870642-provisioned'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provisioned_model_name = \"{}-provisioned\".format(custom_model_name)\n",
    "provisioned_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d7cbf-f391-4436-953e-70eaa987e3aa",
   "metadata": {},
   "source": [
    "## !! **Note:** SDK currently only supports 1 month and 6 months commitment terms. Go to Bedrock console to manually purchase no commitment term option for testing !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "531afd39-5bde-4ead-a342-bea7c972c39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bedrock_admin.create_provisioned_model_throughput(\n",
    "#     modelUnits = 1,\n",
    "#     commitmentDuration = \"OneMonth\", ## Note: SDK is currently missing No Commitment option\n",
    "#     provisionedModelName = provisioned_model_name,\n",
    "#     modelId = base_model_arn\n",
    "# ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828ec02-d7ae-43d3-afcb-060c95d4f4fd",
   "metadata": {},
   "source": [
    "## ListProvisionedModelThroughputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "269b30af-8167-4c70-be70-ec0050fca906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'provisionedModelName': 'custom-titan-1698866630-provisioned',\n",
       "  'provisionedModelArn': 'arn:aws:bedrock:us-west-2:079002598131:provisioned-model/8dr5a7xr94e0',\n",
       "  'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/exz6ndzq3nol',\n",
       "  'desiredModelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/exz6ndzq3nol',\n",
       "  'foundationModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "  'modelUnits': 1,\n",
       "  'desiredModelUnits': 1,\n",
       "  'status': 'InService',\n",
       "  'creationTime': datetime.datetime(2023, 11, 1, 21, 36, 21, 60000, tzinfo=tzlocal()),\n",
       "  'lastModifiedTime': datetime.datetime(2023, 11, 1, 22, 0, 32, 361000, tzinfo=tzlocal())},\n",
       " {'provisionedModelName': 'custom-titan-1698810069-provisioned',\n",
       "  'provisionedModelArn': 'arn:aws:bedrock:us-west-2:079002598131:provisioned-model/k1eskohzk2vi',\n",
       "  'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/emo6bgsjnccp',\n",
       "  'desiredModelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/emo6bgsjnccp',\n",
       "  'foundationModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "  'modelUnits': 1,\n",
       "  'desiredModelUnits': 1,\n",
       "  'status': 'InService',\n",
       "  'creationTime': datetime.datetime(2023, 11, 1, 14, 18, 55, 732000, tzinfo=tzlocal()),\n",
       "  'lastModifiedTime': datetime.datetime(2023, 11, 1, 14, 41, 2, 579000, tzinfo=tzlocal())}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_admin.list_provisioned_model_throughputs()[\"provisionedModelSummaries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d9e7b-68f8-4162-97d6-fe8f43e3b421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GetProvisionedModelThroughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1308145-1e5a-474e-ad82-138de065f16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#provisioned_model_name = \"<YOUR_PROVISIONED_MODEL_NAME>\" # e.g. custom-titan-1698257909-provisioned\n",
    "#provisioned_model_name = \"custom-titan-1698257909-provisioned\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61669df7-a58d-4f86-bb8c-a9319ca52c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2:079002598131:provisioned-model/picnd68jrr0f'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provisioned_model_arn = bedrock_admin.get_provisioned_model_throughput(\n",
    "     provisionedModelId=provisioned_model_name)[\"provisionedModelArn\"]\n",
    "provisioned_model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b15e071-9f84-4a0b-af8c-2f94875fbefe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creating'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_status = bedrock_admin.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "deployment_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93817fcb-22d3-4c85-9ab5-c78fd67b5a16",
   "metadata": {},
   "source": [
    "## The next cell might run for ~10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b22987e2-82fe-4550-9ecd-d13004f0919f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "deployment_status = bedrock_admin.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "\n",
    "while deployment_status == \"Creating\":\n",
    "    \n",
    "    print(deployment_status)\n",
    "    time.sleep(30)\n",
    "    deployment_status = bedrock_admin.get_provisioned_model_throughput(\n",
    "        provisionedModelId=provisioned_model_name)[\"status\"]  \n",
    "    \n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364ddd6-8ad2-47c8-90b3-e518be36a329",
   "metadata": {},
   "source": [
    "# Qualitative Results with Zero Shot Inference AFTER Fine-Tuning\n",
    "\n",
    "As with many GenAI applications, a qualitative approach where you ask yourself the question \"is my model behaving the way it is supposed to?\" is usually a good starting point. In the example below (the same one we started this notebook with), you can see how the fine-tuned model is able to create a reasonable summary of the dialogue compared to the original inability to understand what is being asked of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8ef4202-e6e8-4f65-bb06-4c2309e1823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inputTextTokenCount\":221,\"results\":[{\"tokenCount\":18,\"outputText\":\"#Person2# helps John Sandals check into a room and gives him the key.\",\"completionReason\":\"FINISH\"}]}\n",
      "#Person2# helps John Sandals check into a room and gives him the key.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    # modelId needs to be Provisioned Throughput Model ARN\n",
    "    modelId=provisioned_model_arn,\n",
    "    body=\"\"\"\n",
    "{\n",
    "  \"inputText\": \"Summarize the following conversation.\\\\n\\\\n#Person1#: Hello. My name is John Sandals, and I've got a reservation.\\\\n#Person2#: May I see some identification, sir, please?\\\\n#Person1#: Sure. Here you are.\\\\n#Person2#: Thank you so much. Have you got a credit card, Mr. Sandals?\\\\n#Person1#: I sure do. How about American Express?\\\\n#Person2#: Unfortunately, at the present time we take only MasterCard or VISA.\\\\n#Person1#: No American Express? Okay, here's my VISA.\\\\n#Person2#: Thank you, sir. You'll be in room 507, nonsmoking, with a queen-size bed. Do you approve, sir?\\\\n#Person1#: Yeah, that'll be fine.\\\\n#Person2#: That's great. This is your key, sir. If you need anything at all, anytime, just dial zero.\\\\n\\\\nSummary: \",\n",
    "  \"textGenerationConfig\":{\n",
    "    \"maxTokenCount\": 50, \n",
    "    \"stopSequences\": [],\n",
    "    \"temperature\": 0.1,\n",
    "    \"topP\": 0.9\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(response_body)\n",
    "\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62c91-c793-439d-b3b4-66f6eb0b0c1b",
   "metadata": {},
   "source": [
    "## Delete Provisioned Throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdbf87-b454-410a-9f11-fb42c17ed159",
   "metadata": {},
   "source": [
    "When you're done testing, you can delete Provisioned Throughput to stop charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad633b8-db9c-43a9-b2ab-b39bc7b3ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bedrock_admin.delete_provisioned_model_throughput(\n",
    "#     provisionedModelId = provisioned_model_name\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
