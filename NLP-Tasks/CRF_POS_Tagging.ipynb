{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lingduoduo/NLP/blob/master/NLP_Series_POS_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQWFO0PsoGOI"
   },
   "source": [
    "# So, it is time to learn to PoS Tag!\n",
    "\n",
    "In this notebook, I'll guide you through the steps of training some models to be further utilized in our NLP Tool to do PoS Tagging. Here we won't apply any state of the art algorithm, but we won't be far either!\n",
    "\n",
    "There are different techniques for POS Tagging:\n",
    "\n",
    "* Lexical Based Methods — Assigns the POS tag the most frequently occurring with a word in the training corpus.\n",
    "* Rule-Based Methods — Assigns POS tags based on rules. For example, we can have a rule that says, words ending with “ed” or “ing” must be assigned to a verb. Rule-Based Techniques can be used along with Lexical Based approaches to allow POS Tagging of words that are not present in the training corpus but are there in the testing data.\n",
    "* Probabilistic Methods — This method assigns the POS tags based on the probability of a particular tag sequence occurring. Conditional Random Fields (CRFs) and Hidden Markov Models (HMMs) are probabilistic approaches to assign a POS Tag.\n",
    "* Deep Learning Methods — Recurrent Neural Networks can also be used for POS tagging.\n",
    "\n",
    "\n",
    "## Getting the data (Corpus)\n",
    "\n",
    "Let us start by where we'll get our data (our **corpus**). There are many sources, but two are the most commonly used:\n",
    "* **Penn Treebank** subset from nltk (you can buy the entire Treebank, if you want, but you'll have to invest some $700~).\n",
    "* The **Universal Dependencies** Treebanks, available (as of February 2020) for 90 languages (in different quality and quantity levels).\n",
    "\n",
    "These contain the hard work of many **annotators**, which went through selected sets of sentences and annotated each one by hand, forming a corpus to be used as **supervised** input for our **machine learning algorithms**.\n",
    "\n",
    "The following two cells will show how to import the corpus from each of these two sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4B5gdrh7Z_Ic",
    "outputId": "a6175870-3419-46b2-9fd9-72fe6877a8a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/linghuang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    }
   ],
   "source": [
    "#This cell loads the Penn Treebank corpus from nltk into a list variable named penn_treebank.\n",
    "\n",
    "#No need to install nltk in google colab since it is preloaded in the environments.\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "\n",
    "#Ensure that the treebank corpus is downloaded\n",
    "nltk.download('treebank')\n",
    "\n",
    "#Load the treebank corpus class\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "#Now we iterate over all samples from the corpus (the fileids - that are equivalent to sentences)\n",
    "#and retrieve the word and the pre-labeled PoS tag. This will be added as a list of tuples with\n",
    "#a list of words and a list of their respective PoS tags (in the same order).\n",
    "penn_treebank = []\n",
    "for fileid in treebank.fileids():\n",
    "  tokens = []\n",
    "  tags = []\n",
    "  for word, tag in treebank.tagged_words(fileid):\n",
    "    tokens.append(word)\n",
    "    tags.append(tag)\n",
    "  penn_treebank.append((tokens, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WwZYkNr1bPN",
    "outputId": "21f496ec-a911-401a-b027-e748c7a60017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting conllu\n",
      "  Downloading conllu-5.0.1-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading conllu-5.0.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: conllu\n",
      "Successfully installed conllu-5.0.1\n",
      "--2024-07-18 14:19:30--  https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz\n",
      "Resolving lindat.mff.cuni.cz (lindat.mff.cuni.cz)... 195.113.20.140\n",
      "Connecting to lindat.mff.cuni.cz (lindat.mff.cuni.cz)|195.113.20.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 355216681 (339M) [application/x-gzip]\n",
      "Saving to: ‘ud-treebanks-v2.5.tgz’\n",
      "\n",
      "ud-treebanks-v2.5.t 100%[===================>] 338.76M  3.21MB/s    in 1m 54s  \n",
      "\n",
      "2024-07-18 14:21:25 (2.98 MB/s) - ‘ud-treebanks-v2.5.tgz’ saved [355216681/355216681]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This cell loads the Universal Dependecies Treekbank corpus. It'll download all the packages, but we'll only use the GUM\n",
    "#english package. We'll also install the conllu package, that was developed to parse data in the conLLu format, a\n",
    "#format common of linguistic annotated files. We'll also have a list variable, but now named ud_treebank.\n",
    "\n",
    "#Install conllu package, download the UD Treebanks corpus and unpack it.\n",
    "!pip install conllu\n",
    "!wget https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz\n",
    "!tar zxf ud-treebanks-v2.5.tgz\n",
    "\n",
    "#The imports needed to open and parse (interpret) the conllu file. At the end we'll have a list of dicts.\n",
    "from io import open\n",
    "from conllu import parse_incr\n",
    "\n",
    "#Open the file and load the sentences to a list.\n",
    "data_file = open(\"ud-treebanks-v2.5/UD_English-GUM/en_gum-ud-train.conllu\", \"r\", encoding=\"utf-8\")\n",
    "ud_files = []\n",
    "for tokenlist in parse_incr(data_file):\n",
    "    ud_files.append(tokenlist)\n",
    "\n",
    "#Now we iterate over all samples from the corpus and retrieve the word and the pre-labeled PoS tag (upostag). This will\n",
    "#be added as a list of tuples with a list of words and a list of their respective PoS tags (in the same order).\n",
    "ud_treebank = []\n",
    "for sentence in ud_files:\n",
    "  tokens = []\n",
    "  tags = []\n",
    "  for token in sentence:\n",
    "    tokens.append(token['form'])\n",
    "    tags.append(token['upostag'])\n",
    "  ud_treebank.append((tokens, tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzzGnG10Ulv2"
   },
   "source": [
    "**Word of Caution!**\n",
    "\n",
    "Penn Treebank and UD Treebanks use *distinct tagsets*.\n",
    "\n",
    "We won't be able to interchange them unless we make a converter - also, we'll only be able to do so from Penn->UD, because Penn Treebank has tags more detailed than UD, and we won't be able to retrieve these details from the tags without a third function and a lot of effort.\n",
    "\n",
    "We'll only do that later, in our code.\n",
    "\n",
    "Let us continue with the explanation of the Tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features form Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfD5ujGijuUF"
   },
   "source": [
    "Next, we have to create a function that is able to extract features from our words. These features will be used to predict the PoS.\n",
    "\n",
    "For that,  for each word, we'll pass the sentence and word index, and we'll provide a dict with the features.\n",
    "* Is the first letter capitalised.\n",
    "* Is it the first word in the sentence?\n",
    "* Is it the last word?\n",
    "* What is the prefix of the word?\n",
    "* What is the suffix of the word?\n",
    "* Is the complete word captilised?\n",
    "* What is the previous word?\n",
    "* What is the next word?\n",
    "* Is it numeric?\n",
    "* Is it alphanumeric?\n",
    "* Is there an hyphen in the word?\n",
    "\n",
    "To explain about the feature set (can be changed, if you want), it is composed by:\n",
    "* Word: the word itself. Some words are always one PoS, others not.\n",
    "* is_first, is_last: check if it is the first or last in the sentence.\n",
    "* is_capitalized: first letter is caps? Maybe it is a proper noun...\n",
    "* is_all_caps or is_all_lower: checks for acronyms (or common words).\n",
    "* prefixes/suffixes: check word initialization/termination\n",
    "* prev_word/next_word: checks the preceding and succeding word.\n",
    "* has-hyphen: words with '-' may be adjectives.\n",
    "* is_numeric: for numbers.\n",
    "* capitals_inside: weird cases. Maybe nouns.\n",
    "\n",
    "If you're wondering, yes, this encoding WILL need a lot of memory for training (if you're not using categorical variables).\n",
    "\n",
    "And we'll have to replicate this in our main code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-IyIaTSwoo-V"
   },
   "outputs": [],
   "source": [
    "#Regex module for checking alphanumeric values.\n",
    "import re\n",
    "\n",
    "def extract_features(sentence, index):\n",
    "  return {\n",
    "      'word':sentence[index],\n",
    "      'is_first':index==0,\n",
    "      'is_last':index ==len(sentence)-1,\n",
    "      'is_capitalized':sentence[index][0].upper() == sentence[index][0],\n",
    "      'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "      'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "      'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n",
    "      'prefix-1':sentence[index][0],\n",
    "      'prefix-2':sentence[index][:2],\n",
    "      'prefix-3':sentence[index][:3],\n",
    "      'prefix-3':sentence[index][:4],\n",
    "      'suffix-1':sentence[index][-1],\n",
    "      'suffix-2':sentence[index][-2:],\n",
    "      'suffix-3':sentence[index][-3:],\n",
    "      'suffix-3':sentence[index][-4:],\n",
    "      'prev_word':'' if index == 0 else sentence[index-1],\n",
    "      'next_word':'' if index < len(sentence) else sentence[index+1],\n",
    "      'has_hyphen': '-' in sentence[index],\n",
    "      'is_numeric': sentence[index].isdigit(),\n",
    "      'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYS5r1_m6Yr9"
   },
   "source": [
    "We now prepare the dataset for use in Machine Learning algorithms.\n",
    "\n",
    "There are two steps (three, if we're doing deep learning, but that's for later) to it:\n",
    "* Defining a function to transform the corpus to a more datsetish format.\n",
    "* Then, divide the encoded data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1hiniE_wzPOC"
   },
   "outputs": [],
   "source": [
    "#Ater defining the extract_features, we define a simple function to transform our data in a more 'datasetish' format.\n",
    "#This function returns the data as two lists, one of Dicts of features and the other with the labels.\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "  X, y = [], []\n",
    "  for sentence, tags in tagged_sentences:\n",
    "    sent_word_features, sent_tags = [],[]\n",
    "    for index in range(len(sentence)):\n",
    "        sent_word_features.append(extract_features(sentence, index)),\n",
    "        sent_tags.append(tags[index])\n",
    "    X.append(sent_word_features)\n",
    "    y.append(sent_tags)\n",
    "  return X, y\n",
    "\n",
    "#We divide the set BEFORE encoding. Why? To have full sentences in training/testing sets. When we encode, we do not encode\n",
    "#a sentence, but its words instead.\n",
    "\n",
    "#First, for the Penn treebank.\n",
    "penn_train_size = int(0.8*len(penn_treebank))\n",
    "penn_training = penn_treebank[:penn_train_size]\n",
    "penn_testing = penn_treebank[penn_train_size:]\n",
    "X_penn_train, y_penn_train = transform_to_dataset(penn_training)\n",
    "X_penn_test, y_penn_test = transform_to_dataset(penn_testing)\n",
    "\n",
    "#Then, for UD Treebank.\n",
    "ud_train_size = int(0.8*len(ud_treebank))\n",
    "ud_training = ud_treebank[:ud_train_size]\n",
    "ud_testing = ud_treebank[ud_train_size:]\n",
    "X_ud_train, y_ud_train = transform_to_dataset(ud_training)\n",
    "X_ud_test, y_ud_test = transform_to_dataset(ud_testing)\n",
    "\n",
    "#Third step, vectorize datasets. For that we use sklearn DictVectorizer\n",
    "#WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxqHLWQS3PTY",
    "outputId": "f5dd9092-31c9-4d14-a864-7f85d05640e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_penn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DimhLK6235bF",
    "outputId": "3267194c-7be2-4795-960e-087b92069415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_penn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjnnJLV53TM1",
    "outputId": "4483a637-6b00-4338-ca13-2c0cfa09ef77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Pierre',\n",
       "  'is_first': True,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'P',\n",
       "  'prefix-2': 'Pi',\n",
       "  'prefix-3': 'Pier',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 're',\n",
       "  'suffix-3': 'erre',\n",
       "  'prev_word': '',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Vinken',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'V',\n",
       "  'prefix-2': 'Vi',\n",
       "  'prefix-3': 'Vink',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'en',\n",
       "  'suffix-3': 'nken',\n",
       "  'prev_word': 'Pierre',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'Vinken',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '61',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '6',\n",
       "  'prefix-2': '61',\n",
       "  'prefix-3': '61',\n",
       "  'suffix-1': '1',\n",
       "  'suffix-2': '61',\n",
       "  'suffix-3': '61',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'years',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'y',\n",
       "  'prefix-2': 'ye',\n",
       "  'prefix-3': 'year',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'rs',\n",
       "  'suffix-3': 'ears',\n",
       "  'prev_word': '61',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'old',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'ol',\n",
       "  'prefix-3': 'old',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ld',\n",
       "  'suffix-3': 'old',\n",
       "  'prev_word': 'years',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'old',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'will',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'w',\n",
       "  'prefix-2': 'wi',\n",
       "  'prefix-3': 'will',\n",
       "  'suffix-1': 'l',\n",
       "  'suffix-2': 'll',\n",
       "  'suffix-3': 'will',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'join',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'j',\n",
       "  'prefix-2': 'jo',\n",
       "  'prefix-3': 'join',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'join',\n",
       "  'prev_word': 'will',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': 'join',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'board',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'b',\n",
       "  'prefix-2': 'bo',\n",
       "  'prefix-3': 'boar',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'rd',\n",
       "  'suffix-3': 'oard',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'as',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'as',\n",
       "  'prefix-3': 'as',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'as',\n",
       "  'suffix-3': 'as',\n",
       "  'prev_word': 'board',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': 'as',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'nonexecutive',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'n',\n",
       "  'prefix-2': 'no',\n",
       "  'prefix-3': 'none',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 've',\n",
       "  'suffix-3': 'tive',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'director',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'd',\n",
       "  'prefix-2': 'di',\n",
       "  'prefix-3': 'dire',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'or',\n",
       "  'suffix-3': 'ctor',\n",
       "  'prev_word': 'nonexecutive',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Nov.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'N',\n",
       "  'prefix-2': 'No',\n",
       "  'prefix-3': 'Nov.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': 'v.',\n",
       "  'suffix-3': 'Nov.',\n",
       "  'prev_word': 'director',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '29',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '2',\n",
       "  'prefix-2': '29',\n",
       "  'prefix-3': '29',\n",
       "  'suffix-1': '9',\n",
       "  'suffix-2': '29',\n",
       "  'suffix-3': '29',\n",
       "  'prev_word': 'Nov.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': '29',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Mr.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'M',\n",
       "  'prefix-2': 'Mr',\n",
       "  'prefix-3': 'Mr.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': 'r.',\n",
       "  'suffix-3': 'Mr.',\n",
       "  'prev_word': '.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Vinken',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'V',\n",
       "  'prefix-2': 'Vi',\n",
       "  'prefix-3': 'Vink',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'en',\n",
       "  'suffix-3': 'nken',\n",
       "  'prev_word': 'Mr.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'is',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'is',\n",
       "  'prefix-3': 'is',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'is',\n",
       "  'suffix-3': 'is',\n",
       "  'prev_word': 'Vinken',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'chairman',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'ch',\n",
       "  'prefix-3': 'chai',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'an',\n",
       "  'suffix-3': 'rman',\n",
       "  'prev_word': 'is',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'of',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'of',\n",
       "  'suffix-1': 'f',\n",
       "  'suffix-2': 'of',\n",
       "  'suffix-3': 'of',\n",
       "  'prev_word': 'chairman',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Elsevier',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'E',\n",
       "  'prefix-2': 'El',\n",
       "  'prefix-3': 'Else',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'er',\n",
       "  'suffix-3': 'vier',\n",
       "  'prev_word': 'of',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'N.V.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'N',\n",
       "  'prefix-2': 'N.',\n",
       "  'prefix-3': 'N.V.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': 'V.',\n",
       "  'suffix-3': 'N.V.',\n",
       "  'prev_word': 'Elsevier',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'N.V.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Dutch',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'D',\n",
       "  'prefix-2': 'Du',\n",
       "  'prefix-3': 'Dutc',\n",
       "  'suffix-1': 'h',\n",
       "  'suffix-2': 'ch',\n",
       "  'suffix-3': 'utch',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'publishing',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'p',\n",
       "  'prefix-2': 'pu',\n",
       "  'prefix-3': 'publ',\n",
       "  'suffix-1': 'g',\n",
       "  'suffix-2': 'ng',\n",
       "  'suffix-3': 'hing',\n",
       "  'prev_word': 'Dutch',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'group',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'g',\n",
       "  'prefix-2': 'gr',\n",
       "  'prefix-3': 'grou',\n",
       "  'suffix-1': 'p',\n",
       "  'suffix-2': 'up',\n",
       "  'suffix-3': 'roup',\n",
       "  'prev_word': 'publishing',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': 'group',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_penn_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "470S2WqX3fLP",
    "outputId": "f0fcf7e2-146b-4255-8c93-09d098101d7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_penn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQWIEMVA34k_",
    "outputId": "550c2de3-c04c-44ff-b963-0d67f1b0f7e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_penn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHUJ3T__3ztZ",
    "outputId": "dcc9995f-0186-4795-ac87-80739194108d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Savin',\n",
       "  'is_first': True,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'S',\n",
       "  'prefix-2': 'Sa',\n",
       "  'prefix-3': 'Savi',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'avin',\n",
       "  'prev_word': '',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Corp.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'C',\n",
       "  'prefix-2': 'Co',\n",
       "  'prefix-3': 'Corp',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': 'p.',\n",
       "  'suffix-3': 'orp.',\n",
       "  'prev_word': 'Savin',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'reported',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'r',\n",
       "  'prefix-2': 're',\n",
       "  'prefix-3': 'repo',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'rted',\n",
       "  'prev_word': 'Corp.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': 'reported',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'third-quarter',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'thir',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'er',\n",
       "  'suffix-3': 'rter',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'net',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'n',\n",
       "  'prefix-2': 'ne',\n",
       "  'prefix-3': 'net',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'et',\n",
       "  'suffix-3': 'net',\n",
       "  'prev_word': 'third-quarter',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'loss',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'l',\n",
       "  'prefix-2': 'lo',\n",
       "  'prefix-3': 'loss',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ss',\n",
       "  'suffix-3': 'loss',\n",
       "  'prev_word': 'net',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'of',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'of',\n",
       "  'suffix-1': 'f',\n",
       "  'suffix-2': 'of',\n",
       "  'suffix-3': 'of',\n",
       "  'prev_word': 'loss',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'of',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '35.2',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '3',\n",
       "  'prefix-2': '35',\n",
       "  'prefix-3': '35.2',\n",
       "  'suffix-1': '2',\n",
       "  'suffix-2': '.2',\n",
       "  'suffix-3': '35.2',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '35.2',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'or',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'or',\n",
       "  'prefix-3': 'or',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'or',\n",
       "  'suffix-3': 'or',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '31',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '3',\n",
       "  'prefix-2': '31',\n",
       "  'prefix-3': '31',\n",
       "  'suffix-1': '1',\n",
       "  'suffix-2': '31',\n",
       "  'suffix-3': '31',\n",
       "  'prev_word': 'or',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'cents',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'ce',\n",
       "  'prefix-3': 'cent',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ts',\n",
       "  'suffix-3': 'ents',\n",
       "  'prev_word': '31',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': 'cents',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'share',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'sh',\n",
       "  'prefix-3': 'shar',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 're',\n",
       "  'suffix-3': 'hare',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'share',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'compared',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'co',\n",
       "  'prefix-3': 'comp',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'ared',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'with',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'w',\n",
       "  'prefix-2': 'wi',\n",
       "  'prefix-3': 'with',\n",
       "  'suffix-1': 'h',\n",
       "  'suffix-2': 'th',\n",
       "  'suffix-3': 'with',\n",
       "  'prev_word': 'compared',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'year-earlier',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'y',\n",
       "  'prefix-2': 'ye',\n",
       "  'prefix-3': 'year',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'er',\n",
       "  'suffix-3': 'lier',\n",
       "  'prev_word': 'with',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'profit',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'p',\n",
       "  'prefix-2': 'pr',\n",
       "  'prefix-3': 'prof',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'it',\n",
       "  'suffix-3': 'ofit',\n",
       "  'prev_word': 'year-earlier',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'of',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'of',\n",
       "  'suffix-1': 'f',\n",
       "  'suffix-2': 'of',\n",
       "  'suffix-3': 'of',\n",
       "  'prev_word': 'profit',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'of',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '3.8',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '3',\n",
       "  'prefix-2': '3.',\n",
       "  'prefix-3': '3.8',\n",
       "  'suffix-1': '8',\n",
       "  'suffix-2': '.8',\n",
       "  'suffix-3': '3.8',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '3.8',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'or',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'or',\n",
       "  'prefix-3': 'or',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'or',\n",
       "  'suffix-3': 'or',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'one',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'on',\n",
       "  'prefix-3': 'one',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'ne',\n",
       "  'suffix-3': 'one',\n",
       "  'prev_word': 'or',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'cent',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'ce',\n",
       "  'prefix-3': 'cent',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'nt',\n",
       "  'suffix-3': 'cent',\n",
       "  'prev_word': 'one',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': 'cent',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'share',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'sh',\n",
       "  'prefix-3': 'shar',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 're',\n",
       "  'suffix-3': 'hare',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': 'share',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'A',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'A',\n",
       "  'prefix-2': 'A',\n",
       "  'prefix-3': 'A',\n",
       "  'suffix-1': 'A',\n",
       "  'suffix-2': 'A',\n",
       "  'suffix-3': 'A',\n",
       "  'prev_word': '.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'spokesman',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'sp',\n",
       "  'prefix-3': 'spok',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'an',\n",
       "  'suffix-3': 'sman',\n",
       "  'prev_word': 'A',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'for',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'f',\n",
       "  'prefix-2': 'fo',\n",
       "  'prefix-3': 'for',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'or',\n",
       "  'suffix-3': 'for',\n",
       "  'prev_word': 'spokesman',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': 'for',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Stamford',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'S',\n",
       "  'prefix-2': 'St',\n",
       "  'prefix-3': 'Stam',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'rd',\n",
       "  'suffix-3': 'ford',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'Stamford',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Conn.based',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'C',\n",
       "  'prefix-2': 'Co',\n",
       "  'prefix-3': 'Conn',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'ased',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'company',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'co',\n",
       "  'prefix-3': 'comp',\n",
       "  'suffix-1': 'y',\n",
       "  'suffix-2': 'ny',\n",
       "  'suffix-3': 'pany',\n",
       "  'prev_word': 'Conn.based',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'said',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'sa',\n",
       "  'prefix-3': 'said',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'id',\n",
       "  'suffix-3': 'said',\n",
       "  'prev_word': 'company',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '0',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '0',\n",
       "  'prefix-2': '0',\n",
       "  'prefix-3': '0',\n",
       "  'suffix-1': '0',\n",
       "  'suffix-2': '0',\n",
       "  'suffix-3': '0',\n",
       "  'prev_word': 'said',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'operations',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'op',\n",
       "  'prefix-3': 'oper',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ns',\n",
       "  'suffix-3': 'ions',\n",
       "  'prev_word': '0',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'had',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'h',\n",
       "  'prefix-2': 'ha',\n",
       "  'prefix-3': 'had',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ad',\n",
       "  'suffix-3': 'had',\n",
       "  'prev_word': 'operations',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': 'had',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'loss',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'l',\n",
       "  'prefix-2': 'lo',\n",
       "  'prefix-3': 'loss',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ss',\n",
       "  'suffix-3': 'loss',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'of',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'of',\n",
       "  'suffix-1': 'f',\n",
       "  'suffix-2': 'of',\n",
       "  'suffix-3': 'of',\n",
       "  'prev_word': 'loss',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'of',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '5.5',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '5',\n",
       "  'prefix-2': '5.',\n",
       "  'prefix-3': '5.5',\n",
       "  'suffix-1': '5',\n",
       "  'suffix-2': '.5',\n",
       "  'suffix-3': '5.5',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '5.5',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': 'for',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'f',\n",
       "  'prefix-2': 'fo',\n",
       "  'prefix-3': 'for',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'or',\n",
       "  'suffix-3': 'for',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': 'for',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'quarter',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'q',\n",
       "  'prefix-2': 'qu',\n",
       "  'prefix-3': 'quar',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'er',\n",
       "  'suffix-3': 'rter',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ';',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ';',\n",
       "  'prefix-2': ';',\n",
       "  'prefix-3': ';',\n",
       "  'suffix-1': ';',\n",
       "  'suffix-2': ';',\n",
       "  'suffix-3': ';',\n",
       "  'prev_word': 'quarter',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'in',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'in',\n",
       "  'prefix-3': 'in',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'in',\n",
       "  'prev_word': ';',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'addition',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'ad',\n",
       "  'prefix-3': 'addi',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'tion',\n",
       "  'prev_word': 'in',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'addition',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'loss',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'l',\n",
       "  'prefix-2': 'lo',\n",
       "  'prefix-3': 'loss',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ss',\n",
       "  'suffix-3': 'loss',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'was',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'w',\n",
       "  'prefix-2': 'wa',\n",
       "  'prefix-3': 'was',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'as',\n",
       "  'suffix-3': 'was',\n",
       "  'prev_word': 'loss',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'magnified',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'ma',\n",
       "  'prefix-3': 'magn',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'fied',\n",
       "  'prev_word': 'was',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*-1',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*-',\n",
       "  'prefix-3': '*-1',\n",
       "  'suffix-1': '1',\n",
       "  'suffix-2': '-1',\n",
       "  'suffix-3': '*-1',\n",
       "  'prev_word': 'magnified',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'by',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'b',\n",
       "  'prefix-2': 'by',\n",
       "  'prefix-3': 'by',\n",
       "  'suffix-1': 'y',\n",
       "  'suffix-2': 'by',\n",
       "  'suffix-3': 'by',\n",
       "  'prev_word': '*-1',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'nonrecurring',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'n',\n",
       "  'prefix-2': 'no',\n",
       "  'prefix-3': 'nonr',\n",
       "  'suffix-1': 'g',\n",
       "  'suffix-2': 'ng',\n",
       "  'suffix-3': 'ring',\n",
       "  'prev_word': 'by',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'charges',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'ch',\n",
       "  'prefix-3': 'char',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'es',\n",
       "  'suffix-3': 'rges',\n",
       "  'prev_word': 'nonrecurring',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'totaling',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'to',\n",
       "  'prefix-3': 'tota',\n",
       "  'suffix-1': 'g',\n",
       "  'suffix-2': 'ng',\n",
       "  'suffix-3': 'ling',\n",
       "  'prev_word': 'charges',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'totaling',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '23.5',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '2',\n",
       "  'prefix-2': '23',\n",
       "  'prefix-3': '23.5',\n",
       "  'suffix-1': '5',\n",
       "  'suffix-2': '.5',\n",
       "  'suffix-3': '23.5',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '23.5',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': 'and',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'an',\n",
       "  'prefix-3': 'and',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'nd',\n",
       "  'suffix-3': 'and',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'and',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '8.2',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '8',\n",
       "  'prefix-2': '8.',\n",
       "  'prefix-3': '8.2',\n",
       "  'suffix-1': '2',\n",
       "  'suffix-2': '.2',\n",
       "  'suffix-3': '8.2',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '8.2',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': 'in',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'in',\n",
       "  'prefix-3': 'in',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'in',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'asset-valuation',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'as',\n",
       "  'prefix-3': 'asse',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'tion',\n",
       "  'prev_word': 'in',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'adjustments',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'ad',\n",
       "  'prefix-3': 'adju',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ts',\n",
       "  'suffix-3': 'ents',\n",
       "  'prev_word': 'asset-valuation',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'that',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'that',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'at',\n",
       "  'suffix-3': 'that',\n",
       "  'prev_word': 'adjustments',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'he',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'h',\n",
       "  'prefix-2': 'he',\n",
       "  'prefix-3': 'he',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'he',\n",
       "  'prev_word': 'that',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'described',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'd',\n",
       "  'prefix-2': 'de',\n",
       "  'prefix-3': 'desc',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'ibed',\n",
       "  'prev_word': 'he',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*T*-2',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 1,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*T',\n",
       "  'prefix-3': '*T*-',\n",
       "  'suffix-1': '2',\n",
       "  'suffix-2': '-2',\n",
       "  'suffix-3': 'T*-2',\n",
       "  'prev_word': 'described',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': 'as',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'as',\n",
       "  'prefix-3': 'as',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'as',\n",
       "  'suffix-3': 'as',\n",
       "  'prev_word': '*T*-2',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '``',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '`',\n",
       "  'prefix-2': '``',\n",
       "  'prefix-3': '``',\n",
       "  'suffix-1': '`',\n",
       "  'suffix-2': '``',\n",
       "  'suffix-3': '``',\n",
       "  'prev_word': 'as',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'unusual',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'u',\n",
       "  'prefix-2': 'un',\n",
       "  'prefix-3': 'unus',\n",
       "  'suffix-1': 'l',\n",
       "  'suffix-2': 'al',\n",
       "  'suffix-3': 'sual',\n",
       "  'prev_word': '``',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': 'unusual',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': \"''\",\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': \"'\",\n",
       "  'prefix-2': \"''\",\n",
       "  'prefix-3': \"''\",\n",
       "  'suffix-1': \"'\",\n",
       "  'suffix-2': \"''\",\n",
       "  'suffix-3': \"''\",\n",
       "  'prev_word': '.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'The',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'T',\n",
       "  'prefix-2': 'Th',\n",
       "  'prefix-3': 'The',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'The',\n",
       "  'prev_word': \"''\",\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'charges',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'ch',\n",
       "  'prefix-3': 'char',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'es',\n",
       "  'suffix-3': 'rges',\n",
       "  'prev_word': 'The',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'were',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'w',\n",
       "  'prefix-2': 'we',\n",
       "  'prefix-3': 'were',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 're',\n",
       "  'suffix-3': 'were',\n",
       "  'prev_word': 'charges',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'partly',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'p',\n",
       "  'prefix-2': 'pa',\n",
       "  'prefix-3': 'part',\n",
       "  'suffix-1': 'y',\n",
       "  'suffix-2': 'ly',\n",
       "  'suffix-3': 'rtly',\n",
       "  'prev_word': 'were',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'offset',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'offs',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'et',\n",
       "  'suffix-3': 'fset',\n",
       "  'prev_word': 'partly',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*-1',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*-',\n",
       "  'prefix-3': '*-1',\n",
       "  'suffix-1': '1',\n",
       "  'suffix-2': '-1',\n",
       "  'suffix-3': '*-1',\n",
       "  'prev_word': 'offset',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'by',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'b',\n",
       "  'prefix-2': 'by',\n",
       "  'prefix-3': 'by',\n",
       "  'suffix-1': 'y',\n",
       "  'suffix-2': 'by',\n",
       "  'suffix-3': 'by',\n",
       "  'prev_word': '*-1',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': 'by',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '2',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '2',\n",
       "  'prefix-2': '2',\n",
       "  'prefix-3': '2',\n",
       "  'suffix-1': '2',\n",
       "  'suffix-2': '2',\n",
       "  'suffix-3': '2',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '2',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': 'gain',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'g',\n",
       "  'prefix-2': 'ga',\n",
       "  'prefix-3': 'gain',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'gain',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'on',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'on',\n",
       "  'prefix-3': 'on',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'on',\n",
       "  'prev_word': 'gain',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': 'on',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'sale',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'sa',\n",
       "  'prefix-3': 'sale',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'le',\n",
       "  'suffix-3': 'sale',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'of',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'of',\n",
       "  'suffix-1': 'f',\n",
       "  'suffix-2': 'of',\n",
       "  'suffix-3': 'of',\n",
       "  'prev_word': 'sale',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'investments',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'in',\n",
       "  'prefix-3': 'inve',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ts',\n",
       "  'suffix-3': 'ents',\n",
       "  'prev_word': 'of',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'of',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'of',\n",
       "  'suffix-1': 'f',\n",
       "  'suffix-2': 'of',\n",
       "  'suffix-3': 'of',\n",
       "  'prev_word': 'investments',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'two',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'tw',\n",
       "  'prefix-3': 'two',\n",
       "  'suffix-1': 'o',\n",
       "  'suffix-2': 'wo',\n",
       "  'suffix-3': 'two',\n",
       "  'prev_word': 'of',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'joint',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'j',\n",
       "  'prefix-2': 'jo',\n",
       "  'prefix-3': 'join',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'nt',\n",
       "  'suffix-3': 'oint',\n",
       "  'prev_word': 'two',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'ventures',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'v',\n",
       "  'prefix-2': 've',\n",
       "  'prefix-3': 'vent',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'es',\n",
       "  'suffix-3': 'ures',\n",
       "  'prev_word': 'joint',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': 'ventures',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'he',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'h',\n",
       "  'prefix-2': 'he',\n",
       "  'prefix-3': 'he',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'he',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'said',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'sa',\n",
       "  'prefix-3': 'said',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'id',\n",
       "  'suffix-3': 'said',\n",
       "  'prev_word': 'he',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '0',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '0',\n",
       "  'prefix-2': '0',\n",
       "  'prefix-3': '0',\n",
       "  'suffix-1': '0',\n",
       "  'suffix-2': '0',\n",
       "  'suffix-3': '0',\n",
       "  'prev_word': 'said',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*T*-2',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 1,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*T',\n",
       "  'prefix-3': '*T*-',\n",
       "  'suffix-1': '2',\n",
       "  'suffix-2': '-2',\n",
       "  'suffix-3': 'T*-2',\n",
       "  'prev_word': '0',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': '*T*-2',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Revenue',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'R',\n",
       "  'prefix-2': 'Re',\n",
       "  'prefix-3': 'Reve',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'ue',\n",
       "  'suffix-3': 'enue',\n",
       "  'prev_word': '.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'declined',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'd',\n",
       "  'prefix-2': 'de',\n",
       "  'prefix-3': 'decl',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'ined',\n",
       "  'prev_word': 'Revenue',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '8',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '8',\n",
       "  'prefix-2': '8',\n",
       "  'prefix-3': '8',\n",
       "  'suffix-1': '8',\n",
       "  'suffix-2': '8',\n",
       "  'suffix-3': '8',\n",
       "  'prev_word': 'declined',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': True,\n",
       "  'capitals_inside': False},\n",
       " {'word': '%',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '%',\n",
       "  'prefix-2': '%',\n",
       "  'prefix-3': '%',\n",
       "  'suffix-1': '%',\n",
       "  'suffix-2': '%',\n",
       "  'suffix-3': '%',\n",
       "  'prev_word': '8',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'to',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'to',\n",
       "  'prefix-3': 'to',\n",
       "  'suffix-1': 'o',\n",
       "  'suffix-2': 'to',\n",
       "  'suffix-3': 'to',\n",
       "  'prev_word': '%',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'to',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '85.7',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '8',\n",
       "  'prefix-2': '85',\n",
       "  'prefix-3': '85.7',\n",
       "  'suffix-1': '7',\n",
       "  'suffix-2': '.7',\n",
       "  'suffix-3': '85.7',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '85.7',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': ',',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': ',',\n",
       "  'prefix-2': ',',\n",
       "  'prefix-3': ',',\n",
       "  'suffix-1': ',',\n",
       "  'suffix-2': ',',\n",
       "  'suffix-3': ',',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'from',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'f',\n",
       "  'prefix-2': 'fr',\n",
       "  'prefix-3': 'from',\n",
       "  'suffix-1': 'm',\n",
       "  'suffix-2': 'om',\n",
       "  'suffix-3': 'from',\n",
       "  'prev_word': ',',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '$',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '$',\n",
       "  'prefix-2': '$',\n",
       "  'prefix-3': '$',\n",
       "  'suffix-1': '$',\n",
       "  'suffix-2': '$',\n",
       "  'suffix-3': '$',\n",
       "  'prev_word': 'from',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '93.3',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '9',\n",
       "  'prefix-2': '93',\n",
       "  'prefix-3': '93.3',\n",
       "  'suffix-1': '3',\n",
       "  'suffix-2': '.3',\n",
       "  'suffix-3': '93.3',\n",
       "  'prev_word': '$',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'million',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'mi',\n",
       "  'prefix-3': 'mill',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'on',\n",
       "  'suffix-3': 'lion',\n",
       "  'prev_word': '93.3',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*U*',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*U',\n",
       "  'prefix-3': '*U*',\n",
       "  'suffix-1': '*',\n",
       "  'suffix-2': 'U*',\n",
       "  'suffix-3': '*U*',\n",
       "  'prev_word': 'million',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': '*U*',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'year',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'y',\n",
       "  'prefix-2': 'ye',\n",
       "  'prefix-3': 'year',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'ar',\n",
       "  'suffix-3': 'year',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'earlier',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'e',\n",
       "  'prefix-2': 'ea',\n",
       "  'prefix-3': 'earl',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'er',\n",
       "  'suffix-3': 'lier',\n",
       "  'prev_word': 'year',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': 'earlier',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Savin',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'S',\n",
       "  'prefix-2': 'Sa',\n",
       "  'prefix-3': 'Savi',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'avin',\n",
       "  'prev_word': '.',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'cited',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'ci',\n",
       "  'prefix-3': 'cite',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'ed',\n",
       "  'suffix-3': 'ited',\n",
       "  'prev_word': 'Savin',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '``',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '`',\n",
       "  'prefix-2': '``',\n",
       "  'prefix-3': '``',\n",
       "  'suffix-1': '`',\n",
       "  'suffix-2': '``',\n",
       "  'suffix-3': '``',\n",
       "  'prev_word': 'cited',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'a',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'a',\n",
       "  'prefix-2': 'a',\n",
       "  'prefix-3': 'a',\n",
       "  'suffix-1': 'a',\n",
       "  'suffix-2': 'a',\n",
       "  'suffix-3': 'a',\n",
       "  'prev_word': '``',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'general',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'g',\n",
       "  'prefix-2': 'ge',\n",
       "  'prefix-3': 'gene',\n",
       "  'suffix-1': 'l',\n",
       "  'suffix-2': 'al',\n",
       "  'suffix-3': 'eral',\n",
       "  'prev_word': 'a',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'softening',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'so',\n",
       "  'prefix-3': 'soft',\n",
       "  'suffix-1': 'g',\n",
       "  'suffix-2': 'ng',\n",
       "  'suffix-3': 'ning',\n",
       "  'prev_word': 'general',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'in',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'in',\n",
       "  'prefix-3': 'in',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'in',\n",
       "  'prev_word': 'softening',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': 'in',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'demand',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'd',\n",
       "  'prefix-2': 'de',\n",
       "  'prefix-3': 'dema',\n",
       "  'suffix-1': 'd',\n",
       "  'suffix-2': 'nd',\n",
       "  'suffix-3': 'mand',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'for',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'f',\n",
       "  'prefix-2': 'fo',\n",
       "  'prefix-3': 'for',\n",
       "  'suffix-1': 'r',\n",
       "  'suffix-2': 'or',\n",
       "  'suffix-3': 'for',\n",
       "  'prev_word': 'demand',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'office',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'o',\n",
       "  'prefix-2': 'of',\n",
       "  'prefix-3': 'offi',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'ce',\n",
       "  'suffix-3': 'fice',\n",
       "  'prev_word': 'for',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'products',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'p',\n",
       "  'prefix-2': 'pr',\n",
       "  'prefix-3': 'prod',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ts',\n",
       "  'suffix-3': 'ucts',\n",
       "  'prev_word': 'office',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'in',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'in',\n",
       "  'prefix-3': 'in',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'in',\n",
       "  'prev_word': 'products',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'the',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 't',\n",
       "  'prefix-2': 'th',\n",
       "  'prefix-3': 'the',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 'he',\n",
       "  'suffix-3': 'the',\n",
       "  'prev_word': 'in',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'market',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'm',\n",
       "  'prefix-2': 'ma',\n",
       "  'prefix-3': 'mark',\n",
       "  'suffix-1': 't',\n",
       "  'suffix-2': 'et',\n",
       "  'suffix-3': 'rket',\n",
       "  'prev_word': 'the',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'segments',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 's',\n",
       "  'prefix-2': 'se',\n",
       "  'prefix-3': 'segm',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'ts',\n",
       "  'suffix-3': 'ents',\n",
       "  'prev_word': 'market',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'in',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'i',\n",
       "  'prefix-2': 'in',\n",
       "  'prefix-3': 'in',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'in',\n",
       "  'prev_word': 'segments',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'which',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'w',\n",
       "  'prefix-2': 'wh',\n",
       "  'prefix-3': 'whic',\n",
       "  'suffix-1': 'h',\n",
       "  'suffix-2': 'ch',\n",
       "  'suffix-3': 'hich',\n",
       "  'prev_word': 'in',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'Savin',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'S',\n",
       "  'prefix-2': 'Sa',\n",
       "  'prefix-3': 'Savi',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'in',\n",
       "  'suffix-3': 'avin',\n",
       "  'prev_word': 'which',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': 'competes',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': 'c',\n",
       "  'prefix-2': 'co',\n",
       "  'prefix-3': 'comp',\n",
       "  'suffix-1': 's',\n",
       "  'suffix-2': 'es',\n",
       "  'suffix-3': 'etes',\n",
       "  'prev_word': 'Savin',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False},\n",
       " {'word': '*T*-1',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': False,\n",
       "  'is_alphanumeric': 1,\n",
       "  'prefix-1': '*',\n",
       "  'prefix-2': '*T',\n",
       "  'prefix-3': '*T*-',\n",
       "  'suffix-1': '1',\n",
       "  'suffix-2': '-1',\n",
       "  'suffix-3': 'T*-1',\n",
       "  'prev_word': 'competes',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': True,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': True},\n",
       " {'word': '.',\n",
       "  'is_first': False,\n",
       "  'is_last': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix-1': '.',\n",
       "  'prefix-2': '.',\n",
       "  'prefix-3': '.',\n",
       "  'suffix-1': '.',\n",
       "  'suffix-2': '.',\n",
       "  'suffix-3': '.',\n",
       "  'prev_word': '*T*-1',\n",
       "  'next_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False,\n",
       "  'capitals_inside': False}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_penn_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFc51jNtDptW"
   },
   "source": [
    "# Training a Tagger\n",
    "\n",
    "Now, we can train supervised machine learning algorithms to PoS Tagging.\n",
    "\n",
    "We'll use the Conditional Random Fields (CRF) algorithm. Here's a brief explanation:\n",
    "\n",
    "* **CRF**: A variation of Markov Random Field. Okay, that might not have helped. It is a discriminative model that, in a quick summary, evaluates the probabilities that a set of states are dependant or not between themselves based on a set of observations. In this case, it evaluates the probabilities that a word observed in a context (defined by the above mentioned features) belongs to a specific PoS. In training time, it takes what is the best state given the set of current observations and probabilities.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://miro.medium.com/max/681/1*8hOWH7YF5INMF2OPhKjVxA.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Want more math? Read this: https://towardsdatascience.com/conditional-random-fields-explained-e5b8256da776\n",
    "\n",
    "So, to achieve this, we'll use scikit learn (sklearn) and a sklearn compatible crf suite (skleran_crfsuit). If you don't know what is sklearn, [read this](https://scikit-learn.org/stable/getting_started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHTkotyWpd28",
    "outputId": "f750999b-af01-42e5-b9af-abad720b5d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn_crfsuite\n",
      "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting python-crfsuite>=0.9.7 (from sklearn_crfsuite)\n",
      "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.2.2)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.5.0)\n",
      "Installing collected packages: python-crfsuite, sklearn_crfsuite\n",
      "Successfully installed python-crfsuite-0.9.10 sklearn_crfsuite-0.5.0\n",
      "Started training on Penn Treebank corpus!\n",
      "Finished training on Penn Treebank corpus!\n",
      "Started training on UD corpus!\n",
      "Finished training on UD corpus!\n"
     ]
    }
   ],
   "source": [
    "#Ignoring some warnings for the sake of readability.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#First, install sklearn_crfsuite, as it is not preloaded into Colab.\n",
    "!pip install sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "#This loads the model. Specifics are:\n",
    "#algorithm: methodology used to check if results are improving. Default is lbfgs (gradient descent).\n",
    "#c1 and c2:  coefficients used for regularization.\n",
    "#max_iterations: max number of iterations (DUH!)\n",
    "#all_possible_transitions: since crf creates a \"network\", of probability transition states,\n",
    "#this option allows it to map even \"connections\" not present in the data.\n",
    "penn_crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "#The fit method is the default name used by Machine Learning algorithms to start training.\n",
    "print(\"Started training on Penn Treebank corpus!\")\n",
    "penn_crf.fit(X_penn_train, y_penn_train)\n",
    "print(\"Finished training on Penn Treebank corpus!\")\n",
    "\n",
    "#Same for UD\n",
    "ud_crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "print(\"Started training on UD corpus!\")\n",
    "ud_crf.fit(X_ud_train, y_ud_train)\n",
    "print(\"Finished training on UD corpus!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQvig1nQBcbA"
   },
   "source": [
    "# Checking the Results\n",
    "\n",
    "For that, we'll use a score method named balanced f-score. This score takes into account *precision* and *recall*.\n",
    "\n",
    "* **precision**: Considering the universe of tagged words, how many were correctly tagged?\n",
    "* **recall**: Considering the universe of correct tags, how many words were really correctly tagged?\n",
    "\n",
    "The distinction is in the direction you look. Precision looks at all tagged words to find how many are ok; Recall looks at correct tags to find how many were able to be \"guessed\".\n",
    "\n",
    "F-score is then calculated using these two. I won't go into the maths of it.  If you want,\n",
    "* You can read the wikipedia article here: https://en.wikipedia.org/wiki/F1_score\n",
    "* Or watch a neat simple video here: https://www.youtube.com/watch?v=j-EB6RqqjGI&ab_channel=CodeEmporium\n",
    "\n",
    "Also, here's the wikipedia image to help you understand:\n",
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png\"/>\n",
    "</div>\n",
    "\n",
    "We won't go into the computations either. Let the package do its thing (after all, we're interested in NLP now, not in statistics):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTlJwNkF_0zs",
    "outputId": "d00c8423-e72d-4708-eb3b-9d1951b1683f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Penn ##\n",
      "F1 score on Test Data\n",
      "0.9668646324625245\n",
      "F1 score on Training Data \n",
      "0.9936643188628935\n",
      "Class wise score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NNP      0.952     0.963     0.957      1213\n",
      "           ,      1.000     1.000     1.000       592\n",
      "          CD      1.000     0.999     0.999       683\n",
      "         NNS      0.964     0.986     0.975       740\n",
      "          JJ      0.879     0.912     0.895       731\n",
      "          MD      0.993     1.000     0.996       135\n",
      "          VB      0.980     0.946     0.963       313\n",
      "          DT      0.992     0.993     0.992      1062\n",
      "          NN      0.962     0.955     0.958      1899\n",
      "          IN      0.981     0.980     0.981      1285\n",
      "           .      1.000     1.000     1.000       509\n",
      "         VBZ      0.958     0.936     0.947       219\n",
      "         VBG      0.936     0.876     0.905       185\n",
      "          CC      1.000     0.997     0.998       287\n",
      "         VBD      0.965     0.945     0.955       492\n",
      "         VBN      0.917     0.907     0.912       279\n",
      "      -NONE-      0.998     1.000     0.999       871\n",
      "          RB      0.912     0.912     0.912       296\n",
      "          TO      1.000     1.000     1.000       298\n",
      "         PRP      1.000     1.000     1.000       150\n",
      "         RBR      0.375     0.231     0.286        13\n",
      "         WDT      0.954     1.000     0.976        62\n",
      "         VBP      0.878     0.902     0.890       112\n",
      "          RP      0.667     0.720     0.692        25\n",
      "        PRP$      1.000     1.000     1.000        74\n",
      "         JJS      0.960     1.000     0.980        24\n",
      "         POS      0.992     1.000     0.996       124\n",
      "          ``      1.000     1.000     1.000        55\n",
      "          EX      0.750     1.000     0.857         3\n",
      "          ''      1.000     1.000     1.000        52\n",
      "          WP      1.000     1.000     1.000        13\n",
      "           :      1.000     1.000     1.000        49\n",
      "         JJR      0.764     0.894     0.824        47\n",
      "         WRB      1.000     0.955     0.977        22\n",
      "           $      1.000     1.000     1.000       170\n",
      "        NNPS      0.739     0.459     0.567        37\n",
      "         WP$      1.000     1.000     1.000         4\n",
      "       -LRB-      1.000     1.000     1.000        16\n",
      "       -RRB-      1.000     1.000     1.000        16\n",
      "         PDT      0.000     0.000     0.000         4\n",
      "         RBS      1.000     1.000     1.000         1\n",
      "          FW      0.000     0.000     0.000         0\n",
      "          UH      0.000     0.000     0.000         0\n",
      "         SYM      0.000     0.000     0.000         0\n",
      "          LS      0.000     0.000     0.000         0\n",
      "           #      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.967     0.967     0.967     13162\n",
      "   macro avg      0.814     0.814     0.813     13162\n",
      "weighted avg      0.967     0.967     0.967     13162\n",
      "\n",
      "## UD ##\n",
      "F1 score on Test Data \n",
      "0.9042422401050215\n",
      "F1 score on Training Data \n",
      "0.9889075355782778\n",
      "Class wise score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ      0.823     0.782     0.802       864\n",
      "        NOUN      0.878     0.898     0.888      2338\n",
      "       CCONJ      0.988     0.991     0.989       425\n",
      "       PUNCT      0.998     0.992     0.995      1552\n",
      "         ADP      0.907     0.932     0.919      1090\n",
      "       PROPN      0.370     0.944     0.531       144\n",
      "       SCONJ      0.841     0.782     0.810       385\n",
      "         AUX      0.959     0.963     0.961       675\n",
      "        VERB      0.910     0.786     0.843      1689\n",
      "         DET      0.979     0.983     0.981       996\n",
      "        PRON      0.970     0.965     0.967       990\n",
      "         NUM      0.909     0.974     0.940       154\n",
      "         ADV      0.826     0.880     0.852       560\n",
      "           X      1.000     0.067     0.125        45\n",
      "         SYM      0.545     0.600     0.571        10\n",
      "        PART      0.943     0.929     0.936       408\n",
      "        INTJ      0.800     0.500     0.615         8\n",
      "\n",
      "    accuracy                          0.903     12333\n",
      "   macro avg      0.861     0.822     0.808     12333\n",
      "weighted avg      0.913     0.903     0.904     12333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We'll use the sklearn_crfsuit own metrics to compute f1 score.\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "print(\"## Penn ##\")\n",
    "\n",
    "#First calculate a prediction from test data, then we print the metrics for f-1 using the .flat_f1_score method.\n",
    "y_penn_pred=penn_crf.predict(X_penn_test)\n",
    "print(\"F1 score on Test Data\")\n",
    "print(metrics.flat_f1_score(y_penn_test, y_penn_pred,average='weighted',labels=penn_crf.classes_))\n",
    "#For the sake of clarification, we do the same for train data.\n",
    "y_penn_pred_train=penn_crf.predict(X_penn_train)\n",
    "print(\"F1 score on Training Data \")\n",
    "print(metrics.flat_f1_score(y_penn_train, y_penn_pred_train,average='weighted',labels=penn_crf.classes_))\n",
    "\n",
    "# This presents class wise score. Helps see which classes (tags) are the ones with most problems.\n",
    "print(\"Class wise score:\")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_penn_test, y_penn_pred, labels=penn_crf.classes_, digits=3\n",
    "))\n",
    "\n",
    "#Same for UD\n",
    "print(\"## UD ##\")\n",
    "\n",
    "y_ud_pred=ud_crf.predict(X_ud_test)\n",
    "print(\"F1 score on Test Data \")\n",
    "print(metrics.flat_f1_score(y_ud_test, y_ud_pred,average='weighted',labels=ud_crf.classes_))\n",
    "y_ud_pred_train=ud_crf.predict(X_ud_train)\n",
    "print(\"F1 score on Training Data \")\n",
    "print(metrics.flat_f1_score(y_ud_train, y_ud_pred_train,average='weighted',labels=ud_crf.classes_))\n",
    "\n",
    "### Look at class wise score\n",
    "print(\"Class wise score:\")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_ud_test, y_ud_pred, labels=ud_crf.classes_, digits=3\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJUcgYacWTaa"
   },
   "source": [
    "Not too shabby!\n",
    "\n",
    "Remember that State of the Art results for Penn Treebank are at 97% f1.\n",
    "\n",
    "Now, notice how UD is worse (90%)? Probably because there aren't many tags, so less variation and less classes for probability distribution.\n",
    "\n",
    "---\n",
    "\n",
    "But, wouldn't it be better if we could see it actually working?\n",
    "\n",
    "That's what the following cell does. It also helps us understand what we'll have to implement in our main algorithm for it to work.\n",
    "\n",
    "Feel free to play with the input phrase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4rcQq-ubbuT",
    "outputId": "59c15b77-9292-47f3-e56f-cfae6b58e202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('tagger', 'NN'), ('produced', 'VBN'), ('good', 'JJ'), ('results', 'NNS')]\n",
      "[('The', 'DET'), ('tagger', 'NOUN'), ('produced', 'VERB'), ('good', 'ADJ'), ('results', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "#First, we pass the sentence and \"quickly tokenize it\" - we've already done it in our code, so I'll just mock here with a split:\n",
    "sent = \"The tagger produced good results\"\n",
    "features = [extract_features(sent.split(), idx) for idx in range(len(sent.split()))]\n",
    "\n",
    "#Then we tell the algorithm to make a prediction on a single input (sentence). I'll do once for Penn Treebank and once for UD.\n",
    "penn_results = penn_crf.predict_single(features)\n",
    "ud_results = ud_crf.predict_single(features)\n",
    "\n",
    "#These line magics are just there to make it a neaty print, making a (word, POS) style print;\n",
    "penn_tups = [(sent.split()[idx], penn_results[idx]) for idx in range(len(sent.split()))]\n",
    "ud_tups = [(sent.split()[idx], ud_results[idx]) for idx in range(len(sent.split()))]\n",
    "\n",
    "#The results come out here! Notice the difference in tags.\n",
    "print(penn_tups)\n",
    "print(ud_tups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Most likely Transition Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Transition Features \")\n",
    "len(crf.transition_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(crf.transition_features_).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(crf.transition_features_).most_common()[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Most Likely State Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of State Features \")\n",
    "len(crf.state_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(crf.state_features_).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(crf.state_features_).most_common()[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Mn831Zxbckt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Saving the Weights\n",
    "\n",
    "We will want to load this to our NLPTools, right? So we have to save the weights. This means saving the classifier we trained to be able to classify our tokens.\n",
    "\n",
    "To do it, we use Pickle, which is a Python package to save a readable binary file extension called \"pickle\". We'll later open this in our tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul2KlQu4c5-N"
   },
   "outputs": [],
   "source": [
    "#import the pickle module\n",
    "import pickle\n",
    "\n",
    "#Simply dump! Use 'wb' in open to write bytes.\n",
    "\n",
    "penn_filename = 'penn_treebank_crf_postagger.sav'\n",
    "pickle.dump(penn_crf, open(penn_filename, 'wb'))\n",
    "\n",
    "ud_filename = 'ud_crf_postagger.sav'\n",
    "pickle.dump(ud_crf, open(ud_filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O2F5HijfWc8"
   },
   "source": [
    "To open the file, we just have to import the module and read the file using:\n",
    "\n",
    "`model = pickle.load(open(filename, 'rb'))`\n",
    "\n",
    "Great, we now have pickle files that can be loaded in our tool. Just download them using the lefthand file explorer and we're good to go!\n",
    "See you back at the article!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
