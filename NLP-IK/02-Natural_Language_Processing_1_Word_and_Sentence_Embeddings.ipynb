{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki6jcwCjGwk1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo4S8f58Gwk9"
      },
      "source": [
        "# Word Embeddings\n",
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYyDkHMSGwk_"
      },
      "outputs": [],
      "source": [
        "# First, you'll need to install gensim\n",
        "# !pip install gensim\n",
        "\n",
        "# Import the necessary modules\n",
        "\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0FCHyZ0GwlB",
        "outputId": "381e4685-ea34-465b-c6b9-b68c9645dbd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
          ]
        }
      ],
      "source": [
        "print(common_texts) #Sample Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obAnQvieGwlE"
      },
      "source": [
        " Word2vec accepts several parameters that affect both training speed and quality.\n",
        "\n",
        "One of them is for pruning the internal dictionary. Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there’s not enough data to make any meaningful training on those words, so it’s best to ignore them:\n",
        "\n",
        "`model = Word2Vec(sentences, min_count=10)  # default value is 5`\n",
        "\n",
        "A reasonable value for min_count is between 0-100, depending on the size of your dataset.\n",
        "\n",
        "Another parameter is the size of the NN layers, which correspond to the “degrees” of freedom the training algorithm has:\n",
        "\n",
        "`model = Word2Vec(sentences, vector_size=200)  # default value is 100`\n",
        "\n",
        "Bigger size values require more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other hyper-parameters:\n",
        "\n",
        "*   size: window=window_size for capturing context for target word\n",
        "\n",
        "*   sample: The threshold for configuring which higher-frequency words are randomly down sampled, useful range is (0, 1e-5)\n",
        "\n",
        "*   workers: Use these many worker threads to train the model (faster training with multicore machines)\n",
        "\n",
        "*   sg: Training algorithm: skip-gram if sg=1, otherwise CBOW.\n",
        "\n",
        "*   iter: Number of iterations (epochs) over the corpus.\n"
      ],
      "metadata": {
        "id": "eHJa7t_dVlNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enTdB5hPGwlH"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences=common_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "#Here, vector_size = 10 denotes the length of embedding\n",
        "model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiL5GEqaGwlJ"
      },
      "source": [
        "If you save the model you can continue training it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVn5-eMTGwlK"
      },
      "outputs": [],
      "source": [
        "# load the saved model\n",
        "model = Word2Vec.load(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcwKsP0OGwlM"
      },
      "source": [
        "The trained word vectors are stored in a KeyedVectors instance, as model.wv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ-S-El4GwlO",
        "outputId": "68ad5b3f-314c-49ab-df8a-13eaeee34e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00410223 -0.08368949 -0.05600012  0.07104538  0.0335254   0.0722567\n",
            "  0.06800248  0.07530741 -0.03789154 -0.00561806]\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Get the embeddings for the word 'human'\n",
        "embedding = model.wv['human']\n",
        "\n",
        "print(embedding)\n",
        "print(len(embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zWtQqtrGwlP",
        "outputId": "4b92b52d-e0dc-4703-9b87-c68f1b187571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('graph', 0.3586882948875427), ('system', 0.22743132710456848), ('time', 0.1153423935174942)]\n"
          ]
        }
      ],
      "source": [
        "# Get the most similar words (having the most similar embeddings)\n",
        "similar_words = model.wv.most_similar('human',topn = 3) #topn denotes the top 3 similar words\n",
        "print(similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrllmXJqGwlR"
      },
      "outputs": [],
      "source": [
        "# Store just the words + their trained embeddings.\n",
        "word_vectors = model.wv\n",
        "word_vectors.save(\"word2vec.wordvectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFj9xhGgGwlS",
        "outputId": "0918d36c-49e3-432c-e8a8-92a0e4a9c704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0163195 ,  0.00189972,  0.03474648,  0.00217841,  0.09621626,\n",
              "        0.05062076, -0.08919986, -0.0704361 ,  0.00901718,  0.06394394],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load back with memory-mapping = read-only, shared across processes.\n",
        "from gensim.models import KeyedVectors\n",
        "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
        "wv['computer']  # Get numpy vector embedding for 'computer'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hme83l4GwlT"
      },
      "source": [
        "### Refer to the link below for more details:\n",
        "https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM6M_oYAGwlU"
      },
      "source": [
        "# Gensim comes with several already pre-trained models, in the Gensim-data repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEvTubVQGwlV",
        "outputId": "33955850-7754-4053-ee3e-8ea197c34ba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "# Show all available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gl5eMeCGwlV",
        "outputId": "06eae83e-28bc-4011-8d38-e365750d6838",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7fb4ad042d40>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Download the \"glove-twitter-25\" embeddings\n",
        "# Pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased.\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
        "glove_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcG_GXoUGwlX",
        "outputId": "6e1585d0-fd33-41dd-cca0-e6589e67dab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('facebook', 0.948005199432373),\n",
              " ('tweet', 0.9403423070907593),\n",
              " ('fb', 0.9342358708381653),\n",
              " ('instagram', 0.9104824066162109),\n",
              " ('chat', 0.8964964747428894),\n",
              " ('hashtag', 0.8885937333106995),\n",
              " ('tweets', 0.8878158330917358),\n",
              " ('tl', 0.8778461217880249),\n",
              " ('link', 0.8778210878372192),\n",
              " ('internet', 0.8753897547721863)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Use the downloaded vectors as usual:\n",
        "glove_vectors.most_similar('twitter')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors['queen']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ZGQUmaq22E",
        "outputId": "99afb416-13a0-45c4-d880-cbd80d4bbd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.1266  , -0.52064 ,  0.45565 ,  0.21079 , -0.05081 , -0.65158 ,\n",
              "        1.1395  ,  0.69897 , -0.20612 , -0.71803 , -0.02811 ,  0.10977 ,\n",
              "       -3.3089  , -0.49299 , -0.51375 ,  0.10363 , -0.11764 , -0.084972,\n",
              "        0.02558 ,  0.6859  , -0.29196 ,  0.4594  , -0.39955 , -0.40371 ,\n",
              "        0.31828 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvnW9NgBGwla"
      },
      "source": [
        "# Document/Sentence Embeddings\n",
        "Paragraph, Sentence, and Document embeddings\n",
        "\n",
        "## Doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If7cxdRzGwlj",
        "outputId": "2e4774f7-3cbf-4f09-b4db-dd5d12c318f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Embeddings:\n",
            "[array([ 0.01821357,  0.02594667,  0.04038974,  0.03291611, -0.02587991,\n",
            "       -0.00589329,  0.00655008, -0.04827507,  0.04916208,  0.00108263],\n",
            "      dtype=float32), array([ 4.4840805e-02, -2.6123403e-02, -6.1434133e-05,  5.7107997e-03,\n",
            "       -4.8215697e-03,  4.9016461e-02, -2.1489849e-02, -2.5502274e-02,\n",
            "       -4.1926078e-02, -4.2932746e-03], dtype=float32), array([ 0.00927534, -0.00318728, -0.02852724, -0.02131686, -0.0186496 ,\n",
            "        0.02670106, -0.03630985, -0.00882227,  0.03916181,  0.00347719],\n",
            "      dtype=float32), array([-0.04103417, -0.03968335, -0.01021319, -0.01521414,  0.01974463,\n",
            "       -0.00486366, -0.01671924,  0.00102357, -0.0154149 ,  0.01048233],\n",
            "      dtype=float32), array([-0.00556436,  0.01828448, -0.0213437 ,  0.02301039, -0.01649704,\n",
            "        0.01762558, -0.04732837,  0.01559526, -0.03176651, -0.01864625],\n",
            "      dtype=float32)]\n",
            "\n",
            "Shape:\n",
            "(5, 10)\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Define your sentences (example)\n",
        "sentences = [\"this is the first sentence\", \"this is the second sentence\", \"yet another sentence\", \"one more sentence\", \"and the final sentence\"]\n",
        "\n",
        "# Tag the sentences for training\n",
        "tagged_data = [TaggedDocument(words=sentence.split(), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
        "\n",
        "# Train the model\n",
        "model = Doc2Vec(tagged_data, vector_size=10, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Get the embeddings for the sentences\n",
        "sentence_vectors = [model.infer_vector(sentence.split()) for sentence in sentences]\n",
        "# The infer_vectors expects the input as a list of words (nltk.word_tokenize())\n",
        "\n",
        "print(\"Sentence Embeddings:\")\n",
        "print(sentence_vectors) #Embeddings of the sentences\n",
        "\n",
        "import numpy as np\n",
        "print(\"\\nShape:\")\n",
        "print(np.array(sentence_vectors).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF1RI8k8Gwlk",
        "outputId": "534cac34-178b-4038-f0f0-335d1da23a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01821357,  0.02594667,  0.04038974,  0.03291611, -0.02587991,\n",
              "       -0.00589329,  0.00655008, -0.04827507,  0.04916208,  0.00108263],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "sentence_vectors[0] #the first embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XesFtYhGwll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1253255d-74f4-47a0-f30a-cdeac8f53cc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17146514"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(sentence_vectors[1].reshape(1,-1),sentence_vectors[2].reshape(1,-1))[0][0]\n",
        "#Cosine similarity between embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DKoWDb-Gwln",
        "outputId": "0240928c-30e0-4088-f2b2-cabd19e09ef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9999998 , -0.09469897,  0.09594274, -0.6239071 , -0.28149876],\n",
              "       [-0.09469897,  1.        ,  0.17146516, -0.04729198,  0.34938085],\n",
              "       [ 0.09594274,  0.17146516,  1.        , -0.02119621,  0.19021074],\n",
              "       [-0.6239071 , -0.04729198, -0.02119621,  1.0000001 ,  0.01172717],\n",
              "       [-0.28149876,  0.34938085,  0.19021074,  0.01172717,  0.99999994]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Find the similarity between all the sentences\n",
        "similarity = cosine_similarity(sentence_vectors)\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_8s2ff2Gwlo",
        "outputId": "3eca0f63-8d14-4364-9ccd-ea797b0a2807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence --> this is the first sentence\n",
            "Most Similar Sentence --> yet another sentence\n",
            "Cosine Simialrity: 0.09594278\n"
          ]
        }
      ],
      "source": [
        "#Find the most similar sentence to the first sentence (at index = 0)\n",
        "ind = 0  # The index of the sentence for which you want to find the most similar sentence\n",
        "max = -1 # This will store the cosine_similarity of the most similar document\n",
        "print(\"Input Sentence -->\", sentences[ind])\n",
        "for i in range(np.array(sentence_vectors).shape[0]):\n",
        "    if i != ind:\n",
        "        if max < cosine_similarity(sentence_vectors[i].reshape(1,-1),sentence_vectors[ind].reshape(1,-1))[0][0]:\n",
        "            max = cosine_similarity(sentence_vectors[i].reshape(1,-1),sentence_vectors[ind].reshape(1,-1))[0][0]\n",
        "            s_ind = i\n",
        "\n",
        "print(\"Most Similar Sentence -->\", sentences[s_ind])\n",
        "print(\"Cosine Simialrity:\", max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZynnc0BGwlp"
      },
      "source": [
        "#### More about Doc2vec here:\n",
        "https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S58AcfXwj0Wo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}