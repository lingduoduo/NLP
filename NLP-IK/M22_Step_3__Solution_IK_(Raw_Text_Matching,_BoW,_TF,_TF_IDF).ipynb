{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3Ws0bcs4B3m"
      },
      "source": [
        "# Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDA5c6zA4dcU",
        "outputId": "779f1ce6-68dd-407d-c570-c56244e82e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlufkUp34ghR",
        "outputId": "2fbf6680-f34b-4af0-c6b7-ed1ec6529737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tYn7xoK4jwP",
        "outputId": "e3fe696f-7e98-46d3-a990-aee7258fef10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRrxjCET4r_v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "csv_path = '/IK_rr_DataFrame.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "# A DataFrame containing the parsed text for all research articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NkW7i7Wl4r_v",
        "outputId": "7f0e9c46-7155-4d00-ca0e-26d73f0e30d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             FileName       Author  \\\n",
              "0            Controlled synthesis.pdf  Amit Saxena   \n",
              "1       High Oxygen Nanocomposite.pdf  Amit Saxena   \n",
              "2                    Cutting Edge.pdf  Amit Saxena   \n",
              "3      Maternal and Fetal Factors.pdf  Amit Saxena   \n",
              "4  Opposing Actions of Fibroblast.pdf  Amit Saxena   \n",
              "\n",
              "                                                Text  \n",
              "0  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  \n",
              "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  \n",
              "2  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  \n",
              "3  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  \n",
              "4  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21e024f0-157d-4700-9e4b-87aba057a60b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>Author</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Controlled synthesis.pdf</td>\n",
              "      <td>Amit Saxena</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>High Oxygen Nanocomposite.pdf</td>\n",
              "      <td>Amit Saxena</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cutting Edge.pdf</td>\n",
              "      <td>Amit Saxena</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maternal and Fetal Factors.pdf</td>\n",
              "      <td>Amit Saxena</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Opposing Actions of Fibroblast.pdf</td>\n",
              "      <td>Amit Saxena</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21e024f0-157d-4700-9e4b-87aba057a60b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21e024f0-157d-4700-9e4b-87aba057a60b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21e024f0-157d-4700-9e4b-87aba057a60b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb094f20-4a98-45cf-8fcc-050d30586e7a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb094f20-4a98-45cf-8fcc-050d30586e7a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb094f20-4a98-45cf-8fcc-050d30586e7a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttxJcdvP7BKm"
      },
      "source": [
        "# Input the TEST PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCJ9x3xl63CB"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "#Test pdf for evaluation\n",
        "pdf_path = \"/Dataset-IK/Amit Saxena/A Review of Clustering Techniques.pdf\"\n",
        "text_column = \"PDF\"\n",
        "\n",
        "k = 5 #Retrieve top k authors\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['@',\"'\",'.','\"','/','!',',',\"'ve\",\"...\",\"n't\",'$',\"'s\",'©','''\"''',\"''\",'..','&','*',';','”','``',':','#','!','-','–','?','%',\"'d\",\"'m\",'+','++','(',')','()'])\n",
        "stop_words = set(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8zOsSHLclmN",
        "outputId": "fafc83d3-d03e-4637-99be-e9f7eab5f51c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4pg7rai7m8A"
      },
      "source": [
        "# Defining functions for subtasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_4pd0Cz7dp1"
      },
      "outputs": [],
      "source": [
        "def preprocess_test_document(pdf_path):\n",
        "    test_document_text = extract_text_from_pdf(pdf_path)\n",
        "    preprocessed_text = preprocess_text(test_document_text)\n",
        "    return preprocessed_text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    text = re.sub('http[s]?://\\S+', '', text)\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "    text = [word for word in text if len(word) > 2]\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as pdf_file:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            pdf_text = ''\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                pdf_text += page.extract_text()\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing file '{pdf_path}': {e}\")\n",
        "        return ''\n",
        "    return pdf_text\n",
        "\n",
        "def preprocess_csv_file(csv_path, text_column):\n",
        "    data = pd.read_csv(csv_path)\n",
        "    csv_text_data = data[text_column].tolist()\n",
        "    preprocessed_texts = [preprocess_text(text) for text in csv_text_data]\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z_HztkU84r_x",
        "outputId": "ca74cf71-1e34-41c0-d797-2540a2ca6ad6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Dataset-IK/Amit Saxena/A Review of Clustering Techniques.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "pdf_path #Path to a sample PDF file for matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0WzgIGoj4r_x",
        "outputId": "134f5e2e-bfb8-46c1-a0b8-76402590023e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'review clustering techniques developments amit saxena mukesh prasad akshansh gupta neha bharill prakash patel aruna tiwari meng joo weiping ding chin teng lin department computer science guru ghasidas vishwavidyal aya bilaspur india centre artificial intelligence university technology sydney sydney australia school computational integrative sciences jawaharlal nehru university new delhi india department computer science engineering ndian institute technology indore india school electrical electronic engineering nanyang technological university singapore school computer technology nantong university nantong china abstract paper presents comprehensive study clustering exiting methods developments made various times clustering defined unsupervised learning objects grouped basis similarity inherent among different methods clustering objects hierarchical partitional grid density based model based approaches used methods discussed respective state art applicability measures similarity well evaluation criteria central components clustering also presented paper applications clustering fields like image segmentation object character recognition data mining highlighted keywords unsupervised learning clustering data mining pattern recognition similarity measures introduction grouping objects required various purposes different areas engineering science technology humanities medical science daily life take instance people suffering particular disease symptoms common placed group tagged label usually name disease evidently people possessing symptoms hence disease placed group patients grouped disease treated accordingly patients belonging group handled differently therefore essential medical expert diagnose symptoms patient correctly placed wrong group whenever find labeled object place group label rather trivial task labels given advance however many occasions labeling information provided adva nce group objects basis similarity instances represent wide range problems occurring analysis data generic terms cases dealt scope classification precisely first case class label object given advance termed supervised classification whereas case class label tagged object advance termed unsupervised classification tremendous amount ork supervised classification evidently reported literature widely main purpose behind study classification develop tool algorithm used pre dict class unknown object labeled tool algorithm called classifier objects classification process commonly represented instances patterns pattern consists number features also called attributes classification accuracy classifier judged fact many testing patterns classified correctly rich amount work supervised classification pioneer supervised classificati algorithms found neural etworks fuzzy sets pso rough sets decision tree bayes classifiers etc contrary supervised classification given labeled patterns unsupervised classification differs manner label assigned pattern unsupervised classification commonly known clustering learning operation central process classification supervised unsupervised used paper interchangeably spirit clustering essential component various data analysis machine learning based applications like regression prediction data mining etc according rokach clustering divides data patterns subsets way similar patterns clustered together patterns thereby managed well formed evaluation designates population sampled formally conventionally clustering structure represented set subsets means obviously instance belongs exactly one subset belong subset clustering objects also applicable charactering key features people recognizing basis similarity general may divide people different cluster basis gender height weight color vocal physical appearances ence clustering embraces several interdisciplinary areas mathematics statistics biology genetics use various terminology explain topologies formed using clustering analysis technique example rom biological taxonomies medical syndromes genetic genotypes manufacturing group technology topics identical problem creat groups instances assign instance appropriate groups clustering onsidered difficult supervised classification label attached patterns clustering given label case supervised classification becomes clue grouping data objects whole whereas case lustering becomes difficult decide group pattern belong absence label several parameters features could considered fit clustering curse dimensionality add crisis high dimensionality leads high computational cost also affects consistency algorithms although feature selection methods reported solution sizes databases small large large also guide clustering criteria jain illustrate main aim data clustering search real grouping set instances points objects webster merriam webster online dictionary explains clustering statistical classi fication method finding whether patterns comes various groups making quantitative comparisons different features evident discussion similarity central factor cluster hence clustering proces natural grouping data based inherent similarity discovered clustering cases number clusters formed specified user numeric type data available represent features patterns group way extract information pertaining relationship among patterns make use numeric arithmetic features objects represented numeric values common approach define similarity taken measure distance among patterns lower distance euclidean distance two objects higher similarity vice versa overall paper organized follows various clustering techniques discussed section section presents measures similarity differentiating patterns section variants clustering methods presented evaluation criteria clustering techniques applied different problems provided section section highlights emerging applications clustering section describes clustering method select different applications followed conclusions section due wide range topics subject omission unbalancing certain topics presented paper cannot denied objective paper however present comprehensive timeline study clustering concepts comparisons existing techniques important applications clustering techniques section discuss various clustering approaches inherent techniques reason different clustering approaches towards various techniques due fact precise definition notion cluster different clustering approaches proposed uses different inclusion principle fraley raftery suggested dividing clustering approaches two different groups hierarchi cal partitioning techniques han kamber suggested following three additional categories applying clustering techniques density based methods model based methods grid based methods alternative categorization based induc tion principle different clustering approa ches presented castro however number clusters available dataset divided decided users judiciously using approaches including heuristic trial error evolutionary user decides suitable number accuracy judged intra cluster distance high otherwise accuracy come low fig shows taxonomy clustering approaches fig taxonomy clustering app roaches hierarchical clustering methods hierarchical clustering methods clusters formed iteratively dividing patterns using top bottom approach two forms hierarchical method namely agglomerative divisi hierarchical clustering agglomerative follows bottom approach builds clusters starting single object merging atomic clusters larger larger clusters objects finally lying single cluster otherwise certain termination conditions satisfied divisive hierarchical clustering follows top approach break cluster containing objects smaller clusters object form cluster satisfies certain termination conditions hierarchical ethods usually lead formation dend rogram shown fig fig hierarchical clustering dend rogram hierarchical clustering methods could grouped three categories based similarity measure linkages summarized following sections single linkage clustering type clustering often called connectedness minimum method nearest neighbour method singl linkage clustering link two clusters made single element pair namely two elements one cluster closest clustering distance two clusters determined nearest distance member one cluster member cluster also defines similarity data equipped similarities similarity pair clusters considered equal greatest similarity member one cluster member cluster fig shows mapping single linkage clustering criteria two sets clusters follow min fig mapping single linkage clustering complete linkage clustering complete linkage clustering also called diameter maximum method furthest neighbour method distance two clusters determined longest distance fro member one cluster member cluster fig shows mapping complete linkage clustering criteria two sets clusters follow max fig mapping complete linkage clustering average linkage clustering average linkage clustering also known minimum variance method distance two clusters determined average distance member one luster member cluster fig shows mapping average linkage clustering criteria two sets clusters follow bab fig mapping average linkage clustering steps agglomerative divisive clustering steps agglomerative lustering steps divisive clustering make point separate cluster clustering satisfactory merge two clusters smallest inter cluster distance end construct single cluster containing points clustering satisfactory split cluster yields two components largest inter cluster distance end common criticism classical algorithms lack robustness hence sensitive noise outliers object assigned cluster considered means algorithms capable correcting possible previous misclassification computational complexity algorithms least high cost limits application large scale data sets disadvantages include tendency form spherical shapes reversal phenomenon normal hier archical structure distorte requirement large scale datasets recent years algorithms also enriched new techniques modifications classical methods presented following section enhanced hierarchical lustering main deficienc hierarchical clustering two points clusters linked cannot move cluster hierarchy algorithms use hierarchical clustering enhancements given balanced iterative reducing clustering sing hierarchies birch birch contains idea luster features triple number data objects cluster linear sum attribute values objects cluster sum squares attribute values objects cluster stored tree form need keep tuples clusters main memory tuples main motivations rch lie two aspects ability deal large data sets robustness outliers also birch achieve comutational complexity clustering sing representatives cure cure clustering technique dealing wit large scale databases robust towards outliers accepts clusters various shapes sizes performance good data set birch cure handle outliers well cure clustering quality better birch reverse terms time complexity birch better cure attains com putational complexity compared cure logn iii rock rock applied categorical data sets follows agglomerative hierarchical clustering algorithm based number links two records links capture number records similar algorithm use distance function cure also proposed rock uses random sample strategy handle large datasets chameleon chameleon hierarchical clustering algorithm clusters merged interconnectivity closeness proximity two clusters high relative internal interconnectivity clusters closeness items within clusters one limitation chameleon known low dimensional spaces applied high dimensions table features ierarchical clustering based enhanced methods name type data complexity ability handle igh dimensional data birch numerical cure numerical logn yes rock categorical mma logn chemeleon numerical categorical nlogn logn maximum number neighbours point average number neighbours point number initial sub clusters produced graph partitioning algorithm partition clustering methods partitional clustering opposite hierarchical clustering data assign clusters without hierarchical structure optimizing criterion function common used criterion euclidean distance finds minimum distance points available clusters ass igning point cluster lgorithms studied category include mean pam clara clarans fuzzy means dbscan etc fig shows partitional clustering approach data points partitional clusters fig partitional clustering approaches means clustering means alg orithm one best known bench marked simplest clustering algorithms mostly applied solve clustering problems procedure given data set classif ied user defined number clusters main idea define centroids one cluster objective function given follows minimize jij ijxc chosen distance measure data point cluster centre fig shows flow diagram means algorithm algorithm similar means known linde buzo gray lbg algorithm suggested vector quantization signal compression context prototype vectors called code words constitute code book aims represent data reduced number elements minimizing information loss although means clustering still one popular clustering algorithms yet limitation associated means clustering include efficient universal method ide ntifying initial partitions number clusters means sensitive outliers noise even object quite far away cluster centroid still forced cluster thus distorts cluster shapes fig flow diagram means algorithm procedure means algorithm composed following steps initialization suppose decide form clusters given dataset take distinct points patterns randomly points repr esent initial group centroids centroids changing iteration clusters fixed need spend time decision choosing centroids assign object group closest centroid objects assigned recalculate positions centroids repeat steps centroids longer move produces separation objects groups metric minimized calculated fuzzy means clustering fuzzy means fcm clustering method allows one point belong two clusters unlike means one cluster assigned point method developed dunn improved bezdek procedure fuzzy means similar means based minimization following objective function ijj fuzzy partition matrix exponent controlling degree fuzzy overlap fuzzy overlap refers fuzzy boundaries clusters number data points significant membership one cluster uij degree membership cluster pattern dimension data cluster center dimension norm expressing similarity measured data center procedure fcm fcm suffers initial partition dep endence well noise outliers like means yager filev proposed mountain method estimate cluster centers initial partition gath geva addressed initialization problem dynamically adding cluster prototypes located space represented well previously generated centers set value number cluster select initial cluster prototype compute distance ijxv objects prototypes comp uter elements fuzzy partition matrix ilxv uxv compute cluster prototypes iux stop convergence attain number iterations exceeds given limit otherwise step changing proximity distance improve performance fcm relation outliers another approach reducing effect noise liers keller interpreted memberships compatibility points class prototype rather degree membership relaxes uij uij results possibilistic means clustering algorithm conditions possibilistic fuzzy partition matrix iju ijui table features partition clustering based techniques name type data complexity ability handle high dimensional data mean numerical pam numerical clara numeri cal clarans numerical fuzzy means numerical number points dataset number clusters defined means algorithms problems like defining number clusters initially susceptibility local optima sensitivity outliers memory space unknown number iteration steps required cluster fuzzy means clustering really suitable handling issues related understand ability patte rns incomplete noisy data mixed media information human interaction provide approximate solutions faster mainly used discovering association rules functional dependencies well image retrieval however time mplexity means much less fcm thus means works faster fcm advantages partition based algorithms includes relatively scalable simple uitable datasets compact spherical clusters well separated however disadvantages algorithms include poo cluster descriptors eliance user specify numbe clusters advance iii igh sensitivity initialization phase noise outliers inability deal non convex clusters varying size density measures similarities similarity objects within cluster plays important role clustering process good cluster finds maximum similarity among obj ects measure similarity cluster mainly decided distance among members conventional cluster non fuzzy member either belongs cluster wholly many clustering methods use distance measures determine similarity dissimilarity pair objects useful denote distance two instances valid distance measure symmetric obtain minimum value ideally ero case identical vectors distance measure called metric distance measure also satisfies following properties triangle inequality minkowski distance measures numeric attributes measurement distance fundamental operation unsupervised learning process smaller distance two objects closer objects assumed basis similarity family distance measures minkowski metrics distance measured following equation wher xik value variable entity xjk value variable entity popular common distance measure euclidean norm details unsupervised classification various non euclidean distances seen saxena cosine measure cosine measure popular similarity score text mining information retrieval normalized inner product cosine measure defined ijxxd pearson correlation measure correlation coefficient first discovered bravais later shown person normalized pearson correlation two vectors defined denotes average feature value dimensions extended jaccard measure strehl ghosh represented xtended jaccard measure follows ijt jxxd dice coefficient measure independently developed thorvald srensen raymond dice dice coefficient measure similar extended jaccard measure defined ijxxd choice suitable imilarity measure measures similarities applied millions appl ications clustering fact every clustering problem applies one similarity measures euclidean distance mostly applied find similarity two objects expressed numerically euclidean distance highly sensitive noi usually applied data hundreds attributes also features high values tend dominate others may applied translations non numeric objects numeric values almost nil minimum jaccard similarity coeffic ient suitable sufficiently employed documents word similarity measurement efficiency measurement program performance deal appropriately high stability failure mistake spelling occurred nevertheless metho able detect type words data sets pearson correlation usually unable detect difference two variables cosine similarity also good choice document clustering invariant rotation linear transformations variants lustering methods graph theoretic clustering raph theoretic clustering method represents clusters via graphs edges graph connect instances represented nodes well know graph theoretic algorithm based minimal spanning ree mst inconsistent edges edges whose ight case clustering length significantly larger average nea rby edge lengths another graph theoretic approach cons tructs graphs base limited neighbourhood sets raph theoretic clustering convenient represent clusters via graphs weak handling outliers especially mst well detecting overlapping clusters graph clu stering involves task dividing nodes clusters edge density higher within clusters opposed across clusters natural classic popular statistical setting evaluating solutions problem stochastic block model also referred planted partition model general graph partition problem partition nodes undirected graph equal sized groups minimize total number edges cross groups condon presented simple linear time algorithm graph partition problem analyzed random planted partition model model nodes graph partitioned groups size two nodes group connected edge probability two nodes different groups connected edge probability denotes collaborative coefficient collaborative effect dataset number cluster number datasets number patt erns dataset represents partition matrix number features euclidean distance patterns prototypes general scheme collaborative clustering sho fig demonstrates connections matrices order accomplish collaboration subsets dataset first solve problem dataset separately allow results interact globally forming colla borative process datasets collaborative fuzzy partitioning carried iterative optimization objective function shown optimization involves determination partition matrix rototypes different data sets shown fig collaborative clustering scheme two datasets collaborative clustering scheme three datasets fig collaborative clustering scheme multi objective clustering multi objective clustering many clustering approaches optimized simultaneously multi objective clustering automatic determination mock compactness clusters maximized first objective connectivity clusters maximized second objective pareto approach used optimize aforesaid two objectives simultaneously multi objective clustering ensemble moce proposed face ili uses mock along special crossov operator utilizes ensemble clustering law different clustering methods different objectives used surveys seen overlapping clustering overlapping community etection partition clustering sually indicates exclusive overlapping clustering algorithms like means discussed member object belongs one cluster object belongs one cluster becomes overlapping clustering method gorithm fuzzy means clustering nowadays community detection effective way reveal relationship structure function networks drawn lots attention well developed networks modeled graphs whe nodes represent objects edges represent interactions among community detection divides network groups nodes nodes densely connected inside sparsely connected outside however real world objects often diverse roles belong multiple communities example professor collaborates researchers different fields person family group well friend group time community detection objects divided ultiple groups known overlapping nodes aim overlapping community detection discover overlapping nodes communities lots overlapping community detection approaches proposed rou ghly divided two categories node based link based algorithms node based overlapping community detection algorithms directly divide nodes network different communities based intuition link networks usuall represents unique relation link based algorithms firstly cluster edges network map link communities node communities gathering nodes incident edg within link community newly proposed link based lgorithms shown superiority detecting complex multi scale communities however high computational complexities bias discovered communities shi propose genetic algorithm gaocd overlapping communi detection based link clustering framework different node based overlapping community detection algorithms gaocd utilize property unique role links applies novel genetic algorithm cluster edges experiments artificial real networks show gaocd effectively reveal overlapping structure evaluation criteria formation clusters important process however also meaningful test validity accuracy clusters forme method tested whether clusters formed certain method show maximum similarity among objects cluster minimum similarity among clusters recently many evaluation criteria developed criteria divided mainly two categories internal external internal quality criteria measure internal criteria generally measure compactness clusters applying similarity measure techniques general measures int cluster separability intra cluster homogeneity combination two sum squared error sum square error sse frequently used criterion measure clustering defined ikk csse set instances cluster vector mean cluster scatter criteria scatter criteria matrix defined follows cluster xcs condorcets criterion condorcets criterion another approach apply ranking problem criterion defined follows jkj xxs measure similarity distance vectors criterion fortier solomon defined criterion extension condorcets criterion defined jkj xxs threshold value category utility metric category utility defined measures goodness category set entities size binary featu set binary category calculated follows log log log icu prior probability entity belonging positive category conditional probability entity feature given entity belongs category likewise conditional probability entity feature given entity belongs category prior probability entity processing feature edge cut metrics edge cut minimization problem useful cases dealing clustering problems case cluster quality measu red ratio remaining edge weights total precut edge weights finding optimal value easy edge cut minimization problem restriction size clusters external quality criteria measures order match structure cluster predefined classification instances external quality criteria measure useful mutual information based measure streh proposed mutual information based measure used ext ernal measure clustering criteria measure instances clustered using referring target attribute whose domain dom defined follows logg llmmcmm indicates number instances cluster also class denotes total number instances class similarly indicates number instances cluster rand index rand index simple criterion used compute similar clusters benchmark classifications rand index defined tnrandtp number tru positives number true negatives number false positives number false negatives rand index lies two partitions agree perfectly rand index measure rand index alse positives false negatives equally weighted may cause undesirable features clustering applications measure addresses concern used balance false negatives weighting recall parameter measure defined follows prfpr precision rate recall rate recall impact increasing allocates increasing amount weight recall final measure precision recall defined follows tpptp tprtp jaccard index jaccard index considered identify equivalency two datasets jaccard index defined follows tpj empty simply number unique elements common sets divided total number unique elements oth sets fowlkes mallows index fowlkes mallows index determines similarity clusters obtained clustering algorithm higher value fowlkes mallows index indicates similarity clusters determined follows tpfmtp confusion matrix confusion matrix also known contingency table error matrix used quickly visualize results clustering classification system trained disting uish apples oranges tomatoes confusion matrix summarize results testing algorithm inspection assuming sample fruits apples oranges tomatoes result confusion matrix look like tab table confusion matrix actual class predicted class apple orange tomato apple orange tomato external indices based pre specified structure reflection prior information data use standard validate clustering solutions internal tests dependent external information prior knowledge contrary examine clustering structure directly original data evaluation refer application clustering useful several applications endless useful applications applications given diverse fields image segmentation image segmentation essential component image processing image segme ntation achieved using hierarchical clustering means also applied segmentation magnetic resonance imaging mri provides visualization internal structures objects living organisms mri images better contr ast computerized tomography therefore medical image segmentation research uses mri images segmenting mri image key task many medical applications surgical planning abnormality detection mri segmentation aims partiti input image significant anatomical areas uniform according certain image properties mri segmentation formulated clustering problem set feature vectors obtained transformation image measurem ents pixel positions grouped number structures bioinformatics gene expression data recently advances genome sequencing projects dna microarray technologies achieved first draft human genome sequence project completed several years earlier expected applications clustering algorithms bioinformatics seen two aspects first aspect based analysis gene expression data generated dna mic roarray technologies second aspect describes clustering processes directly work linear dna protein sequences assumption functionally similar genes proteins usually share similar patterns primary sequence structures object recognition use clustering group views objects purposes object recognition range data described system consideration employed view point dependent view cantered approach object reco gnition problem object recognized represented terms library range images object character recognition clustering employed jain identify lexemes handwritten text purposes writer independent hand writing recognition success handwriting recognition system vitally dependent acceptance potential users writer dependent systems give higher level recognition accuracy given writer independent systems former require large amount training data writer independent system hand must able recognize wide variety writing styles order satisfy individual user information etrieval information etrieval concern automatic storage retrieval documents many university libraries use systems provide access books journals documents libraries use ibrary congress lassification lcc scheme efficient storage retrie val books lcc scheme consists classes labelled used characterize books belonging different subjects example label corresponds books area science subclass assigned mathematics lab els used classifying books related computers areas computer science data ining data mining extraction knowledge large databases applied relational transaction spatial database well large stores unstructured data world wide web many data mining systems use today applications include treasury detecting money laundering national basketball ssociation coaches detecting trends patterns play individual players teams categorizing patterns children foster care system several articles recent published special issues data mining spatial data analysis clustering useful extract interesting features identify patterns exist huge amounts spatial databases expensive hard user deal large spatial datasets like atellite images medical equipment geographical information ystems gis image database exploration etc clustering process helps understand spatial data analyzing process automatically business role clustering quite interesting business areas helps marketer researchers analysis prediction customers order provide services based requirements also help market segmentation new product development product positioning clustering may used set available shopping items web group unique products data reduction data reduction compression one necessary tasks handling large data processing becomes demanding clustering applied help compressing data informatio clustering different set interesting cluster different set cluster choose information set data useful process save data processing time along data reduction big data minin big data also emerging issue volume data beyond capacity conventional data base management tools processed big data mining due use various social sites travel governance etc practices mammoth mount data heaped every moment clustering information data help aggregating similar information collected unformatted databases mainly text hadoop one big data processing tool expected big data rocessing play important role detection cyber crime clustering groups people similar behaviour social network face book whatsa etc predicting market behaviour based various polls social sites applications sequence analysis human genetic clustering social network analysis search result grouping software evolution recommender systems educational data mining climatology field robotics etc choice appropriate clustering method depicted fig wide amount literature available referred paper becomes obvious question method uniformly good remember according free lunch concept given wolpert algorithm uniformly good circumstances fact algorithm merit strength specific nature data fails type data selection appropriate lustering method may sometimes also involve decision certain parameters whether one wants proper alignment unsupervised grouping objects number clusters say user define choosing value matters choic made fine tuning among intra cluster objects patterns virtue distance expected selecting heuristic stochastic evolutionary computing like genetic algorithms applied find othe hand case data mining data processing applications dimensionality reduction mostly required reduce number attributes features existing dataset order extract rules better prediction capability many occasions expected reducing dimensionality dataset whether structure internal topology dataset disturbed reduced data space saxena proposed four unsupervised methods ature selection using genetic algorithms fraley presents comprehensive discussion decide clustering method described clustering methodology based multivariate normal mixture models shown give much better rformance existing methods approach limitations however first limitation computational methods hierarchical clustering storage time requirements grow faster linear rate relative size initial partition cannot directly applied large data sets secondly although experience date suggests models based multivariate normal distribution sufficiently flexible accommodate many practical situations nderlying assumption groups concentrated locally linear subspaces models methods may suitable instances bensmail showed exact bayesian inference via gibbs sampling calculations bayes factors using laplace metropolis estimator works well several real simulated examples large data sets cure method advisable whereas birch also good less time complexity although quality clusteri inferior obtained cure refer table partitioned clustering method means clustering dominates still popular clustering method refer table many clusters depends close fine tuning want among clusters also keep mind purpose applying means various clustering methods presented paper already strengths weaknesses mostly given therein apart discussion sele ction appropriate method clustering worth noting looking huge amount literature available wide variety application clustering possible settle agreeable recommendation specific task objectives calls specific strategy tested experimentally finally part comprehensive comparative table various clustering algorithms presented given table details meaning symbols refer table comparative study clustering algorithms category clustering algorithm name time complexity scalability suitable large scale data suitable high dimensional data sensitive noise outlier partition means low knt middle yes high pam high low little clara middle high yes little clarans high middle yes little hierarchy birch low high yes little cure low logs high yes yes little rock high logn middle yes little chameleon high high little fuzzy based fcm low middle high density based dbscan middle logn middle yes little graph theory click low high yes high grid based clique low high yes moderat conclusions classification objects finds prime importance several data processing applications including data mining medical diagnostics pattern recognition social paradigms objects already labeled placed supervised classifi groups labeled grouped unsupervised classified groups paper presented various methods used clusters states arts limitations hierarchical type clustering methods clusters formed iterat ively viding patterns instances top bottom manner accordingly agglomerative divisive splitting hierarchical clustering methods discussed opposed hierarchical clustering partitional clustering assigns data clusters without hierarchical structure optimizing criterion function common criterion finding euclidean distance points available clusters assigning point cluster minimum distance benchmark means clustering methods variations like fuzzy means discussed graph theoretic methods produce clusters via graphs mixture density based methods data objects assumed generated according several proba bility distributions derived different types density functions multivariate gaussian distribution families different parameters grid based clustering techniques include sting statistical inf ormation grid approach highly scalable algorithm ability decompose data set various levels details evolutionary approaches clustering start random population candidate solutions fitness function would optimized clustering based simulated annealing collaborative clustering multi objective clustering states art also included various types similarity criteria clustering given paper clusters formed evaluation criteria also summarised see performance accuracy clusters applications clustering image segmentation object character recognition information retrieval data mining highlighted paper course abundant amount literature available clustering applications possible cover entirely basic important methods included paper merits demeri acknowledgement uthors would like thank anonymous reviewers valuable suggestions comments improve quality paper work partially supported australian research council arc discovery grant reference duda hart stork pattern classification wiley publications zhang yin guo xiao cross validation based weights structure determination chebyshev polynomial neural netwo rks pattern classification pattern recognition vol nakayama kagaku pattern classification linear goal programming extensions journal global optimization vol shop pattern recognition machine learning berlin springer isbn zhang neural networks classification survey ieee transaction systems man cybernetics part applications reviews vol zhang liu wang data core based fuzzy min max neural etwork pattern classification ieee transaction neural networks vol jiang wah constructing training feed forward neural net works pattern classification pattern recognition vol murphey multi class pattern classification using neural networks pattern recognition vol paola schowengerdt detailed comparison back propagation neural network maximum likelihood classifiers urban land use classification ieee transaction geoscience remote sensing vol rumelhart mcclelland parallel distributed processing mit press cambridge zhou verification nonparametric characteristics back propagation neural networks image classification ieee transaction geoscience remote sensing vol jaeger benz supervised fuzzy classification sar data using multiple sources ieee international geoscience remote sensing symposium marzano scaranari vulpiani supervised fuzzy logic assification hydrometeors using band weather radars ieee transaction geoscience remote sensing vol xue zhang browne particle swarm optimization feature selection classification multi objective approach ieee transaction cybernetics vol saxena vora novel approach use small world theory particle swarm optimization international conference advanced compu ting communications pawlak rough sets international journal computer information science vol pawlak rough sets theoretical aspects reasoning data kluwer netherlands dalai chatterjee dey chakravorti bhattacharya rough set based feature selection classification power quality sensing device employing correlation techniques ieee sensors journal vol quinlan induction decision trees machine learning vol farida zhang rahman hossain strachan hybrid decision tree naive bayes classifiers multi class classifica tion tasks expert systems applications vol han kamber pei data mining concepts techniques morgan kaufmann publishers rokach clustering methods data mining knowledge discover handbook springer saxena pal vora evolutionary methods unsupervised feature selection using sammons stress function fuzzy information engineering jain data clustering years beyond means pattern recognition letters vol merriam webster online dictionary castro yang fast robust general purpose clu stering algorithm international conference artificial intelligence fraley raftery many clusters clustering method answers via model based cluster analysis technical report department statistics university washington jain murty flynn data clustering review acm computing surveys vol sneath sokal numerical taxonomy freeman san francisco king step wise clustering procedures journal american statistical association vol ward hierarchical grouping optimize objective function journal american statistical association vol murtagh survey recent advances hierarchical clustering algorithms use cluster centers computer journal vol nagpal jatain gaur review based data clustering algorithms ieee onference information communication technologies periklis data clustering techniques university toronto guha rastogi kyuseok cure efficient clustering algorithm large databases acm george han kumar chameleon hierarchical clustering algorithm using dynamic modeling ieee computer vol lam wunsch clustering academic press library signal processing signal processing theory machine learning vol macqueen methods classification analysis multivariate observations symposium mathematical statistics probability berkeley university california press vol gersho gray vector quantization signal compression kluwer academic publishers dunn fuzzy relative isodata process use detecting compact well separated clusters journal cybernetics vol bezdek pattern recognition fuzzy objective function algorithms plenum press new york yager filev approximate clustering via mountain method ieee transaction systems man cybernetics part bernetics vol gath geva unsupervised optimal fuzzy clustering ieee transaction pattern analysis machine intelligence vol hathaway bezdek generalized fuzzy means clustering strategies using norm distances ieee transaction fuzzy systems vol krishnapuram keller possibilistic approach clustering ieee transaction fuzzy systems vol zahn graph theoretical methods detecting describing gestalt clusters ieee transaction computer vol urquhart graph theoretical clustering based limited neighborhood sets patter recognition vol fisher knowledge acquisition via incremental conceptual clustering machine learning haykin neural networks comprehensive foundation edition prentice hall wunsch survey clustering algorithms ieee transaction neural networks vol wunsch clustering algorithms biomedical research review ieee reviews biomedical engineering vol mclachlan krishnan algorithm extensions wiley new york banfield raftery model based gaussian non gaussian clustering biometrics vol ester kriegel sander density based algorithm discovering clusters large spatial databases wit noise international conference knowledge discovery data mining cheeseman stutz bayesian classification autoclass theory results advances knowledge discovery data mining wallace dowe intrinsic classification mml snob program australian joint conference artificial intelligence wang yang muntz sting statistical information grid approach spatial data mining vldb nference sheikholeslami chatterjee zhang wavecluster wavelet based clustering approach spatial data large databases international journal large data bases vol agrawal johannes dimitrios raghavan automatic subspace clustering high dimensional data data mining applications sigmod conference jain flynn data clustering review acm computing surveys csur vol schwefel numerical optimization computer models john wiley new york fog owens walsh artificial intelligence simulated evolution john wiley new york holland adaption natural artificial systems university michigan press goldberg genetic algorithms search optimization machine learning addison wesley reading kennedy eberhart swarm intelligence morgan kaufmann kennedy eberhart particle swarm optimization ieee international conference neural networks dorigo stutzle ant colony optimization mit press glover future paths integer programming links artificial intelligence computers operations research vol sultan tabu search approach clustering problem pattern recognition vol pedrycz collaborative fuzzy clustering pattern recognition letters vol coletta vendramin hruschka campello pedrycz collaborative fuzzy clustering algorithms refinements design guidelines ieee transactions fuzzy systems vol pedrycz rai collaborative clustering use fuzzy means quantification fuzzy sets systems vol pedrycz knowledge based clustering data information granules wiley publications prasad lin yang saxena vertical collaborative fuzzy means multiple eeg data sets springer intelligent robotics applications lecture notes computer science vol pizzuti overlapping community detection complex networks gecco gregory fast algorithm find overlapping communities networks pkdd ahn bagrow lehmann link communities reveal multi scale complexity networks nature vol forestier gancarski wemmert collaborative clustering back ground knowledge data knowledge engineering vol handl knowles evolutionary approach multiobjective clustering ieee transaction evolutionary computation vol konak coit smith multiobjective optimization using genetic algorithms tutorial reliability engineering system safety vol faceili carvalho souto multiobjective clustering ensemble international conference hybrid intelligent systems law topchy jain multiobjective data clustering ieee conference computer vision pattern recognition vol forsyth ponce computer vision modern approach prentice hall consortium initial sequencing analysis human genome nature vol dorai jain shape spectra based view grouping free form object international conference image rocessing vol connell jain learning prototypes line handwritten digits international conference pattern recognition vol rasmussen clustering algorithms information retri eval data structures algorithms prentice hall englewood cliffs mckiernan classification outline library congress washington hedberg searching mother lode tales first data miners eee expert intelligent systems applications vol cohen communications acm data mining association computing machinery nov saxena wang dimensionality reduction unsupervised featur selection applying non euclidean norms classification accuracy international journal data warehousing mining vol sultan khan computational experience four algorithms hard clust ering problem pattern recognition letters vol michalski stepp diday automated construction classifications conceptual clustering versus numerical taxonomy ieee transaction pattern analysis machine intelligence vol venter sequence human genome science vol kolodner reconstructive memory computer model cognitive science vol carpineto romano order theoretic approach conceptual clustering international conference machine learning talavera bejar generality based conceptual clustering probabilistic concepts eee transactions pattern analysis machine intelligence vol hadzikadic yun concept formation incremental conceptual clustering international joint conference artificial intelligence biswas weinberg fisher iterate conceptual clustering algorithm data mining ieee transactions systems man cybernetics part vol thompson langley concept formation structured domains concept formation knowledge experience unsupervised learning morgan kaufmann jonyer cook holder graph based hierarchical conceptual clustering journal machine learning research vol lebowitz experiments incremental concept formation unimem machine learning vol hanson bauer conceptual clustering categorization polymorphy machine learning journal vol kohonen self organizing map neurocomputing vol pages vesanto alhoniemi clustering self organizing map ieee transactions neural networks vol upton fingelton spatial data analysis example point pattern quantitative data john wiley sons new ork vol strehl ghosh mooney impact similarity measures web page clustering workshop artificial intelligence web search fortier solomon clustering procedures multivariate anal ysis gluck corter information uncertainty utility categories program annual conference cognitive science society condorcet essai sur lapplica tion lanalyse probabilite des decisions rendues pluralite des voix paris limprimerie royale marcotorchino michaud optimisation analyse ordinale des donnees masson paris corter gluck plaining basic categories feature predictability information psychological bulletin vol strehl ghosh clustering guidance quality evaluation using relationship based visualization intelligent enginee ring systems artificial neural networks louis missouri usa stehman selecting interpreting measures thematic classification accuracy remote sensing environment vol rand objective criteria evaluation clustering methods journal american statistical associatio vol rijsbergen information retrieval butterworths london brendan dueck clustering passing essages data points science vol fowlkes mallows method comparing two hierarchical clusterings journal american statistical association vol olson delen advanced data mining techniques springer edition powers evaluation precision recall factor roc informedness markedness correlation journal machine learning technologies vol jaccard distribution flore alpine dans bassin des dranses dans quelques regions voisines bulletin societe vaudoise des sciences naturelles vol han kamber pei data mining con cepts techniques morgan kaufman san francisco usa grefenstette optimization control parameters genetic algorithms ieee transaction systems man cybernetics vol lin prasad chang designing mamdani type fuzzy rule using collaborative fcm scheme international conference fuzzy theory applications eugene chapter combinatorial implications max flow min cut theorem chapter linear programm ing interpretation max flow min cut theorem combinatorial optimization networks matroids dover papadimitriou steiglitz chapter max flow min cut theorem combinatorial optimization algorithms complexity dover fotheringham charlto brunsdon geographically weighted regression natural evolution expansion method spatial data analysis environment planning vol honarkhah caers stochastic simulation patterns using distance based pattern modeling mathematical geosciences vol tahmasebi hezarkhani sahimi multiple point geostatistical modeling based cross correlation functions computational geosciences guha rastogi shim rock robust clustering algorithm categorical attributes ieee conference data engineering zhang ramakrishn linvy birch efficient method lar databases acm sigmod jiang chen ooi tan epic extensible scalable system processing big data vldb conference huang fast clustering algorithm cluster large categorical data sets data mining dmkd hinneburg keim efficient approach clustering large multimedia databases noise kdd conference berry linoff data mining techniques marketing sales customer support john wiley sons inc usa fennell allenby yang edwards effectiveness demographics phychographic variables explaining brand product category use quantitative marketing economics vol kiang fisher effect sample size extended self organizing map network market segmentation application computational statistics data analysis vol dolnicar using cluster analysis market segmentation typical misconceptions established methodological weaknesses recommendations improvement journal marketing esearch vol wagner scholz decker number clusters market segmentation data analysis decision support heidelberg springer durbin eddy krogh mitchison biological sequenc analysis probabilistic models proteins nucleic acids cambridge cambridge university press kaplan winther prisoners abstraction theory measure genetic variation concept race biologica theory vol carrington scott social network analysis introduction sage handbook social network analysis london vol yippy growing leaps bounds news press may retrieved may dirk concept oriented approach support software maintenance reuse activities joint conference knowledge based software engineering dias anquetil oliveira organizing knowledge used software maintenance journal universal computer science vol francesco rokach shapira introduction recommender systems handbook recommender systems handbook springer www educationaldatamining org baker data mining education international encyclopedia education edition oxford elsevier vol siemens baker lear ning analytics educational data mining towards communication collaboration international conference learning analytics knowledge huth beck philipp demuzere ustrnul cahynova kysely tveito classifications atmospheric circulation patterns recent advances applications annals new york academy science vol bewley shekhar leonard upcroft lever real time volume estimation dragline payload ieee international conference robotics automation manning raghavan schu tze introduction information retrieval cambridge university press nguyen chen chan clustering multi viewpoint based similarity measure ieee transactions knowledge data engineering vol bravais memoires par divers savants paris pearson mathematical contributions theory evolution iii regression heredity panmixia philosophical transactions royal society london series vol srensen method establishing groups equal ampl itude plant sociology based similarity species application analyses vegetation danish commons kongelige danske videnskabernes selskab vol dice measures amount ecologic association species ecology vol hamilton time series analysis princeton university press tsay analysis financial time series john wiley sons saxena wang dimensionality reduction unsupervised feature selection applying non euclidean norms classification accuracy international journal data warehousing mining ijdwm vol arora chana survey clustering techniques big data analysis international conference next generation information technology summit confluence shirkhorshidi aghabozorgi wah herawan big data ustering review lecture notes computer science vol wang wang yang clustering pattern similarity large data sets international conf erence management ata acm huang fast clustering algorithm cluster large categorical data sets data mining dmkd zhu ding data mining big data ieee transaction knowledge engineering vol russom big data analytics tdwi best practices report fourth quarter xiao nie huang multi view means clustering big data twenty third nternational joint conference artificial intelligence aaai fan albert mining big data current status forecast uture acm sigkdd explorations newsletter vol shvachko kuang radia chansler hadoop stributed file system ieee symposium mass storage systems technologies msst jeffrey ghemawat mapreduce flexible data processing tool communications acm vol celeux govaert classification algorithm clustering two stochastic versions computational statistics data analysis vol kaufman rousseeuw finding groups data introduction cluster analysis wiley ngand han clarans method clustering objects spatial data mining ieee trans knowledge data engineering vol sisodia singh sisodia saxena clustering techniqu brief survey different clustering algorithms international journal latest trends engineering technology ijltet vol zhong miao wang graph theoretical clustering method based two rounds mini mum spanning trees pattern recognition vol chen sanghavi improved graph clustering ieee transactions information theory vol condon karp algorithms aph partitioning planted partition model random structures algorithms vol donath hoffman lower bounds partitioning graphs ibm res develop vol shi malik normalized cuts image segmentation ieee transactions pattern analysis machine intelligence vol luxburg tutorial spectral clustering statistics computing vol rohe chatterjee spectral clustering high dimensional stochastic block model annals sta tistics vol gunnemann farber boden seidl subspace clustering meet dense sub graph mining synthesis two paradigms icdm macropol singh scalable discovery best clusters large graphs proceedings vldb endowment vol whang sui dhillon scalable memory efficient clustering large scale social networks icdm karypis kumar fast high quality multilevel scheme partitioning irregular graphs siam journal scientific computing vol karypis kumar multilevel way partitioning scheme irregular graphs journal parallel distribu ted computing vol yan huang jordan fast approximate spectral cluster ing kdd liu wang danilevsky han large scale spectral cluste ring graphs ijcai yang divide conquer framework distributed graph lustering icml ghosh dubey compar ative analysis means fuzzy means algorithms international journal advanced computer science applications vol niwattanakul singthongchai naenudorn wanapu using jaccard coefficient ywords similarity proceedings international multiconference engineers computer scientists vol imecs march hong kong chen pau wang hand book pattern reco gnition computer vision world scientific singapore dubes cluster analysis related issue jain dubes algorithms clustering data englewood cliffs prentice hall shi cai dong link clustering bas overlapping community detection algorithm data knowledge engineering vol palla derenyi farkas vicsek uncovering overlapping community structure complex networks nature society nature vol wolpert macready free lunch theorem optimization ieee transactions evolutionary computation vol bensmail celeux raftery robert inference model based cluster analysis stat comput tian comprehensive survey clustering algorithms ann data sci'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "test_text_sw_removed = preprocess_test_document(pdf_path)\n",
        "test_text_sw_removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3dQn-Mi34r_y",
        "outputId": "131fa1ac-bf38-41aa-b54e-744447cc4058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/IK_rr_DataFrame.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "csv_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1MdwKua4r_y"
      },
      "outputs": [],
      "source": [
        "csv_txts_sw_removed = preprocess_csv_file(csv_path, 'Text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOOk_D3P4r_y",
        "outputId": "2c228be6-a4b0-4f27-e150-d4c9860efaeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "len(csv_txts_sw_removed) #Stopwords have been removed from the text of each file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqk78W8i4r_y"
      },
      "source": [
        "# Finding similarity using plaintext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKmbdqA_4r_y"
      },
      "outputs": [],
      "source": [
        "#Let's find the most similar document based on jaccard simialrity (plain text)\n",
        "\n",
        "def Jaccard_Similarity(doc1, doc2):\n",
        "\n",
        "    # List the unique words in a document\n",
        "    words_doc1 = set(doc1.lower().split())\n",
        "    words_doc2 = set(doc2.lower().split())\n",
        "\n",
        "    ## doc1 = This is a cat\n",
        "    ## doc2 = This is a dog\n",
        "\n",
        "    ## words_doc1: {This, is, a, cat}\n",
        "    ## words_doc2: {This, is, a, dog}\n",
        "    # Find the intersection of words list of doc1 & doc2\n",
        "    intersection = words_doc1.intersection(words_doc2)\n",
        "    # Intersection: {This, is, a}\n",
        "    # Union: {This, is, a, cat, dog}\n",
        "\n",
        "    # Find the union of words list of doc1 & doc2\n",
        "    union = words_doc1.union(words_doc2)\n",
        "\n",
        "    # Calculate Jaccard similarity score\n",
        "    # using length of intersection set divided by length of union set\n",
        "    return float(len(intersection)) / len(union)\n",
        "\n",
        "\n",
        "\n",
        "jac_sim = np.zeros(df.shape[0]) #Initializing jac_sim of every document with 0\n",
        "for i in range(len(csv_txts_sw_removed)):\n",
        "    jac_sim[i] = Jaccard_Similarity(test_text_sw_removed, csv_txts_sw_removed[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JpE2Hb04r_z",
        "outputId": "e0cdeaf1-6717-47eb-a589-fcb8ffc19de7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "#Finding index of maximum jac_sim\n",
        "np.argmax(jac_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tduikswJ4r_z",
        "outputId": "92379498-d267-4bbb-cf60-1b38181f22cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileName                A Review of Clustering Techniques.pdf\n",
              "Author                                            Amit Saxena\n",
              "Text        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...\n",
              "Name: 10, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#Details of the most similar document\n",
        "df.loc[np.argmax(jac_sim)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDA2e0ts4r_z"
      },
      "source": [
        "# Finding simialrity using BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGaP2Kco4r_z"
      },
      "outputs": [],
      "source": [
        "# We will do stemming to reduce the vocabulary.\n",
        "# Stemming is preferred over lemmatization for simialrity based tasks.\n",
        "from nltk.stem import SnowballStemmer\n",
        "sb_stemmer = SnowballStemmer('english')\n",
        "\n",
        "stemmed_csv_data = []\n",
        "for each_text in csv_txts_sw_removed:\n",
        "    stemmed_txt = []\n",
        "    for each_word in each_text.split(' '):\n",
        "        stemmed_txt.append(sb_stemmer.stem(each_word))\n",
        "    stemmed_csv_data.append(stemmed_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ekDhKq4r_0",
        "outputId": "9e80a306-6158-4b17-bb27-108ae0eb4aa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "len(stemmed_csv_data) #Stemmed text of the PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBB8G1204r_0"
      },
      "outputs": [],
      "source": [
        "#Stemmed test PDF\n",
        "stemmed_test_txt = []\n",
        "for each_word in test_text_sw_removed.split():\n",
        "    stemmed_test_txt.append(sb_stemmer.stem(each_word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxQETB_54r_0"
      },
      "source": [
        "### Generating BoW representation (Presence/Absence - 1/0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDcdWT1H4r_0"
      },
      "outputs": [],
      "source": [
        "# Combining test PDF text with csv text (to get same representation)\n",
        "stemmed_csv_data.append(stemmed_test_txt)\n",
        "# You can also use the encoder fit on the csv_text on the text PDF text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXMEWZPt4r_0",
        "outputId": "8d300958-6378-4184-ab15-29aae2f44120"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "len(stemmed_csv_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMsTSddc4r_0"
      },
      "outputs": [],
      "source": [
        "#This expects the input as an array of lists or as a list of lists\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "te = TransactionEncoder()\n",
        "csv_data = pd.DataFrame(te.fit(stemmed_csv_data).transform(stemmed_csv_data).astype('int'), columns= te.columns_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYn3nlv84r_1",
        "outputId": "cc5e4a73-9077-406b-adcf-e91731ee657a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 8580)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "csv_data.shape #Enormous vocabulary of 8580 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tu956w24r_1"
      },
      "outputs": [],
      "source": [
        "#Using frequent features only to process the similarities quickly\n",
        "col_lst_less_than_10 = []\n",
        "for col in csv_data.columns:\n",
        "    if csv_data[col].sum() < 10:\n",
        "        col_lst_less_than_10.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlJbhTNS4r_1",
        "outputId": "2f9643f2-84d9-4700-9c47-e062c154e900"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8297"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "len(col_lst_less_than_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu9-FV8A4r_1",
        "outputId": "209e49cc-f62c-493a-f6cf-5e34eac66278"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 283)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "csv_data_rm_10 = csv_data.drop(col_lst_less_than_10, axis = 1)\n",
        "csv_data_rm_10.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwGTPZU94r_1"
      },
      "outputs": [],
      "source": [
        "# Let's compute cosine similarity. You can also try jaccard similarity here.\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "def calculate_similarity(test_rep, csv_rep):\n",
        "    similarity_scores = []\n",
        "    indices = []\n",
        "    for i, csv_reps in enumerate(csv_rep):\n",
        "        similarity =  cosine_similarity(np.array(test_rep).reshape(1,-1),np.array(csv_reps).reshape(1,-1))[0][0]\n",
        "        similarity_scores.append(similarity)\n",
        "        indices.append(i)\n",
        "    return similarity_scores, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhD0AR-J4r_2"
      },
      "outputs": [],
      "source": [
        "sim_scores, ind = calculate_similarity(csv_data.iloc[csv_data.shape[0] - 1].values, csv_data.loc[0:csv_data.shape[0]-2].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFJ5whq-4r_2",
        "outputId": "a74c53ba-d410-467b-8c51-46baf35b52a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "np.argmax(sim_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJUyCR8I4r_2",
        "outputId": "ff211fe8-1cb9-4c72-9e8d-1777fbf90545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileName                A Review of Clustering Techniques.pdf\n",
              "Author                                            Amit Saxena\n",
              "Text        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...\n",
              "Name: 10, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "#Details of the most similar document\n",
        "df.loc[np.argmax(jac_sim)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sknP1eDY4r_2"
      },
      "source": [
        "#### Retrieve top-k unique authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkYaGgOJ4r_2"
      },
      "outputs": [],
      "source": [
        "def retrieve_top_k_unique_authors(df, similarity_scores, indices, k):\n",
        "    # Sort scores and corresponding indices\n",
        "    sorted_scores_indices = sorted(zip(similarity_scores, indices), key=lambda x: x[0], reverse=True)\n",
        "    unique_authors = []\n",
        "\n",
        "    # Loop over sorted scores and indices\n",
        "    for _, idx in sorted_scores_indices:\n",
        "        # Get author corresponding to index\n",
        "        author = df.iloc[idx]['Author']\n",
        "        # Append author to unique_authors list if it's not there yet\n",
        "        if author not in unique_authors:\n",
        "            unique_authors.append(author)\n",
        "            # Break the loop if we have found k unique authors\n",
        "            if len(unique_authors) == k:\n",
        "                break\n",
        "\n",
        "    return unique_authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ahJHTc94r_2",
        "outputId": "3dd06d13-aaba-467d-aaa4-b28d12c7a6a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Amit Saxena']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "k=3\n",
        "top_k_authors = retrieve_top_k_unique_authors(df, sim_scores, ind, k)\n",
        "top_k_authors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ME_D11R4sAA"
      },
      "source": [
        "# Using Term Frequency Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krzhxHd04sAB"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# The expected input is list of strings or an array of strings\n",
        "str_text = []\n",
        "for each_text in stemmed_csv_data:\n",
        "    mystr = ''\n",
        "    for each_word in each_text:\n",
        "        mystr = mystr + ' ' + each_word #You can achieve the same using join\n",
        "    str_text.append(mystr.lstrip(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "I64yZ2pm4sAB",
        "outputId": "d0fa3b83-bb8f-48e6-c5ba-2d0c6c820605"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   aaai  aalexa  aar  abaci  abbrevi  abcam  abcellera  abdalla  abdallah  \\\n",
              "0     0       0    0      0        0      0          0        1         0   \n",
              "1     0       0    0      0        0      0          0        0         0   \n",
              "2     0       0    0      0        2      0          0        0         0   \n",
              "3     0       0    0      0        0      0          0        0         0   \n",
              "4     0       0    2      0        0      0          0        0         1   \n",
              "\n",
              "   abdomin  ...  zou  zro  zucker  zugaib  zurakowski  zutphen  zyme  zymek  \\\n",
              "0        0  ...    1    0       0       0           0        0     0      0   \n",
              "1        0  ...    0    0       0       0           0        0     0      0   \n",
              "2        0  ...    0    0       0       0           0        0     0      0   \n",
              "3        1  ...    0    0       0       1           0        0     0      0   \n",
              "4        0  ...    0    0       0       0           0        0     0      1   \n",
              "\n",
              "   zymographi  zymosan  \n",
              "0           0        0  \n",
              "1           0        0  \n",
              "2           0        0  \n",
              "3           0        0  \n",
              "4           0        0  \n",
              "\n",
              "[5 rows x 8579 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d26541d5-2f91-4314-8d0b-5701a3b79013\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaai</th>\n",
              "      <th>aalexa</th>\n",
              "      <th>aar</th>\n",
              "      <th>abaci</th>\n",
              "      <th>abbrevi</th>\n",
              "      <th>abcam</th>\n",
              "      <th>abcellera</th>\n",
              "      <th>abdalla</th>\n",
              "      <th>abdallah</th>\n",
              "      <th>abdomin</th>\n",
              "      <th>...</th>\n",
              "      <th>zou</th>\n",
              "      <th>zro</th>\n",
              "      <th>zucker</th>\n",
              "      <th>zugaib</th>\n",
              "      <th>zurakowski</th>\n",
              "      <th>zutphen</th>\n",
              "      <th>zyme</th>\n",
              "      <th>zymek</th>\n",
              "      <th>zymographi</th>\n",
              "      <th>zymosan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8579 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d26541d5-2f91-4314-8d0b-5701a3b79013')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d26541d5-2f91-4314-8d0b-5701a3b79013 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d26541d5-2f91-4314-8d0b-5701a3b79013');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33ffd771-2f6f-42ad-9a2a-700180d7b328\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33ffd771-2f6f-42ad-9a2a-700180d7b328')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33ffd771-2f6f-42ad-9a2a-700180d7b328 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "cv = CountVectorizer()\n",
        "cv.fit(str_text)\n",
        "tf_data = pd.DataFrame(cv.transform(str_text).todense(), columns = sorted(cv.vocabulary_))\n",
        "tf_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qyJm7Ut4sAB"
      },
      "outputs": [],
      "source": [
        "#Using frequent features only to process the similarities quickly\n",
        "col_lst_less_than_10 = []\n",
        "for col in tf_data.columns:\n",
        "    if tf_data[col].sum() < 10:\n",
        "        col_lst_less_than_10.append(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392MWV6n4sAB",
        "outputId": "168927ff-e44a-4ed2-e6cd-bcbcb58573dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7176"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(col_lst_less_than_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPfMclta4sAB",
        "outputId": "332c1382-4550-4658-edf4-ef2b1b9090ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 1403)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "tf_data.drop(col_lst_less_than_10, axis = 1, inplace = True)\n",
        "tf_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1VRAKS94sAC",
        "outputId": "35884f70-a468-40cd-9c7d-cc45ce13e287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Amit Saxena']\n"
          ]
        }
      ],
      "source": [
        "# Calculate similarity between the test document and CSV documents\n",
        "similarity_scores, indices = calculate_similarity(tf_data.iloc[tf_data.shape[0] - 1].values, tf_data.loc[0:tf_data.shape[0]-2].values)\n",
        "\n",
        "# Load the CSV data\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Retrieve top-k unique authors\n",
        "k=5\n",
        "top_k_authors = retrieve_top_k_unique_authors(df, similarity_scores, indices, k)\n",
        "\n",
        "# Print the top-k authors\n",
        "print(top_k_authors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvLY2Dg54sAC"
      },
      "source": [
        "# Using TF-IDF Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXs3i9r04sAC",
        "outputId": "2cd88769-2111-4f40-8d56-0b513180563a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 8579)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "fidf = TfidfVectorizer()\n",
        "fidf.fit(str_text)\n",
        "tf_idf_data = pd.DataFrame(fidf.transform(str_text).todense(), columns = sorted(fidf.vocabulary_))\n",
        "tf_idf_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsZGHbcV4sAC",
        "outputId": "db34ff95-4406-4e90-ad1f-46de8dfd7747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Amit Saxena']\n"
          ]
        }
      ],
      "source": [
        "# Calculate similarity between the test document and CSV documents\n",
        "similarity_scores, indices = calculate_similarity(tf_idf_data.iloc[tf_idf_data.shape[0] - 1].values, tf_idf_data.loc[0:tf_idf_data.shape[0]-2].values)\n",
        "\n",
        "# Load the CSV data\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Retrieve top-k unique authors\n",
        "k=5\n",
        "top_k_authors = retrieve_top_k_unique_authors(df, similarity_scores, indices, k)\n",
        "\n",
        "# Print the top-k authors\n",
        "print(top_k_authors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KSD3R9s4sAD"
      },
      "source": [
        "# Validating Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJmBy26Yclmi"
      },
      "outputs": [],
      "source": [
        "def top_k_accuracy(y_true, y_pred, k=1):\n",
        "    \"\"\"\n",
        "    Compute the top-k accuracy based on word presence in predictions.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (str): True label (actual author).\n",
        "    y_pred (list): List of predicted authors for the test PDFs.\n",
        "                   The shape of y_pred should be (num_PDFs, k).\n",
        "    k (int): The value of k for top-k accuracy. Default is 1 (top-1 accuracy).\n",
        "\n",
        "    Returns:\n",
        "    top_k_acc (float): The top-k accuracy value.\n",
        "    \"\"\"\n",
        "    if k <= 0 or not isinstance(k, int):\n",
        "        raise ValueError(\"k must be a positive integer.\")\n",
        "\n",
        "    num_samples = len(y_pred)\n",
        "    num_correct = 0\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        if y_true in y_pred[i][:k]:\n",
        "            num_correct += 1\n",
        "\n",
        "    top_k_acc = num_correct / num_samples\n",
        "    return top_k_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjlMalepdbVQ",
        "outputId": "b2602d2b-0589-462c-9cf8-acdcb9a020f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Top-3 accuracy with an example\n",
        "top_k_accuracy('Sanatan',[['Sanatan','Arash','Abhinav'],['Arash','Abhinav','Vartika'],['Arash','Sanatan','Abhinav']],3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok3K-BGAd7_H",
        "outputId": "53018c48-5b92-472d-c0a9-0627a0c6aa8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Top-1 accuracy (Matching with the first prediction only)\n",
        "top_k_accuracy('Sanatan',[['Sanatan','Arash','Abhinav'],['Arash','Abhinav','Vartika'],['Arash','Sanatan','Abhinav']],1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0wPZaF2etua"
      },
      "source": [
        "## Some pointers for unbiased evaluation\n",
        "> You can split the given dataset into train and test, and evaluate the performance of your models with Top-k accuracy **for different values of k**.\n",
        "\n",
        "\n",
        "* When dividing the data, make sure that at least one PDF file from each author appears in both the training and testing sets. Exclude authors for whom there is only one PDF available in the dataset.\n",
        "\n",
        "* You can average the performance over multiple runs.\n",
        "\n",
        "* You can think of aggregating and comparing documents as a whole (per author).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ucJmP_ye1Iq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}