{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c635960",
   "metadata": {},
   "source": [
    "# L3: Image generation app ðŸŽ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c186d0",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0447fb8-b684-4835-9a31-1d0a824d2607",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1b5677-271a-46ac-a02e-656f2e315e15",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# # Helper function\n",
    "# import requests, json\n",
    "\n",
    "# #Text-to-image endpoint\n",
    "# def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
    "#     headers = {\n",
    "#       \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "#       \"Content-Type\": \"application/json\"\n",
    "#     }   \n",
    "#     data = { \"inputs\": inputs }\n",
    "#     if parameters is not None:\n",
    "#         data.update({\"parameters\": parameters})\n",
    "#     response = requests.request(\"POST\",\n",
    "#                                 ENDPOINT_URL,\n",
    "#                                 headers=headers,\n",
    "#                                 data=json.dumps(data))\n",
    "#     return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3810ba-5532-4b25-8f05-94652735757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def get_completion(input):\n",
    "\n",
    "    # Load the pipeline from a pretrained model\n",
    "    pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", use_safetensors=True)\n",
    "    \n",
    "    # Set the device to GPU if available, otherwise use CPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    pipeline = pipeline.to(device)\n",
    "    \n",
    "    image = pipeline(input).images[0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a85ed",
   "metadata": {},
   "source": [
    "## Building an image generation app "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fab52",
   "metadata": {},
   "source": [
    "Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28748bf-2618-4b8c-aa6f-7aad9c573af8",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ad5b9f8ba04251b467521924d2b898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce705183e814a0d9d234ce0f3af8b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,<PIL.Image.Image image mode=RGB size=512x512 at 0x16EA448D0>\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"a dog in a park\"\n",
    "\n",
    "result = get_completion(prompt)\n",
    "IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee90440",
   "metadata": {},
   "source": [
    "## Generating with `gr.Interface()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024026ce-7832-4749-8992-50d31d61fcda",
   "metadata": {
    "height": 438
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34437d0d31db4463880ca3603a633c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98da610c65c494bb2d3ab83c56dc8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr \n",
    "\n",
    "#A helper function to convert the PIL image to base64\n",
    "#so you can send it to the API\n",
    "def base64_to_pil(img_base64):\n",
    "    base64_decoded = base64.b64decode(img_base64)\n",
    "    byte_stream = io.BytesIO(base64_decoded)\n",
    "    pil_image = Image.open(byte_stream)\n",
    "    return pil_image\n",
    "\n",
    "def generate(prompt):\n",
    "    output = get_completion(prompt)\n",
    "    # result_image = base64_to_pil(output)\n",
    "    return output\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=generate,\n",
    "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
    "\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT1']))\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d16450",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 19062\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a7330",
   "metadata": {},
   "source": [
    "## Building a more advanced interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2aec35-51e6-4f12-b096-189a968ef8e3",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "import gradio as gr \n",
    "\n",
    "#A helper function to convert the PIL image to base64 \n",
    "# so you can send it to the API\n",
    "def base64_to_pil(img_base64):\n",
    "    base64_decoded = base64.b64decode(img_base64)\n",
    "    byte_stream = io.BytesIO(base64_decoded)\n",
    "    pil_image = Image.open(byte_stream)\n",
    "    return pil_image\n",
    "\n",
    "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
    "    params = {\n",
    "        \"negative_prompt\": negative_prompt,\n",
    "        \"num_inference_steps\": steps,\n",
    "        \"guidance_scale\": guidance,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    }\n",
    "    \n",
    "    output = get_completion(prompt)\n",
    "    # pil_image = base64_to_pil(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48190bc3-6f1d-43ab-816c-e9b4eb65899d",
   "metadata": {},
   "source": [
    "#### gr.Slider()\n",
    "- You can set the `minimum`, `maximum`, and starting `value` for a `gr.Slider()`.\n",
    "- If you want the slider to increment by integer values, you can set `step=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c844370-4c46-4115-858e-f5cd5fe337ab",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3b673d61d144bbb22df655348a48ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fb76a3766d4b02915d1bf0b25cac14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo = gr.Interface(fn=generate,\n",
    "                    inputs=[\n",
    "                        gr.Textbox(label=\"Your prompt\"),\n",
    "                        gr.Textbox(label=\"Negative prompt\"),\n",
    "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "                                  info=\"Controls how much the text prompt influences the result\"),\n",
    "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "                    ],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\"\n",
    "                    )\n",
    "\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT2']))\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71999364",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95b525",
   "metadata": {},
   "source": [
    "## `gr.Blocks()`\n",
    "\n",
    "- Within `gr.Blocks()`, you can define multiple `gr.Row()`s, or multiple `gr.Column()`s.\n",
    "- Note that if the jupyter notebook is very narrow, the layout may change to better display the objects.  If you define two columns but don't see the two columns in the app, try expanding the width of your web browser, and the screen containing this jupyter notebook.\n",
    "\n",
    "- When using `gr.Blocks()`, you'll need to explicitly define the \"Submit\" button using `gr.Button()`, whereas the 'Clear' and 'Submit' buttons are automatically added when using `gr.Interface()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6818b5e-1342-439b-b129-a8904719d09c",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399da24ddb0e40399a16a153892ae9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7109869dba848e398e928f77d39056b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    prompt = gr.Textbox(label=\"Your prompt\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "            btn = gr.Button(\"Submit\")\n",
    "        with gr.Column():\n",
    "            output = gr.Image(label=\"Result\")\n",
    "\n",
    "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f13197-6af1-4818-8122-63d52c41daae",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6f7a8-8cd5-422e-a622-f9aef30fadb3",
   "metadata": {},
   "source": [
    "#### scale\n",
    "\n",
    "- To choose how much relative width to give to each column, set the `scale` parameter of each `gr.Column()`.  \n",
    "- If one column has `scale=4` and the second column has `scale=1`, then the first column takes up 4/5 of the total width, and the second column takes up 1/5 of the total width.\n",
    "\n",
    "#### gr.Accordion()\n",
    "- The `gr.Accordion()` can show/hide  the app options with a mouse click.\n",
    "- Set `open=True` to show the contents of the Accordion by default, or `False` to hide it by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "655908ab-fa08-4b86-b218-f685f62d3638",
   "metadata": {
    "height": 421
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a6c2de5c39402abe03da76445ad064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2504773698ee43a19a864bf8e56aa799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
    "        with gr.Column(scale=1, min_width=50):\n",
    "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
    "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "                with gr.Column():\n",
    "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "    output = gr.Image(label=\"Result\") #Move the output up too\n",
    "            \n",
    "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "\n",
    "gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT4']))\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d91ece7c-f5a5-4025-8558-23bd2e007ed2",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d2cbd-a799-40dc-9c50-a3e26080a16b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
