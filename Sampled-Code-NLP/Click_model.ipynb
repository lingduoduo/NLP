{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"~/Downloads/0000_part_00.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5299643 entries, 0 to 5299642\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Dtype \n",
      "---  ------                  ----- \n",
      " 0   referralcreativeid      int64 \n",
      " 1   targetgroupid           int64 \n",
      " 2   campaignid              int64 \n",
      " 3   accountid               int64 \n",
      " 4   publisherid             int64 \n",
      " 5   gender                  int32 \n",
      " 6   agegroup                int32 \n",
      " 7   deviceplatform          int32 \n",
      " 8   repeatvisitor           int32 \n",
      " 9   positiveresponse        int32 \n",
      " 10  negativeresponse        int32 \n",
      " 11  age                     int64 \n",
      " 12  secondssincelastseen    int64 \n",
      " 13  secondssincelastposres  int64 \n",
      " 14  secondssincelastnegres  int64 \n",
      " 15  rank                    int64 \n",
      " 16  placementid             int64 \n",
      " 17  cardtype                object\n",
      " 18  cardsubtype             object\n",
      " 19  topcardtype             object\n",
      " 20  operatingsystem         object\n",
      " 21  devicebrand             object\n",
      " 22  browser                 object\n",
      " 23  pagetype                object\n",
      " 24  placementlayout         object\n",
      " 25  offerlayout             object\n",
      " 26  emaildomain             object\n",
      " 27  referrals               int32 \n",
      "dtypes: int32(7), int64(11), object(10)\n",
      "memory usage: 990.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "creatives = pd.read_csv(\"~/Downloads/creatives_with_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3880 entries, 0 to 3879\n",
      "Data columns (total 30 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   creativeid           3880 non-null   int64 \n",
      " 1   text                 3880 non-null   object\n",
      " 2   free_delivery        3880 non-null   bool  \n",
      " 3   free_trail           3880 non-null   bool  \n",
      " 4   lucky_draw           3880 non-null   bool  \n",
      " 5   click                3880 non-null   bool  \n",
      " 6   dollar_sign          3880 non-null   bool  \n",
      " 7   exclamation          3880 non-null   bool  \n",
      " 8   question_sign        3880 non-null   bool  \n",
      " 9   discount             3880 non-null   bool  \n",
      " 10  offer                3880 non-null   bool  \n",
      " 11  unlock               3880 non-null   bool  \n",
      " 12  bonus                3880 non-null   bool  \n",
      " 13  cash_back            3880 non-null   bool  \n",
      " 14  sign_up              3880 non-null   bool  \n",
      " 15  now                  3880 non-null   bool  \n",
      " 16  first_name_replaced  3880 non-null   bool  \n",
      " 17  claim                3880 non-null   bool  \n",
      " 18  enjoy                3880 non-null   bool  \n",
      " 19  help                 3880 non-null   bool  \n",
      " 20  congrats             3880 non-null   bool  \n",
      " 21  save                 3880 non-null   bool  \n",
      " 22  apr                  3880 non-null   bool  \n",
      " 23  loan                 3880 non-null   bool  \n",
      " 24  discount.1           3880 non-null   bool  \n",
      " 25  discount_value       3880 non-null   bool  \n",
      " 26  discount_num         3880 non-null   object\n",
      " 27  discount_perc        3880 non-null   bool  \n",
      " 28  discount_perc_num    3880 non-null   object\n",
      " 29  no_number            3880 non-null   bool  \n",
      "dtypes: bool(26), int64(1), object(3)\n",
      "memory usage: 219.9+ KB\n"
     ]
    }
   ],
   "source": [
    "creatives.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "copytext = creatives['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(s_text):\n",
    "    #try remove all tags\n",
    "    document = re.sub(r'\\<[^>]*>','',str(s_text)) #tick\n",
    "    \n",
    "#     #replace coded apostrophies\n",
    "#     document = document.replace('&rsquo;','') #tick\n",
    "    document = document.replace('&amp;','and') #tick\n",
    "#     document = document.replace('%',' percent') #tick\n",
    "#     document = document.replace('*','') #tick\n",
    "#     document = document.replace('$','dollars ') #tick\n",
    "    document = document.replace('&nbsp','') #tick\n",
    "\n",
    "#     #remove prefixed Test\n",
    "#     document = re.sub(r'^Test\\s+', '', document)\n",
    "\n",
    "#     # Remove all the special characters\n",
    "# #     document = re.sub(r'[,@\\'?\\.$%_]', '', document)\n",
    "\n",
    "#     # remove all single characters\n",
    "#     document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "#      # Remove single characters from the start\n",
    "#     document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "#     # Substituting multiple spaces with single space\n",
    "#     document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "#     # Removing prefixed 'b'\n",
    "#     document = re.sub(r'^b\\s+', '', document)\n",
    "#     document = re.sub(r'\\W', ' ',document)   \n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "creatives['clean_text']=copytext.apply(lambda x: cleaning_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.merge(data, creatives, left_on=[\"referralcreativeid\"], right_on=[\"creativeid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>referralcreativeid</th>\n",
       "      <th>targetgroupid</th>\n",
       "      <th>campaignid</th>\n",
       "      <th>accountid</th>\n",
       "      <th>publisherid</th>\n",
       "      <th>gender</th>\n",
       "      <th>agegroup</th>\n",
       "      <th>deviceplatform</th>\n",
       "      <th>repeatvisitor</th>\n",
       "      <th>positiveresponse</th>\n",
       "      <th>...</th>\n",
       "      <th>save</th>\n",
       "      <th>apr</th>\n",
       "      <th>loan</th>\n",
       "      <th>discount.1</th>\n",
       "      <th>discount_value</th>\n",
       "      <th>discount_num</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>discount_perc_num</th>\n",
       "      <th>no_number</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2646117866475294712</td>\n",
       "      <td>2692224928836550658</td>\n",
       "      <td>2536115181270101577</td>\n",
       "      <td>101767</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>your purchase gives you access to amazing deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2876960757946056733</td>\n",
       "      <td>2876932591550332946</td>\n",
       "      <td>2855789494061301904</td>\n",
       "      <td>2853527618225229629</td>\n",
       "      <td>2045379072644613984</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>you've earned a free trial to discovery+! the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2886698170375209078</td>\n",
       "      <td>2859533790709940435</td>\n",
       "      <td>2820179516474261505</td>\n",
       "      <td>2791520355034103636</td>\n",
       "      <td>2045379072644613984</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unlock up to $200 to spend online when you joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2873745257665069106</td>\n",
       "      <td>2886801434273644881</td>\n",
       "      <td>2837686477485113390</td>\n",
       "      <td>2791726255766259938</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>our koalas are very quickly heading towards ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2879161314514436348</td>\n",
       "      <td>2692884309398716623</td>\n",
       "      <td>2692879945712140371</td>\n",
       "      <td>2633455211965079646</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>you've earned $150 off smiledirectclub aligner...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    referralcreativeid        targetgroupid           campaignid  \\\n",
       "0  2646117866475294712  2692224928836550658  2536115181270101577   \n",
       "1  2876960757946056733  2876932591550332946  2855789494061301904   \n",
       "2  2886698170375209078  2859533790709940435  2820179516474261505   \n",
       "3  2873745257665069106  2886801434273644881  2837686477485113390   \n",
       "4  2879161314514436348  2692884309398716623  2692879945712140371   \n",
       "\n",
       "             accountid          publisherid  gender  agegroup  deviceplatform  \\\n",
       "0               101767                   64       1         2               2   \n",
       "1  2853527618225229629  2045379072644613984       2         5               1   \n",
       "2  2791520355034103636  2045379072644613984       2         5               1   \n",
       "3  2791726255766259938                   64       2         2               2   \n",
       "4  2633455211965079646                   64       2         2               2   \n",
       "\n",
       "   repeatvisitor  positiveresponse  ...   save    apr   loan  discount.1  \\\n",
       "0              2                 0  ...  False  False  False       False   \n",
       "1              5                 0  ...  False  False  False       False   \n",
       "2              5                 8  ...  False  False  False        True   \n",
       "3              7                 0  ...  False  False  False       False   \n",
       "4              0                 0  ...  False  False  False        True   \n",
       "\n",
       "   discount_value  discount_num  discount_perc discount_perc_num no_number  \\\n",
       "0           False         False          False             False      True   \n",
       "1           False         False          False             False      True   \n",
       "2            True           200          False             False     False   \n",
       "3           False         False          False             False      True   \n",
       "4            True           150          False             False     False   \n",
       "\n",
       "                                          clean_text  \n",
       "0  your purchase gives you access to amazing deal...  \n",
       "1  you've earned a free trial to discovery+! the ...  \n",
       "2  unlock up to $200 to spend online when you joi...  \n",
       "3  our koalas are very quickly heading towards ex...  \n",
       "4  you've earned $150 off smiledirectclub aligner...  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>referralcreativeid</th>\n",
       "      <th>targetgroupid</th>\n",
       "      <th>campaignid</th>\n",
       "      <th>accountid</th>\n",
       "      <th>publisherid</th>\n",
       "      <th>gender</th>\n",
       "      <th>agegroup</th>\n",
       "      <th>deviceplatform</th>\n",
       "      <th>repeatvisitor</th>\n",
       "      <th>positiveresponse</th>\n",
       "      <th>...</th>\n",
       "      <th>save</th>\n",
       "      <th>apr</th>\n",
       "      <th>loan</th>\n",
       "      <th>discount.1</th>\n",
       "      <th>discount_value</th>\n",
       "      <th>discount_num</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>discount_perc_num</th>\n",
       "      <th>no_number</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2877094116681646110</td>\n",
       "      <td>2886801434273644881</td>\n",
       "      <td>2837686477485113390</td>\n",
       "      <td>2791726255766259938</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>our koalas are losing their homes and their li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2864738144312164568</td>\n",
       "      <td>2864737723405631502</td>\n",
       "      <td>2812042340155326467</td>\n",
       "      <td>2443482344537199973</td>\n",
       "      <td>2601936972420513252</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>get available coupon codes automatically appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2887882859786469391</td>\n",
       "      <td>2881856153088819253</td>\n",
       "      <td>2871881563989147782</td>\n",
       "      <td>2809479086472472188</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>download and sign in to the bws app to go into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2770807802255704283</td>\n",
       "      <td>2770807334104072306</td>\n",
       "      <td>2770806943262048353</td>\n",
       "      <td>2755560006908929678</td>\n",
       "      <td>404</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>click below to claim your €16.87 cash back on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2798422745457885189</td>\n",
       "      <td>2804369278003183635</td>\n",
       "      <td>2133407807667190781</td>\n",
       "      <td>102564</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4,000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>maximise your kiwisaver savings by receiving a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      referralcreativeid        targetgroupid           campaignid  \\\n",
       "25   2877094116681646110  2886801434273644881  2837686477485113390   \n",
       "65   2864738144312164568  2864737723405631502  2812042340155326467   \n",
       "97   2887882859786469391  2881856153088819253  2871881563989147782   \n",
       "117  2770807802255704283  2770807334104072306  2770806943262048353   \n",
       "156  2798422745457885189  2804369278003183635  2133407807667190781   \n",
       "\n",
       "               accountid          publisherid  gender  agegroup  \\\n",
       "25   2791726255766259938                  100       1         3   \n",
       "65   2443482344537199973  2601936972420513252       2         6   \n",
       "97   2809479086472472188                  100       2         2   \n",
       "117  2755560006908929678                  404       2         0   \n",
       "156               102564                  131       2         6   \n",
       "\n",
       "     deviceplatform  repeatvisitor  positiveresponse  ...   save    apr  \\\n",
       "25                2              8                 0  ...  False  False   \n",
       "65                1              7                 0  ...  False  False   \n",
       "97                2              0                 0  ...  False  False   \n",
       "117               2              0                 0  ...  False  False   \n",
       "156               1              8                 0  ...   True  False   \n",
       "\n",
       "      loan  discount.1  discount_value  discount_num  discount_perc  \\\n",
       "25   False       False           False         False          False   \n",
       "65   False       False           False         False          False   \n",
       "97   False        True            True           500          False   \n",
       "117  False       False           False         False          False   \n",
       "156  False        True            True         4,000          False   \n",
       "\n",
       "    discount_perc_num no_number  \\\n",
       "25              False      True   \n",
       "65              False      True   \n",
       "97              False     False   \n",
       "117             False     False   \n",
       "156             False     False   \n",
       "\n",
       "                                            clean_text  \n",
       "25   our koalas are losing their homes and their li...  \n",
       "65   get available coupon codes automatically appli...  \n",
       "97   download and sign in to the bws app to go into...  \n",
       "117  click below to claim your €16.87 cash back on ...  \n",
       "156  maximise your kiwisaver savings by receiving a...  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = all[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    our koalas are losing their homes and their li...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:1]['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 our koalas are losing their homes and their li ... name : clean_text , dtype : object\n"
     ]
    }
   ],
   "source": [
    "s = str(sample[:1]['clean_text'])\n",
    "print(' '.join(tokenizer.tokenize(s.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9808275699615479}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"You've earned 50% off 6 bottles of wine from Firstleaf! Personalized wines matched to your taste buds. Take the wine quiz & get $40 worth of free wine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9812963008880615}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"You've earned 5% off 6 bottles of wine from Firstleaf! Personalized wines matched to your taste buds. Take the wine quiz & get $40 worth of free wine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9998084902763367}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all.to_csv(\"all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readin clean data directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all = pd.read_csv(\"all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = all[['clean_text', 'referrals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "by_rating = collections.defaultdict(list)\n",
    "for _, row in sample.iterrows():\n",
    "    by_rating[row.referrals].append(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(by_rating[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split data\n",
    "final_list = []\n",
    "np.random.seed(20210505)\n",
    "train_proportion = 0.7\n",
    "val_proportion = 0.3\n",
    "\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "\n",
    "    np.random.shuffle(item_list)\n",
    "    \n",
    "    n_total = len(item_list)\n",
    "    n_train = int(train_proportion * n_total)\n",
    "    n_val = int(val_proportion * n_total)\n",
    "    \n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    \n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reviews = pd.DataFrame(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    204280\n",
       "val       87548\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reviews.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: referrals, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reviews.referrals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>referrals</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi {rokt.firstname|there} ready to make the mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you've earned 50% off 6 bottles of wine from f...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{rokt.firstname|congrats}, you've earned more ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get available coupon codes automatically appli...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>join over 500,000 pet parents shopping at pet ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291824</th>\n",
       "      <td>“the packaging was great, the quality and styl...</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291825</th>\n",
       "      <td>you've earned $90 to shop on hellofresh!\\nfind...</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291826</th>\n",
       "      <td>you've earned 12 free meals from hellofresh, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291827</th>\n",
       "      <td>your purchase earned 3 months free of siriusxm...</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291828</th>\n",
       "      <td>{rokt.firstname|hey there}, you've earned $15 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  referrals  split\n",
       "0       hi {rokt.firstname|there} ready to make the mo...          0  train\n",
       "1       you've earned 50% off 6 bottles of wine from f...          0  train\n",
       "2       {rokt.firstname|congrats}, you've earned more ...          0  train\n",
       "3       get available coupon codes automatically appli...          0  train\n",
       "4       join over 500,000 pet parents shopping at pet ...          0  train\n",
       "...                                                   ...        ...    ...\n",
       "291824  “the packaging was great, the quality and styl...          1    val\n",
       "291825  you've earned $90 to shop on hellofresh!\\nfind...          1    val\n",
       "291826  you've earned 12 free meals from hellofresh, i...          1    val\n",
       "291827  your purchase earned 3 months free of siriusxm...          1    val\n",
       "291828  {rokt.firstname|hey there}, you've earned $15 ...          1    val\n",
       "\n",
       "[291829 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_reviews['referrals'] = final_reviews.referrals.apply({0: 'negative', 1: 'positive'}.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Vocabulary class maintains token to integer mapping needed for the rest of the machine learning pipeline\n",
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract Vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK(unknow) token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "        \n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx, \n",
    "                'add_unk': self._add_unk, \n",
    "                'unk_token': self._unk_token}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self._add_unk:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  The Vectorizer class converts text to numeric vectors\n",
    "class ReviewVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, review_vocab, rating_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_vocab (Vocabulary): maps words to integers\n",
    "            rating_vocab (Vocabulary): maps class labels to integers\n",
    "        \"\"\"\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "\n",
    "    def vectorize(self, review):\n",
    "        \"\"\"Create a collapsed one-hit vector for the review\n",
    "        \n",
    "        Args:\n",
    "            review (str): the review\n",
    "        Returns:\n",
    "            one_hot (np.ndarray): the collapsed one-hot encoding\n",
    "        \"\"\"\n",
    "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
    "        \n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "\n",
    "        return one_hot\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the review dataset\n",
    "            cutoff (int): the parameter for frequency-based filtering\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary(add_unk=True)\n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "        # Add ratings\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "\n",
    "        # Add top words if count > provided count\n",
    "        word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "               \n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "\n",
    "        return cls(review_vocab, rating_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"Intantiate a ReviewVectorizer from a serializable dictionary\n",
    "        \n",
    "        Args:\n",
    "            contents (dict): the serializable dictionary\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer class\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
    "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\n",
    "\n",
    "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\"Create the serializable dictionary for caching\n",
    "        \n",
    "        Returns:\n",
    "            contents (dict): the serializable dictionary\n",
    "        \"\"\"\n",
    "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
    "                'rating_vocab': self.rating_vocab.to_serializable()}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
    "        \"\"\"\n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self.train_df = self.review_df[self.review_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.review_df[self.review_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.review_df[self.review_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        train_review_df = review_df[review_df.split=='train']\n",
    "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(review_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
    "        \n",
    "        Args:\n",
    "            split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        review_vector = \\\n",
    "            self._vectorizer.vectorize(row.review)\n",
    "\n",
    "        rating_index = \\\n",
    "            self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "\n",
    "        return {'x_data': review_vector,\n",
    "                'y_target': rating_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Model: ReviewClassifier\n",
    "class ReviewClassifier(nn.Module):\n",
    "    \"\"\" a simple perceptron based classifier \"\"\"\n",
    "    def __init__(self, num_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): the size of the input feature vector\n",
    "        \"\"\"\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_features, \n",
    "                             out_features=1)\n",
    "\n",
    "    def forward(self, x_in, apply_sigmoid=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, num_features)\n",
    "            apply_sigmoid (bool): a flag for the sigmoid activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch,)\n",
    "        \"\"\"\n",
    "        y_out = self.fc1(x_in).squeeze()\n",
    "        if apply_sigmoid:\n",
    "            y_out = torch.sigmoid(y_out)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target):\n",
    "    y_target = y_target.cpu()\n",
    "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General utilities\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation and Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>referrals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;p&gt;our koalas are losing their homes &amp;amp; the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>&lt;p&gt;get available coupon codes automatically ap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>&lt;p&gt;download and sign in to the bws app to go i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>click below to claim your €16.87 cash back on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>maximise your kiwisaver savings by receiving a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  referrals\n",
       "25   <p>our koalas are losing their homes &amp; the...          0\n",
       "65   <p>get available coupon codes automatically ap...          0\n",
       "97   <p>download and sign in to the bws app to go i...          0\n",
       "117  click below to claim your €16.87 cash back on ...          0\n",
       "156  maximise your kiwisaver savings by receiving a...          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = corpus[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your purchase gives you access to amazing deals from kogan.com. sign up for their emails for incredible offers',\n",
       " \"<p>you've earned a free trial to discovery+! the only streaming service with the greatest real-life entertainment + exclusive originals all in one place.</p>\",\n",
       " '<p>unlock up to $200 to spend online when you join visible. unlimited data. powered by verizon, 5g included in {rokt.city|your city}. terms apply.</p>',\n",
       " '<p>our koalas are very quickly heading towards extinction. adopt a koala today with wwf-australia to help restore their precious forest homes. find out more via email.</p>',\n",
       " \"<p>you've earned $150 off smiledirectclub aligners &amp; a $25 prepaid mastercard for completing your scan or returning your impression kit. sign up to claim this limited time offer.</p>\",\n",
       " nan,\n",
       " '<p>looking for extra comfort? receive $30 off the softest loungewear ever from cozy earth! sign up to emails to get this exclusive offer. shop now!</p>',\n",
       " \"you've earned a 14 day free trial of ancestry. start exploring millions of records and build your family tree now! click below to receive your free trial!\",\n",
       " \"you've unlocked $25 off and free next day delivery with appliances online! sign up to get the best deals on top brands like westinghouse, bosch and more!\",\n",
       " \"<p>you've earned 10 free delicious meals from home chef! new menus every week, customized to your preferences. sign up to learn more.</p>\",\n",
       " \"<p>you've earned $150 off smiledirectclub aligners &amp; a $25 prepaid mastercard for completing your scan or returning your impression kit. sign up to claim this limited time offer.</p>\",\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " '<p>win a $500 wish voucher with bws!\\xa0download and sign in to the bws app for your chance to win!</p>',\n",
       " '<p>get a free coles/woolworths gift voucher for completing a lifepoints survey on your favourite food. join emails for free now and head to site to get started!</p>',\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " \"<p>you've earned $150 off smiledirectclub aligners &amp; a $25 prepaid mastercard for completing your scan or returning your impression kit. sign up to claim this limited time offer.</p>\",\n",
       " '<p>boost your job post on indeed. the first £100 sponsored job credit is on us.</p>',\n",
       " \"<p>you've unlocked access to click frenzy's exclusive\\xa0member\\xa0benefits!\\xa0sign up today for early event access and a chance to score one of our famous 99% off deals!</p>\",\n",
       " \"<p>you've earned £5 off your first order of freshly roasted coffee from pact coffee! from £1.95 for your first bag, delivered to your door.</p>\",\n",
       " nan,\n",
       " \"<p>congratulations, you've unlocked 4 free meals from hellofresh! start cooking amazing meals from scratch. sign up for emails &amp; claim now.</p>\",\n",
       " \"<p>{rokt.firstname|congrats}, you've earned 12 free meals from hellofresh! sign up for emails &amp; get 1st box free shipping.</p>\",\n",
       " \"<p>{rokt.firstname|congrats}, you've earned 12 free meals from hellofresh, including 1st box free shipping! sign up for emails &amp; start cooking delicious meals from scratch.</p>\",\n",
       " 'get market-smashing prices on apple, nike, lg, nintendo, samsung &amp; more at kogan.com! sign up for the latest email deals and start shopping now!',\n",
       " '<p>paypal is bringing even more stars. earn an additional star for every $2 you spend when you pay with paypal at starbucks, this april only. offer ends 4/30/2021. terms apply.</p>',\n",
       " '<p>our koalas are losing their homes &amp; their lives. adopt one today with wwf-australia to help return more koalas to the wild. sign up to help.</p>',\n",
       " '<p>dive into thousands of options for your garden this spring. wayfair has everything you need, plus free delivery to most of the uk on orders over £40. sign up for emails now!</p>',\n",
       " \"<p>congratulations, you've unlocked 4 free meals from hellofresh! start cooking amazing meals from scratch. sign up for emails &amp; claim now.</p>\",\n",
       " '<p>score! you’ve earned a free trial of discovery+, the premiere real-life tv streaming service available anytime, anywhere on your favorite device.</p>',\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " \"get $20 off your first order if you sign up to pet circle now. join australia's #1 rated online pet supplies shop with the lowest prices &amp; free shipping!\",\n",
       " '<p>our koalas are very quickly heading towards extinction. adopt a koala today with wwf-australia to help restore their precious forest homes. find out more via email.</p>',\n",
       " '<p>start selling online with free extensions from wordpress ecommerce hosting. start a new or improve an existing online store!</p>',\n",
       " '<p>easy-to-use virtual servers. 1st month free, plans start at $3.50/mo.</p>',\n",
       " '<p>your purchase gets you a 30-day free trial of hulu! stream tons of shows and movies, exclusive originals, and more.</p>',\n",
       " '<p>boost your job post on indeed. the first £100 sponsored job credit is on us.</p>',\n",
       " '<p>start selling online with free extensions from wordpress ecommerce hosting. start a new or improve an existing online store!</p>',\n",
       " '<p>easy-to-use virtual servers. 1st month free, plans start at $3.50/mo.</p>',\n",
       " nan,\n",
       " '<p>boost your job post on indeed. the first £100 sponsored job credit is on us.</p>',\n",
       " '<p>switch to visible &amp; pay only $20/mo for 3 months of wireless. unlimited data. powered by verizon, 5g included. sign up with code 20for3. offer ends 4/30.</p>',\n",
       " '<p>straighten your teeth with smiledirectclub. sign up to order a free impression kit &amp; get entered to win free aligners!</p>',\n",
       " '<p>claim your offer of $90 off across your first 4 weeks of green chef meals, including 1st box free shipping! sign up for emails &amp; get this offer now.</p>',\n",
       " \"<p>you've earned a free trial to discovery+! the only streaming service with the greatest real-life entertainment + exclusive originals all in one place.</p>\",\n",
       " 'click below to claim your £16.87 cash back on your next online order with the complete savings paid programme.',\n",
       " '<p>{rokt.firstname|congrats}, your event ticket purchase gets you £60 off 4 recipe boxes from hellofresh! claim now &amp; find out more via email.</p>',\n",
       " '<p>claim your business today and get started today to reach more of the right customers.</p>',\n",
       " '<p>get plans starting at only $19/month with next insurance</p>',\n",
       " \"<p>you've earned a free trial to discovery+! the only streaming service with the greatest real-life entertainment + exclusive originals all in one place.</p>\",\n",
       " '<p>{rokt.firstname|congrats}, you earned a special offer from smiledirectclub! get started with an at home impression kit or a free 3d scan. sign up &amp; take our smile assessment.</p>',\n",
       " \"<p>switch to verizon prepaid and get up to $75 in savings. 3rd month free with new activation. add'l terms apply.</p>\",\n",
       " nan,\n",
       " '<p>download and sign in to the bws app to go into the draw to win 1 of 5 $500 wish vouchers!</p>',\n",
       " 'join over 500,000 pet parents shopping at pet circle for the lowest prices on the best pet brands + free delivery. sign up to emails to get $20 off your first order!',\n",
       " 'get started today to reach more of the right customers.',\n",
       " '<p>boost your job post on indeed. the first $100 sponsored job credit is on us.</p>',\n",
       " '<p>get plans starting at only $19/month with next insurance</p>',\n",
       " '<p>your purchase gets you a 30-day free trial of hulu! stream tons of shows and movies, exclusive originals, and more.</p>',\n",
       " \"<p>{rokt.firstname|congrats}, you've earned a special offer from smiledirectclub. sign up to get started for free and you'll be entered to win free aligners.</p>\",\n",
       " \"<p>{rokt.firstname|congrats}, you've earned 12 free meals from hellofresh! sign up for emails &amp; get 1st box free shipping.</p>\",\n",
       " \"<p>hi {rokt.firstname|there}! you've unlocked 50% off a one-year sam's club membership by shopping with memberdeals. click below to start saving now!</p>\",\n",
       " \"<span>{rokt.firstname|hey}, as a thank you for your ticket purchase you've unlocked your first craft beer box free from beer52! find out more via email.</span>\",\n",
       " \"<p>you've unlocked 20% off at holland &amp; barrett! stock up on your favourite vitamins, skincare and free-from foods. sign up to emails and receive your coupon code to shop now!</p>\",\n",
       " \"<p>you've unlocked a free trial set from harry's! includes a\\xa05-blade razor, foaming gel &amp; blade cover - delivered to your door. just pay delivery! learn more.</p>\",\n",
       " 'click below to claim your £10 cash back on your next online order with the complete savings paid programme.',\n",
       " '<p>get available coupon codes automatically applied to your orders. simply add capital one shopping to your browser, and shop like normal. this free tool does the work for you.</p>',\n",
       " 'your purchase gives you access to amazing deals from kogan.com. sign up for their emails for incredible offers',\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " \"<p>you've unlocked a $20 voucher to spend on mydeal! sign up to shop in-demand products at discount prices from leading brands.</p>\",\n",
       " \"<p>you've earned $150 off smiledirectclub aligners &amp; a $25 prepaid mastercard for completing your scan or returning your impression kit. sign up to claim this limited time offer.</p>\",\n",
       " \"<p>get $20 off your first order if you sign up to pet circle now. join australia's #1 rated online pet supplies shop with the lowest prices &amp; free shipping!</p>\",\n",
       " 'get started today to reach more of the right customers.',\n",
       " '<p>get plans starting at only $19/month with next insurance</p>',\n",
       " '<p>stock up at first choice liquor market with 10% off your next order! sign up now for your code!</p>',\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " \"<p>you've earned a free trial to discovery+! the only streaming service with the greatest real-life entertainment + exclusive originals all in one place.</p>\",\n",
       " '<p>straighten your teeth with smiledirectclub. sign up to order a free impression kit &amp; get entered to win free aligners!</p>',\n",
       " \"<p>{rokt.firstname|congrats}, you've earned 12 free meals from hellofresh, including 1st box free shipping! sign up for emails &amp; start cooking delicious meals from scratch.</p>\",\n",
       " '<p>{rokt.firstname|hey}, looking to save money on wireless? join visible &amp; claim $100 to spend online. unlimited data. powered by verizon, 5g included. terms apply.</p>',\n",
       " \"<p>you've unlocked 20% off at holland &amp; barrett! stock up on your favourite vitamins, skincare and free-from foods. sign up to emails and receive your coupon code to shop now!</p>\",\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " \"<p>you've unlocked access to click frenzy's exclusive\\xa0member\\xa0benefits!\\xa0sign up today for early event access and a chance to score one of our famous 99% off deals!</p>\",\n",
       " \"<p>you've earned up to 12 free meals from hellofresh, including 1st box free shipping! sign up for emails &amp; claim now.</p>\",\n",
       " '<p>make money online when you take paid surveys with lifepoints. sign up now and head to site to start getting rewarded today!</p>',\n",
       " \"you've unlocked $25 off and free next day delivery with appliances online! sign up to get the best deals on top brands like westinghouse, bosch and more!\",\n",
       " 'your purchase gives you access to amazing deals from kogan.com. sign up for their emails for incredible offers',\n",
       " \"<p>you've earned $150 off smiledirectclub aligners &amp; a $25 prepaid mastercard for completing your scan or returning your impression kit. sign up to claim this limited time offer.</p>\",\n",
       " \"<p>you've unlocked access to click frenzy's exclusive member deals! sign up today.</p>\",\n",
       " '<p>boost your job post on indeed. the first £100 sponsored job credit is on us.</p>',\n",
       " '<p>our koalas are very quickly heading towards extinction. adopt a koala today with wwf-australia to help restore their precious forest homes. find out more via email.</p>',\n",
       " '<p>unlock up to $200 to spend online when you join visible. unlimited data. powered by verizon, 5g included in {rokt.city|your city}. terms apply.</p>',\n",
       " \"<p>hey {rokt.firstname|there}! you've earned a free trial to discovery+! the only streaming service with the greatest real-life entertainment + exclusive originals in one place.</p>\",\n",
       " \"<p>switch to verizon prepaid and get up to $75 in savings. 3rd month free with new activation. add'l terms apply.</p>\",\n",
       " \"<p>you've earned up to $2,000 in free bets from pointsbet. claim now and make your first sportsbook deposit to unlock!</p>\",\n",
       " '<p>boost your job post on indeed. the first £100 sponsored job credit is on us.</p>',\n",
       " 'your purchase gives you access to amazing deals from kogan.com. sign up for their emails for incredible offers',\n",
       " \"<p>you've earned $150 off smiledirectclub aligners &amp; a $25 prepaid mastercard for completing your scan or returning your impression kit. sign up to claim this limited time offer.</p>\",\n",
       " '<p>download and sign in to the bws app to go into the draw to win 1 of 5 $500 wish vouchers!</p>',\n",
       " \"<p>you've unlocked 10% off your next first choice liquor market order! sign up today for exclusive access to special offers and promotions.</p>\",\n",
       " \"here's $20 off your first order plus free delivery* with ezibuy. sign up and find the latest in fashion &amp; homewares online now.\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e1b20f417f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    220\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(sample).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21821789, 0.21821789, 0.21821789, 0.21821789, 0.21821789,\n",
       "        0.43643578, 0.21821789, 0.21821789, 0.21821789, 0.21821789,\n",
       "        0.21821789, 0.21821789, 0.21821789, 0.21821789, 0.21821789,\n",
       "        0.21821789, 0.21821789, 0.21821789]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
