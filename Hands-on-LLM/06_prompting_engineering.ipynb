{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8UTx1Z0ZjEw_",
        "outputId": "fcc19775-7789-4fea-96fb-7a3b1100de04",
        "colab": {
          "referenced_widgets": [
            "f6ac83638b3e44bcbc30c5d4d1a78376",
            "e86e2c4b876f416c931a9e60827d3409",
            "97ef3b1560a8408a82cc7decfffcb360",
            "ebd92829726d402f8f472283220f924f",
            "ed2fe8690def4436ad5381c02618e8ff",
            "5a30629ef3df41d8b5540413a033816f",
            "8654061102874e72b163e641a7016bf0",
            "e502bc10acdc4c6799824b441f4add3f",
            "98065a0716dd4731b2ecedecc54b6541",
            "57d385ae2b274c45ae77643feca89193",
            "785843426f614dc78056ed5d198f0f54"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6ac83638b3e44bcbc30c5d4d1a78376"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1eMbO_dyjExA"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RYqanVZkjExA",
        "outputId": "fcb68e1b-f6ec-496c-beae-1649633c4f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why did the chicken join the band? Because it had the drumsticks!\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
        "]\n",
        "\n",
        "# Generate the output\n",
        "output = pipe(messages)\n",
        "print(output[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "33r_U8_MjExA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc923f0e-d52c-4c36-d5fd-f98303b0eb0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "Create a funny joke about chickens.<|end|>\n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "# Apply prompt template\n",
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a high temperature\n",
        "output = pipe(messages, do_sample=True, temperature=1)\n",
        "print(output[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Nr0z1Mjuni",
        "outputId": "c2aa43ec-7be6-4876-a44f-3a4a5b520231"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why don't chickens use computers? Because their fingers aren't long enough!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a high top_p\n",
        "output = pipe(messages, do_sample=True, top_p=1)\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXvB4VLQjy0M",
        "outputId": "efa4e2ab-8d58-4bf2-bf34-8807e011cedf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why did the farmer decide to get a new job? Because every person he talked to was worse than a hen in a boss fight!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instruction-Based Prompting\n",
        "\n",
        "- Specificity\n",
        "\n",
        "Accurately describe what you want to achieve. Instead of asking the LLM to “Write a description for a product” ask it to “Write a description for a product in less than two sentences and use a formal tone.”\n",
        "\n",
        "- Hallucination\n",
        "\n",
        "LLMs may generate incorrect information confidently, which is referred to as hallucination. To reduce its impact, we can ask the LLM to only generate an answer if it knows the answer. If it does not know the answer, it can respond with “I don’t know.”\n",
        "\n",
        "- Order\n",
        "\n",
        "Either begin or end your prompt with the instruction. Especially with long prompts, information in the middle is often forgotten.1 LLMs tend to focus on information either at the beginning of a prompt (primacy effect) or the end of a prompt (recency effect)."
      ],
      "metadata": {
        "id": "wAxjJ9W5kVz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These advanced components can quickly make a prompt quite complex. Some common components are:\n",
        "\n",
        "- Persona\n",
        "\n",
        "Describe what role the LLM should take on. For example, use “You are an expert in astrophysics” if you want to ask a question about astrophysics.\n",
        "\n",
        "- Instruction\n",
        "\n",
        "The task itself. Make sure this is as specific as possible. We do not want to leave much room for interpretation.\n",
        "\n",
        "- Context\n",
        "\n",
        "Additional information describing the context of the problem or task. It answers questions like “What is the reason for the instruction?”\n",
        "\n",
        "- Format\n",
        "\n",
        "The format the LLM should use to output the generated text. Without it, the LLM will come up with a format itself, which is troublesome in automated systems.\n",
        "\n",
        "- Audience\n",
        "\n",
        "The target of the generated text. This also describes the level of the generated output. For education purposes, it is often helpful to use ELI5 (“Explain it like I’m 5”).\n",
        "\n",
        "- Tone\n",
        "\n",
        "The tone of voice the LLM should use in the generated text. If you are writing a formal email to your boss, you might not want to use an informal tone of voice.\n",
        "\n",
        "- Data\n",
        "\n",
        "The main data related to the task itself.\n"
      ],
      "metadata": {
        "id": "vOK4iEHSkv6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt components\n",
        "persona = \"You are an expert in Large Language models. You excel at breaking down complex papers into digestible summaries.\\n\"\n",
        "instruction = \"Summarize the key findings of the paper provided.\\n\"\n",
        "context = \"Your summary should extract the most crucial points that can help researchers quickly understand the most vital information of the paper.\\n\"\n",
        "data_format = \"Create a bullet-point summary that outlines the method. Follow this up with a concise paragraph that encapsulates the main results.\\n\"\n",
        "audience = \"The summary is designed for busy researchers that quickly need to grasp the newest trends in Large Language Models.\\n\"\n",
        "tone = \"The tone should be professional and clear.\\n\"\n",
        "text = \"MY TEXT TO SUMMARIZE\"\n",
        "data = f\"Text to summarize: {text}\"\n",
        "\n",
        "# The full prompt - remove and add pieces to view its impact on the generated output\n",
        "query = persona + instruction + context + data_format + audience + tone + data"
      ],
      "metadata": {
        "id": "c1B7vHe-kEGX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "XUnBPv1dr4Fw",
        "outputId": "2d6ac625-8b81-4ebf-ee75-cd45fe76159e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are an expert in Large Language models. You excel at breaking down complex papers into digestible summaries.\\nSummarize the key findings of the paper provided.\\nYour summary should extract the most crucial points that can help researchers quickly understand the most vital information of the paper.\\nCreate a bullet-point summary that outlines the method. Follow this up with a concise paragraph that encapsulates the main results.\\nThe summary is designed for busy researchers that quickly need to grasp the newest trends in Large Language Models.\\nThe tone should be professional and clear.\\nText to summarize: MY TEXT TO SUMMARIZE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In-Context Learning: Providing Examples"
      ],
      "metadata": {
        "id": "0Y-QsI5LsC6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a single example of using the made-up word in a sentence\n",
        "one_shot_prompt = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"A 'Gigamuru' is a type of Japanese musical instrument. An example of a sentence that uses the word Gigamuru is:\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"I have a Gigamuru that my uncle gave me as a gift. I love to play it at home.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"To 'screeg' something is to swing a sword at it. An example of a sentence that uses the word screeg is:\"\n",
        "    }\n",
        "]\n",
        "print(tokenizer.apply_chat_template(one_shot_prompt, tokenize=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI-XnywUsFEV",
        "outputId": "fb040124-7f00-4530-b33a-077b094da275"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "A 'Gigamuru' is a type of Japanese musical instrument. An example of a sentence that uses the word Gigamuru is:<|end|>\n",
            "<|assistant|>\n",
            "I have a Gigamuru that my uncle gave me as a gift. I love to play it at home.<|end|>\n",
            "<|user|>\n",
            "To 'screeg' something is to swing a sword at it. An example of a sentence that uses the word screeg is:<|end|>\n",
            "<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the output\n",
        "outputs = pipe(one_shot_prompt)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adTCqmCSsJsd",
        "outputId": "fb364dd6-30f4-47a4-ffeb-f5dcb2d8c03a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " During the medieval reenactment, the knight skillfully screeged the wooden shield to demonstrate his prowess in combat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain Prompting: Breaking up the Problem"
      ],
      "metadata": {
        "id": "EOuz94YTsTCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create name and slogan for a product\n",
        "product_prompt = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a name and slogan for a chatbot that leverages LLMs.\"}\n",
        "]\n",
        "outputs = pipe(product_prompt)\n",
        "product_description = outputs[0][\"generated_text\"]\n",
        "print(product_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDBICKl4sVKS",
        "outputId": "13b15bdc-503a-4df9-86fe-ebc0790781d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Name: ChatSage\n",
            "Slogan: \"Unleashing the power of AI to enhance your conversations.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on a name and slogan for a product, generate a sales pitch\n",
        "sales_prompt = [\n",
        "    {\"role\": \"user\", \"content\": f\"Generate a very short sales pitch for the following product: '{product_description}'\"}\n",
        "]\n",
        "outputs = pipe(sales_prompt)\n",
        "sales_pitch = outputs[0][\"generated_text\"]\n",
        "print(sales_pitch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qAUPnvPsZWR",
        "outputId": "c7c5ecc7-2c33-47f1-f778-29528c66e01c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Introducing ChatSage, the revolutionary AI-powered tool designed to elevate your conversations to new heights. With our cutting-edge technology, we unleash the power of AI to enhance your interactions, making every conversation more engaging, insightful, and meaningful. Experience the future of communication with ChatSage – where AI meets human connection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reasoning with Generative Models"
      ],
      "metadata": {
        "id": "aClMaNrysjDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chain-of-Thought: Think Before Answering"
      ],
      "metadata": {
        "id": "FN1mODW-sovW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answering with chain-of-thought\n",
        "cot_prompt = [\n",
        "    {\"role\": \"user\", \"content\": \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\"},\n",
        "    {\"role\": \"user\", \"content\": \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"}\n",
        "]\n",
        "\n",
        "# Generate the output\n",
        "outputs = pipe(cot_prompt)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3NYFQ8wsqJ5",
        "outputId": "053eeca5-4ed0-487d-e06b-5c5a4660111f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The cafeteria started with 23 apples. They used 20 apples to make lunch, so they had 23 - 20 = 3 apples left. After buying 6 more apples, they now have 3 + 6 = 9 apples. The answer is 9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot chain-of-thought\n",
        "zeroshot_cot_prompt = [\n",
        "    {\"role\": \"user\", \"content\": \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have? Let's think step-by-step.\"}\n",
        "]\n",
        "\n",
        "# Generate the output\n",
        "outputs = pipe(zeroshot_cot_prompt)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZLo131Lsuce",
        "outputId": "f1100125-b4d0-4a58-dac2-112d08954def"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Step 1: Start with the initial number of apples in the cafeteria, which is 23.\n",
            "\n",
            "Step 2: Subtract the number of apples used to make lunch, which is 20.\n",
            "23 - 20 = 3 apples remaining.\n",
            "\n",
            "Step 3: Add the number of apples bought, which is 6.\n",
            "3 + 6 = 9 apples.\n",
            "\n",
            "So, the cafeteria now has 9 apples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Self-Consistency: Sampling Outputs"
      ],
      "metadata": {
        "id": "R2iqCQMzs40N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tree-of-Thought: Exploring Intermediate Steps"
      ],
      "metadata": {
        "id": "O97ztBHAtLaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot tree-of-thought\n",
        "zeroshot_tot_prompt = [\n",
        "    {\"role\": \"user\", \"content\": \"Imagine three different experts are answering this question. All experts will write down 1 step of their thinking, then share it with the group. Then all experts will go on to the next step, etc. If any expert realizes they're wrong at any point then they leave. The question is 'The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?' Make sure to discuss the results.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "jaRH7GJLtMb3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the output\n",
        "outputs = pipe(zeroshot_tot_prompt)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivq6ywpGtS2L",
        "outputId": "e2b2299b-e47e-4e29-8137-5b7007cb6123"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Expert 1:\n",
            "Step 1: Start with the initial number of apples, which is 23.\n",
            "\n",
            "Expert 2:\n",
            "Step 1: Subtract the number of apples used for lunch, which is 20.\n",
            "Step 2: Add the number of apples bought, which is 6.\n",
            "\n",
            "Expert 3:\n",
            "Step 1: Start with the initial number of apples, which is 23.\n",
            "Step 2: Subtract the number of apples used for lunch, which is 20.\n",
            "Step 3: Add the number of apples bought, which is 6.\n",
            "\n",
            "Results:\n",
            "All three experts arrived at the same answer: 23 - 20 + 6 = 9 apples remaining in the cafeteria.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output Verification"
      ],
      "metadata": {
        "id": "_lsSFQ94tYp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Structured output\n",
        "By default, most generative models create free-form text without adhering to specific structures other than those defined by natural language. Some use cases require their output to be structured in certain formats, like JSON.\n",
        "\n",
        "- Valid output\n",
        "Even if we allow the model to generate structured output, it still has the capability to freely generate its content. For instance, when a model is asked to output either one of two choices, it should not come up with a third.\n",
        "\n",
        "- Ethics\n",
        "Some open source generative models have no guardrails and will generate outputs that do not consider safety or ethical considerations. For instance, use cases might require the output to be free of profanity, personally identifiable information (PII), bias, cultural stereotypes, etc.\n",
        "\n",
        "-Accuracy\n",
        "Many use cases require the output to adhere to certain standards or performance. The aim is to double-check whether the generated information is factually accurate, coherent, or free from hallucination.\n"
      ],
      "metadata": {
        "id": "wZjC7L-9tkrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot learning: Providing no examples\n",
        "zeroshot_prompt = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a character profile for an RPG game in JSON format.\"}\n",
        "]\n",
        "\n",
        "# Generate the output\n",
        "outputs = pipe(zeroshot_prompt)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9PJG9kytjai",
        "outputId": "3430ffcb-d48b-4b5b-f3a3-d70eacce913f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ```json\n",
            "{\n",
            "  \"name\": \"Aria Stormbringer\",\n",
            "  \"class\": \"Warrior\",\n",
            "  \"race\": \"Human\",\n",
            "  \"level\": 10,\n",
            "  \"attributes\": {\n",
            "    \"strength\": 18,\n",
            "    \"dexterity\": 12,\n",
            "    \"constitution\": 16,\n",
            "    \"intelligence\": 8,\n",
            "    \"wisdom\": 10,\n",
            "    \"charisma\": 14\n",
            "  },\n",
            "  \"skills\": {\n",
            "    \"melee\": 15,\n",
            "    \"ranged\": 10,\n",
            "    \"magic\": 5,\n",
            "    \"stealth\": 12,\n",
            "    \"acrobatics\": 10,\n",
            "    \"animal_handling\": 8\n",
            "  },\n",
            "  \"equipment\": {\n",
            "    \"weapon\": \"Two-handed Axe\",\n",
            "    \"armor\": \"Chainmail\",\n",
            "    \"shield\": \"Breastplate\",\n",
            "    \"accessories\": [\n",
            "      \"Warhammer\",\n",
            "      \"Chainmail Boots\",\n",
            "      \"Leather Gloves\"\n",
            "    ]\n",
            "  },\n",
            "  \"background\": \"Aria grew up in a small village on the outskirts of a large city. She was always fascinated by the stories of great warriors and adventurers who roamed the lands. When she was just a child, she witnessed a group of bandits attack her village, and she vowed to become a warrior to protect her people. She trained hard and eventually joined a group of adventurers who set out to explore the world and fight evil.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-shot learning: Providing an example of the output structure\n",
        "one_shot_template = \"\"\"Create a short character profile for an RPG game. Make sure to only use this format:\n",
        "\n",
        "{\n",
        "  \"description\": \"A SHORT DESCRIPTION\",\n",
        "  \"name\": \"THE CHARACTER'S NAME\",\n",
        "  \"armor\": \"ONE PIECE OF ARMOR\",\n",
        "  \"weapon\": \"ONE OR MORE WEAPONS\"\n",
        "}\n",
        "\"\"\"\n",
        "one_shot_prompt = [\n",
        "    {\"role\": \"user\", \"content\": one_shot_template}\n",
        "]\n",
        "\n",
        "# Generate the output\n",
        "outputs = pipe(one_shot_prompt)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk2moxgmtzJ4",
        "outputId": "f17d537c-89ee-4adf-dac9-059b521dd9e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " {\n",
            "  \"description\": \"A cunning rogue with a mysterious past, skilled in stealth and deception.\",\n",
            "  \"name\": \"Shadowcloak\",\n",
            "  \"armor\": \"Leather Hood\",\n",
            "  \"weapon\": \"Dagger\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grammar: Constrained Sampling\n"
      ],
      "metadata": {
        "id": "Y7_UNQBst93b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "del model, tokenizer, pipe\n",
        "\n",
        "# Flush memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QwTlQa04t-4O"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcX5YCmuN3B",
        "outputId": "4b6052b2-bb60-43fe-f222-1dd0e7c790de"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.90.tar.gz (63.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.90-cp310-cp310-linux_x86_64.whl size=3413693 sha256=db4a14fb7ce2c0fa7b2c9dcad4f598a90e11c4e3ee6c58ee2163304b246a2fa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/67/02/f950031435db4a5a02e6269f6adb6703bf1631c3616380f3c6\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp.llama import Llama\n",
        "\n",
        "# Load Phi-3\n",
        "llm = Llama.from_pretrained(\n",
        "    repo_id=\"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
        "    filename=\"*fp16.gguf\",\n",
        "    n_gpu_layers=-1,\n",
        "    n_ctx=2048,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f1bddeeb7b9e460e8c771afd180f8c0d",
            "8ef0bed472d6438ca99148a6b424df9d",
            "d812eba5c18e4657bc9c286c3fdf89ae",
            "c773490543c243d799fd66ca2e1b1106",
            "830adc1ab31d48c2a3222aed84a54ff5",
            "17c8fcdc4a064d209d7e8187c6ef56c4",
            "4cd5470b80454c5183dc1100bd27e38c",
            "e9e03df4972b423495669e9c7abdf3fd",
            "4d868d83a0dc441c89eac9984b57c719",
            "73b9b7adfad546b5aeba3bbd0cdde327",
            "e15fa0ceaec54957b9b3ebc1546731ef"
          ]
        },
        "id": "mJzHdURluD-k",
        "outputId": "7847e9d8-c9fc-409c-b0f0-249f7726341e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Phi-3-mini-4k-instruct-fp16.gguf:   0%|          | 0.00/7.64G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1bddeeb7b9e460e8c771afd180f8c0d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate output\n",
        "output = llm.create_chat_completion(\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Create a warrior for an RPG in JSON format.\"},\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"},\n",
        "    temperature=0,\n",
        ")['choices'][0]['message'][\"content\"]"
      ],
      "metadata": {
        "id": "M3BPs2-uuHQb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Format as json\n",
        "json_output = json.dumps(json.loads(output), indent=4)\n",
        "print(json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvkfQ_iVuin7",
        "outputId": "421bdceb-afb9-4b0d-aae9-f163cc3372fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"warrior\": {\n",
            "        \"name\": \"Eldric Stormbringer\",\n",
            "        \"class\": \"Warrior\",\n",
            "        \"level\": 5,\n",
            "        \"attributes\": {\n",
            "            \"strength\": 18,\n",
            "            \"dexterity\": 10,\n",
            "            \"constitution\": 16,\n",
            "            \"intelligence\": 8,\n",
            "            \"wisdom\": 10,\n",
            "            \"charisma\": 12\n",
            "        },\n",
            "        \"skills\": [\n",
            "            {\n",
            "                \"name\": \"Martial Arts\",\n",
            "                \"proficiency\": 20,\n",
            "                \"description\": \"Expert in hand-to-hand combat and weapon handling.\"\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Shield Block\",\n",
            "                \"proficiency\": 18,\n",
            "                \"description\": \"Highly skilled at deflecting attacks with a shield.\"\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Heavy Armor\",\n",
            "                \"proficiency\": 16,\n",
            "                \"description\": \"Expertly equipped with heavy armor for protection.\"\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Survival\",\n",
            "                \"proficiency\": 14,\n",
            "                \"description\": \"Adept at finding food, water, and shelter in the wilderness.\"\n",
            "            }\n",
            "        ],\n",
            "        \"equipment\": [\n",
            "            {\n",
            "                \"name\": \"Iron Sword\",\n",
            "                \"type\": \"Weapon\",\n",
            "                \"damage\": 12,\n",
            "                \"durability\": 100\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Chainmail Armor\",\n",
            "                \"type\": \"Armor\",\n",
            "                \"defense\": 18,\n",
            "                \"durability\": 100\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Leather Boots\",\n",
            "                \"type\": \"Armor\",\n",
            "                \"defense\": 8,\n",
            "                \"durability\": 100\n",
            "            }\n",
            "        ],\n",
            "        \"abilities\": [\n",
            "            {\n",
            "                \"name\": \"Berserker Rage\",\n",
            "                \"description\": \"Increases strength and attack power for a short duration.\"\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Shield Wall\",\n",
            "                \"description\": \"Forms a defensive barrier with allies, reducing incoming damage.\"\n",
            "            },\n",
            "            {\n",
            "                \"name\": \"Battle Cry\",\n",
            "                \"description\": \"Inspires nearby allies, increasing their attack power temporarily.\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwtlfNaDukrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6ac83638b3e44bcbc30c5d4d1a78376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86e2c4b876f416c931a9e60827d3409",
              "IPY_MODEL_97ef3b1560a8408a82cc7decfffcb360",
              "IPY_MODEL_ebd92829726d402f8f472283220f924f"
            ],
            "layout": "IPY_MODEL_ed2fe8690def4436ad5381c02618e8ff"
          }
        },
        "e86e2c4b876f416c931a9e60827d3409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a30629ef3df41d8b5540413a033816f",
            "placeholder": "​",
            "style": "IPY_MODEL_8654061102874e72b163e641a7016bf0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "97ef3b1560a8408a82cc7decfffcb360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e502bc10acdc4c6799824b441f4add3f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98065a0716dd4731b2ecedecc54b6541",
            "value": 2
          }
        },
        "ebd92829726d402f8f472283220f924f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d385ae2b274c45ae77643feca89193",
            "placeholder": "​",
            "style": "IPY_MODEL_785843426f614dc78056ed5d198f0f54",
            "value": " 2/2 [00:02&lt;00:00,  1.34s/it]"
          }
        },
        "ed2fe8690def4436ad5381c02618e8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a30629ef3df41d8b5540413a033816f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8654061102874e72b163e641a7016bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e502bc10acdc4c6799824b441f4add3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98065a0716dd4731b2ecedecc54b6541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57d385ae2b274c45ae77643feca89193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "785843426f614dc78056ed5d198f0f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1bddeeb7b9e460e8c771afd180f8c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ef0bed472d6438ca99148a6b424df9d",
              "IPY_MODEL_d812eba5c18e4657bc9c286c3fdf89ae",
              "IPY_MODEL_c773490543c243d799fd66ca2e1b1106"
            ],
            "layout": "IPY_MODEL_830adc1ab31d48c2a3222aed84a54ff5"
          }
        },
        "8ef0bed472d6438ca99148a6b424df9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c8fcdc4a064d209d7e8187c6ef56c4",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd5470b80454c5183dc1100bd27e38c",
            "value": "Phi-3-mini-4k-instruct-fp16.gguf: 100%"
          }
        },
        "d812eba5c18e4657bc9c286c3fdf89ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9e03df4972b423495669e9c7abdf3fd",
            "max": 7643295904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d868d83a0dc441c89eac9984b57c719",
            "value": 7643295904
          }
        },
        "c773490543c243d799fd66ca2e1b1106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b9b7adfad546b5aeba3bbd0cdde327",
            "placeholder": "​",
            "style": "IPY_MODEL_e15fa0ceaec54957b9b3ebc1546731ef",
            "value": " 7.64G/7.64G [05:49&lt;00:00, 21.8MB/s]"
          }
        },
        "830adc1ab31d48c2a3222aed84a54ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c8fcdc4a064d209d7e8187c6ef56c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd5470b80454c5183dc1100bd27e38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9e03df4972b423495669e9c7abdf3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d868d83a0dc441c89eac9984b57c719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73b9b7adfad546b5aeba3bbd0cdde327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15fa0ceaec54957b9b3ebc1546731ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}