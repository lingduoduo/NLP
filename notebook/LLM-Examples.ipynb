{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd32ff2-6fa5-4d75-bde5-7fd88cbbeef5",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f8a129-73dd-4891-a5a8-a65e72216ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ling/miniconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertModel\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7117c22-bea0-4152-bf3f-d7275d79b9c5",
   "metadata": {},
   "source": [
    "The provided code initializes a BERT (Bidirectional Encoder Representations from Transformers) model by loading a pre-trained version known as 'bert-base-uncased' from the Transformers package. BERT is a widely used natural language processing model that can be further explored for different embedding and attention layers, allowing for fine-tuned analysis and manipulation of text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c747aac-184c-40d6-9908-26862e9d0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9030e030-dea1-4966-a87c-909ac0c7dbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.encoder.layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab45a5ed-070b-46ab-ba19-2407641a328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 199 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "embeddings.word_embeddings.weight                                           (30522, 768)\n",
      "embeddings.position_embeddings.weight                                         (512, 768)\n",
      "embeddings.token_type_embeddings.weight                                         (2, 768)\n",
      "embeddings.LayerNorm.weight                                                       (768,)\n",
      "embeddings.LayerNorm.bias                                                         (768,)\n",
      "\n",
      "==== First Encoder ====\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight                                   (768, 768)\n",
      "encoder.layer.0.attention.self.query.bias                                         (768,)\n",
      "encoder.layer.0.attention.self.key.weight                                     (768, 768)\n",
      "encoder.layer.0.attention.self.key.bias                                           (768,)\n",
      "encoder.layer.0.attention.self.value.weight                                   (768, 768)\n",
      "encoder.layer.0.attention.self.value.bias                                         (768,)\n",
      "encoder.layer.0.attention.output.dense.weight                                 (768, 768)\n",
      "encoder.layer.0.attention.output.dense.bias                                       (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.weight                                 (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.bias                                   (768,)\n",
      "encoder.layer.0.intermediate.dense.weight                                    (3072, 768)\n",
      "encoder.layer.0.intermediate.dense.bias                                          (3072,)\n",
      "encoder.layer.0.output.dense.weight                                          (768, 3072)\n",
      "encoder.layer.0.output.dense.bias                                                 (768,)\n",
      "encoder.layer.0.output.LayerNorm.weight                                           (768,)\n",
      "encoder.layer.0.output.LayerNorm.bias                                             (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "pooler.dense.weight                                                           (768, 768)\n",
      "pooler.dense.bias                                                                 (768,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "named_params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(named_params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in named_params[0:5]:\n",
    "    print(\"{:<55} {:>32}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Encoder ====\\n')\n",
    "for p in named_params[5:21]:\n",
    "    print(\"{:<55} {:>32}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in named_params[-2:]:\n",
    "    print(\"{:<55} {:>32}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c3a28-bd0e-4499-9069-574a45115ccb",
   "metadata": {},
   "source": [
    "### Search semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be43f978-986b-4f01-beb7-7e2a1c70bcce",
   "metadata": {},
   "source": [
    "The Hugging Face summarization task page lists models that support summarization. In this section, we will the following resources:\n",
    "\n",
    "- data: We will work with the 'xsum dataset,' containing a collection of BBC articles and their corresponding summaries. This dataset serves as the foundation for our tasks.\n",
    "\n",
    "- model: Our chosen model is the 't5-small model,' with 60 million parameters (equivalent to 242MB for PyTorch). T5, an encoder-decoder model developed by Google, boasts versatility, supporting various tasks including summarization, translation, question-answering, and text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08e40f8-a60a-4905-83f9-78aa158392c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xsum (/Users/ling/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 143.52it/s]\n"
     ]
    }
   ],
   "source": [
    "xsum_dataset = load_dataset(\n",
    "    \"xsum\", version=\"1.2.0\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397a4f0-aab2-4211-b9cc-f0e06dc5c390",
   "metadata": {},
   "source": [
    "This dataset provides 3 columns:\n",
    "\n",
    "- document: the BBC article text\n",
    "- summary: a \"ground-truth\" summary --> Note how subjective this \"ground-truth\" is. Is this the same summary you would write? This a great example of how many LLM applications do not have obvious \"right\" answers.\n",
    "- id: article ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbab8df-467b-4004-8ad1-9aecdd5ac626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a sample of 100 rows\n",
    "xsum_sample = xsum_dataset[\"train\"].select(range(100)).to_pandas()\n",
    "\n",
    "# Combining 'document' and 'summary' columns\n",
    "xsum_sample[\"combined\"] = (\n",
    "    \"Document: \" + xsum_sample.document.str.strip() + \"; Summary: \" + xsum_sample.summary.str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ddf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#encoding the data\n",
    "encoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n",
    "encoded_data = encoder.encode(xsum_sample[\"combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ea4500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12973621, -0.07995631, -0.02103529, ...,  0.01458149,\n",
       "        -0.04181127,  0.05969846],\n",
       "       [-0.10183057, -0.00813391,  0.01535374, ...,  0.0399589 ,\n",
       "        -0.10245837,  0.08624614],\n",
       "       [-0.06544376, -0.22466165,  0.01042661, ...,  0.06865784,\n",
       "         0.07314408,  0.01244242],\n",
       "       ...,\n",
       "       [-0.02983218,  0.0890516 , -0.07677924, ...,  0.01902936,\n",
       "        -0.02879047,  0.09262642],\n",
       "       [ 0.00134849, -0.07791834,  0.02811532, ...,  0.18549399,\n",
       "         0.0806486 , -0.11673684],\n",
       "       [-0.17274612,  0.04478129,  0.00123185, ...,  0.10003569,\n",
       "         0.03951619,  0.03509405]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81792db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "faiss.normalize_L2(encoded_data)\n",
    "index.add_with_ids(encoded_data, np.arange(len(encoded_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3c08df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document: The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we\\'re neglected or forgotten,\" she said.\\n\"That may not be true but it is perhaps my perspective over the last few days.\\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\\nThe Labour Party\\'s deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.; Summary: Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_text = xsum_sample[\"combined\"][0]\n",
    "search_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd69adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_vector = encoder.encode(search_text)\n",
    "_vector = np.array([search_vector])\n",
    "faiss.normalize_L2(_vector)\n",
    "\n",
    "k = 2\n",
    "distances, ann = index.search(_vector, k=k)\n",
    "results = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce097a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.6326008]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a84623a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2a14265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A 13ft-deep hole causing widespread disruption to trains in south London has been found to have opened above an active sewer.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716c604",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e051c8e-7fb7-47c9-9164-78490e6331c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=60,\n",
    "    truncation=True,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68ff9cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1ed3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49c7fb3d-a209-4b3a-bed0-7df30a3f9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to a batch of articles\n",
    "results = summarizer(xsum_sample[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a39a4766-ce68-4f01-a3e3-6d500728b02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the full cost of damage in Newton Stewart is s...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastian Vettel will start third ahead of tea...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 67-year-old is accused of committing the o...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man receiving psychiatric treatment at the c...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregor Townsend gave a debut to powerhouse win...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the 25-year-old was hit by a motorbike during ...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gundogan will not be fit for the start of the ...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   generated_summary  \\\n",
       "0  the full cost of damage in Newton Stewart is s...   \n",
       "1  a fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Sebastian Vettel will start third ahead of tea...   \n",
       "3  the 67-year-old is accused of committing the o...   \n",
       "4  a man receiving psychiatric treatment at the c...   \n",
       "5  Gregor Townsend gave a debut to powerhouse win...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  the 25-year-old was hit by a motorbike during ...   \n",
       "8  gundogan will not be fit for the start of the ...   \n",
       "9  the crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Clean-up operations are continuing across the ...   \n",
       "1  Two tourist buses have been destroyed by fire ...   \n",
       "2  Lewis Hamilton stormed to pole position at the...   \n",
       "3  A former Lincolnshire Police officer carried o...   \n",
       "4  An armed man who locked himself into a room at...   \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...   \n",
       "6  A man with links to a car that was involved in...   \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...   \n",
       "8  Manchester City midfielder Ilkay Gundogan says...   \n",
       "9  A jogger has been hit by an unmarked police ca...   \n",
       "\n",
       "                                            document  \n",
       "0  The full cost of damage in Newton Stewart, one...  \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...  \n",
       "2  Ferrari appeared in a position to challenge un...  \n",
       "3  John Edward Bates, formerly of Spalding, Linco...  \n",
       "4  Patients and staff were evacuated from Cerahpa...  \n",
       "5  Simone Favaro got the crucial try with the las...  \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...  \n",
       "7  Belgian cyclist Demoitie died after a collisio...  \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...  \n",
       "9  The crash happened about 07:20 GMT at the junc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"summary_text\": \"generated_summary\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(xsum_sample))[\n",
    "        [\"generated_summary\", \"summary\", \"document\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e428da-bb6a-4757-b341-0e90a6c02b2f",
   "metadata": {},
   "source": [
    "### Search and sampling in inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15021d61-8839-4d7a-b8db-7d9335178fdc",
   "metadata": {},
   "source": [
    "You may see parameters like `num_beams`, `do_sample`, etc. specified in Hugging Face pipelines.  These are inference configurations.\n",
    "\n",
    "LLMs work by predicting (generating) the next token, then the next, and so on.  The goal is to generate a high probability sequence of tokens, which is essentially a search through the (enormous) space of potential sequences.\n",
    "\n",
    "To do this search, LLMs use one of two main methods:\n",
    "* **Search**: Given the tokens generated so far, pick the next most likely token in a \"search.\"\n",
    "   * **Greedy search** (default): Pick the single next most likely token in a greedy search.\n",
    "   * **Beam search**: Greedy search can be extended via beam search, which searches down several sequence paths, via the parameter `num_beams`.\n",
    "* **Sampling**: Given the tokens generated so far, pick the next token by sampling from the predicted distribution of tokens.\n",
    "   * **Top-K sampling**: The parameter `top_k` modifies sampling by limiting it to the `k` most likely tokens.\n",
    "   * **Top-p sampling**: The parameter `top_p` modifies sampling by limiting it to the most likely tokens up to probability mass `p`.\n",
    "\n",
    "You can toggle between search and sampling via parameter `do_sample`.\n",
    "\n",
    "For more background on search and sampling, see [this Hugging Face blog post](https://huggingface.co/blog/how-to-generate).\n",
    "\n",
    "We will illustrate these various options below using our summarization pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d39ed141-bdd3-42fc-81e2-05c759939c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can instead do a beam search by specifying num_beams.\n",
    "summarizer(xsum_sample[\"document\"][0], num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "212e9573-1594-4c99-a641-cf4c93de77e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the waters breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we could use sampling.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a885e929-8161-4ded-bf31-9a46ac392000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining wall, flooding many commercial properties .'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True, top_k=10, top_p=0.8)›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24ff1057-b148-443b-9624-5125fa59693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f1506b-f136-42a7-996b-9123e1abadd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the full cost of damage in Newton Stewart is still being assessed. many roads in peeblesshire remain badly affected\n",
       "by standing water. the water breached a retaining wall, flooding many commercial properties.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the full cost of damage in Newton Stewart is still being assessed. many roads in peeblesshire remain badly affected\n",
       "by standing water. the water breached a retaining wall, flooding many commercial properties.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pre-trained tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "\n",
    "# For summarization, T5-small expects a prefix \"summarize: \"\n",
    "# so we prepend that to each article as a prompt.\n",
    "\n",
    "articles = list(map(lambda article: \"summarize: \" + article, xsum_sample[\"document\"]))\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024,\n",
    "    return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "# Generate summaries\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=60,\n",
    ")\n",
    "# Decode the generated summaries\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "\n",
    "print(decoded_summaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d74048-beb3-4805-a3be-f56f884b7e3f",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087bee1-58ce-46ff-a4eb-94892d3f8315",
   "metadata": {},
   "source": [
    "Zero-shot classification (or zero-shot learning) is the task of classifying a piece of text into one of a few given categories or labels, without having explicitly trained the model to predict those categories beforehand. The idea appeared in literature before modern LLMs, but recent advances in LLMs have made zero-shot learning much more flexible and powerful.\n",
    "\n",
    "Background reading: See the Hugging Face task page on zero-shot classification or Wikipedia on zero-shot learning.\n",
    "\n",
    "In this section, we will use:\n",
    "\n",
    "Data: a few example articles from the xsum dataset used in the Summarization section above. Our goal is to label news articles under a few categories.\n",
    "Model: nli-deberta-v3-small, a fine-tuned version of the DeBERTa model. The DeBERTa base model was developed by Microsoft and is one of several models derived from BERT; for more details on DeBERTa, see the Hugging Face doc page, the code on GitHub, or the research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04b39106-5d0b-4314-9c5e-494c9114e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linghuang/miniconda3/envs/langchain/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "zero_shot_pipeline = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-deberta-v3-small\",\n",
    ")\n",
    "\n",
    "\n",
    "def categorize_article(article: str) -> None:\n",
    "    \"\"\"\n",
    "    This helper function defines the categories (labels) which the model must use to label articles.\n",
    "    Note that our model was NOT fine-tuned to use these specific labels,\n",
    "    but it \"knows\" what the labels mean from its more general training.\n",
    "\n",
    "    This function then prints out the predicted labels alongside their confidence scores.\n",
    "    \"\"\"\n",
    "    results = zero_shot_pipeline(\n",
    "        article,\n",
    "        candidate_labels=[\n",
    "            \"politics\",\n",
    "            \"finance\",\n",
    "            \"sports\",\n",
    "            \"science and technology\",\n",
    "            \"pop culture\",\n",
    "            \"breaking news\",\n",
    "        ],\n",
    "    )\n",
    "    # Print the results nicely\n",
    "    del results[\"sequence\"]\n",
    "    display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5593d5-a67d-4dea-bc2a-49604993a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science and technology</td>\n",
       "      <td>0.762033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking news</td>\n",
       "      <td>0.089980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>0.059526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance</td>\n",
       "      <td>0.036244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.027556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.024660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   labels    scores\n",
       "0  science and technology  0.762033\n",
       "1           breaking news  0.089980\n",
       "2             pop culture  0.059526\n",
       "3                 finance  0.036244\n",
       "4                  sports  0.027556\n",
       "5                politics  0.024660"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorize_article(\n",
    "    \"\"\"\n",
    "A large language model (LLM) is a language model notable for its ability to achieve general-purpose language understanding and generation. LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive self-supervised and semi-supervised training process.[1] LLMs are artificial neural networks following a transformer architecture.[2]\n",
    "\n",
    "They can be used for text generation by taking an input text and repeatedly predicting the next token or word.[3] Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[4] They are thought to acquire knowledge about syntax, semantics and \"ontology\" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[5]\n",
    "\n",
    "Notable examples include OpenAI's GPT models (e.g., GPT-3.5 and GPT-4, used in ChatGPT), Google's PaLM (used in Bard), and Meta's LLaMA, as well as BLOOM, Ernie 3.0 Titan, and Anthropic's Claude 2.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721a6d3-dfe4-4ba7-96e2-0ba5c4ffc760",
   "metadata": {},
   "source": [
    "### Few-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb37eff-eac4-4307-81d4-50d274c12d41",
   "metadata": {},
   "source": [
    "In few-shot learning tasks, you give the model an instruction, a few query-response examples of how to follow that instruction, and then a new query. The model must generate the response for that new query. This technique has pros and cons: it is very powerful and allows models to be reused for many more applications, but it can be finicky and require significant prompt engineering to get good and reliable results.\n",
    "\n",
    "Background reading: See the Wikipedia page on few-shot learning or this Hugging Face blog about few-shot learning.\n",
    "\n",
    "In this section, we will use:\n",
    "\n",
    "- Task: Few-shot learning can be applied to many tasks. Here, we will do sentiment analysis, which was covered earlier. However, you will see how few-shot learning allows us to specify custom labels, whereas the previous model was tuned for a specific set of labels. We will also show other (toy) tasks at the end. In terms of the Hugging Face task specified in the pipeline constructor, few-shot learning is handled as a text-generation task.\n",
    "- Data: We use a few examples, including a tweet example from the blog post linked above.\n",
    "- Model: gpt-neo-1.3B, a version of the GPT-Neo model discussed in the blog linked above. It is a transformer model with 1.3 billion parameters developed by Eleuther AI. For more details, see the code on GitHub or the research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "644a356f-d0fc-4014-955a-c0959d700d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1f15f5ce524568acf13950dae761ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0d5aaa11f543ae8dfaff0f30e1bf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfda51a0f2e45f78d20d50b418a046f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ecfea224f3482491bb4b437874df4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920bafb37ddc4ba5b5457b0cb1c8b879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83a014ac69d42ea9664f706b083eac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will limit the response length for our few-shot learning tasks.\n",
    "few_shot_pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"EleutherAI/gpt-neo-1.3B\",\n",
    "    max_new_tokens=10,\n",
    "    # model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c3c2c61-538e-4a57-ae8d-50a9ea4c94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token ID for \"###\", which we will use as the EOS token below.\n",
    "eos_token_id = few_shot_pipeline.tokenizer.encode(\"###\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fd4cabc-7142-4fa2-8188-1e488f918ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "[Tweet]: \"This new music video was incredible\"\n",
      "[Sentiment]: \"Very positive\"\n",
      "\n",
      "And the sentiment:\n"
     ]
    }
   ],
   "source": [
    "# Without any examples, the model output is inconsistent and usually incorrect.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2921d329-99c8-40f2-ac18-1db254d6becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "[Tweet]: \"This is the link to the article\"\n",
      "[Sentiment]: Neutral\n",
      "###\n",
      "[Tweet]: \"This new music video was incredible\"\n",
      "[Sentiment]: Strong\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# With only 1 example, the model may or may not get the answer right.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af09b8a1-bc3e-4f77-939d-6546755ee0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "[Tweet]: \"I hate it when my phone battery dies.\"\n",
      "[Sentiment]: Negative\n",
      "###\n",
      "[Tweet]: \"My day has been 👍\"\n",
      "[Sentiment]: Positive\n",
      "###\n",
      "[Tweet]: \"This is the link to the article\"\n",
      "[Sentiment]: Neutral\n",
      "###\n",
      "[Tweet]: \"This new music video was incredible\"\n",
      "[Sentiment]: Positive\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# With 1 example for each sentiment, the model is more likely to understand!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"I hate it when my phone battery dies.\"\n",
    "[Sentiment]: Negative\n",
    "###\n",
    "[Tweet]: \"My day has been 👍\"\n",
    "[Sentiment]: Positive\n",
    "###\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a12ec15-961d-4c54-8909-ddc7f2649941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each food, suggest a good drink pairing:\n",
      "\n",
      "[food]: tapas\n",
      "[drink]: wine\n",
      "###\n",
      "[food]: pizza\n",
      "[drink]: soda\n",
      "###\n",
      "[food]: jalapenos poppers\n",
      "[drink]: beer\n",
      "###\n",
      "[food]: scone\n",
      "[drink]: soda\n",
      "[food]: poppers\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# The model isn't ready to serve drinks!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each food, suggest a good drink pairing:\n",
    "\n",
    "[food]: tapas\n",
    "[drink]: wine\n",
    "###\n",
    "[food]: pizza\n",
    "[drink]: soda\n",
    "###\n",
    "[food]: jalapenos poppers\n",
    "[drink]: beer\n",
    "###\n",
    "[food]: scone\n",
    "[drink]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "784ee2d8-26af-459e-ae24-6049edeaf95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\n",
      "\n",
      "[word]: happy\n",
      "[description]: smiling, laughing, clapping\n",
      "###\n",
      "[word]: nervous\n",
      "[description]: glancing around quickly, sweating, fidgeting\n",
      "###\n",
      "[word]: sleepy\n",
      "[description]: heavy-lidded, slumping, rubbing eyes\n",
      "###\n",
      "[word]: confused\n",
      "[description]: wandering around, turning in circles, confused\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\n",
    "\n",
    "[word]: happy\n",
    "[description]: smiling, laughing, clapping\n",
    "###\n",
    "[word]: nervous\n",
    "[description]: glancing around quickly, sweating, fidgeting\n",
    "###\n",
    "[word]: sleepy\n",
    "[description]: heavy-lidded, slumping, rubbing eyes\n",
    "###\n",
    "[word]: confused\n",
    "[description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efc88c98-dcbf-4148-a930-9be5d5c95571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a book summary from the title:\n",
      "\n",
      "[book title]: \"Stranger in a Strange Land\"\n",
      "[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\n",
      "###\n",
      "[book title]: \"The Adventures of Tom Sawyer\"\n",
      "[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\n",
      "###\n",
      "[book title]: \"Dune\"\n",
      "[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\n",
      "###\n",
      "[book title]: \"Blue Mars\"\n",
      "[book description]: \"This is the first of a series of science fiction novels.  It is set in the future, in a future where humans have become a minority.  They are forced to live in a constant state of tension and competition with Earth, a minority\n"
     ]
    }
   ],
   "source": [
    "# We override max_new_tokens to generate longer answers.\n",
    "# These book descriptions were taken from their corresponding Wikipedia pages.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"Generate a book summary from the title:\n",
    "\n",
    "[book title]: \"Stranger in a Strange Land\"\n",
    "[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\n",
    "###\n",
    "[book title]: \"The Adventures of Tom Sawyer\"\n",
    "[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\n",
    "###\n",
    "[book title]: \"Dune\"\n",
    "[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\n",
    "###\n",
    "[book title]: \"Blue Mars\"\n",
    "[book description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    "    max_new_tokens=50,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79bbe7d-9b67-4b50-a432-4797255c6ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the full cost of damage in Newton Stewart is still being assessed. many roads in peeblesshire remain badly affected\n",
       "by standing water. the water breached a retaining wall, flooding many commercial properties.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the full cost of damage in Newton Stewart is still being assessed. many roads in peeblesshire remain badly affected\n",
       "by standing water. the water breached a retaining wall, flooding many commercial properties.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "998bc503-ea99-4a7b-bd72-3c2482860d36",
   "metadata": {},
   "source": [
    "### Query for similar documents using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3693068b-e985-4c38-8c32-84161d4cf243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3e7724-4e53-4e3b-9bc3-be16e0c272ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>35232142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>40143035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>35951548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>36266422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>38826984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>34540833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>20836172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>35932467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>40758845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>30358490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "5  Simone Favaro got the crucial try with the las...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  Belgian cyclist Demoitie died after a collisio...   \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...   \n",
       "9  The crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary        id  \n",
       "0  Clean-up operations are continuing across the ...  35232142  \n",
       "1  Two tourist buses have been destroyed by fire ...  40143035  \n",
       "2  Lewis Hamilton stormed to pole position at the...  35951548  \n",
       "3  A former Lincolnshire Police officer carried o...  36266422  \n",
       "4  An armed man who locked himself into a room at...  38826984  \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...  34540833  \n",
       "6  A man with links to a car that was involved in...  20836172  \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...  35932467  \n",
       "8  Manchester City midfielder Ilkay Gundogan says...  40758845  \n",
       "9  A jogger has been hit by an unmarked police ca...  30358490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
