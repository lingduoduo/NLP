{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca0c2ec-cd58-415f-a71e-c024ac554306",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d20621-b3b9-438e-b31e-058c9cc7ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 19:42:36.319818: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-22 19:42:37.533906: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056255e-c817-47be-adaa-f2bc21daa282",
   "metadata": {},
   "source": [
    "### Load and test out mistral-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c3be99-c274-438a-8041-b1df8129c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3380ad2c-6910-4926-b528-3230ef4a3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b63e06c-8f91-4792-b953-a89d03fef375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fee206e-cc5a-4d8a-b1d6-27007e99425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27179789afcc4f5a9563ee71f36eb5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57c26ff-cbf1-4e91-a171-ffb7d14899bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d75a12-ccee-4eb9-afd9-fe856d7dc7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What can you tell me about the 2021 fantasy football season? [/INST]The 2021 fantasy football season began on August 17th, 2021, with the first games of the NFL Preseason. The regular season started on September 11th, 2021 and ended on January 9th, 2022. The Super Bowl LVI, which was the 56th Super Bowl, was held on February 6th, 2022, at SoFi Stadium in Los Angeles, California.\n",
      "\n",
      "    Due to the COVID-19 pandemic, the 2021 fantasy football season was played with some changes, including a reduced preseason schedule, the elimination of in-person attendance at games, and the use of virtual meetings for teams.\n",
      "\n",
      "    In terms of fantasy football leagues, many leagues opted to use a PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards. The use of PPR has become increasingly popular in recent years, as it provides more opportunities for players to score points.\n",
      "\n",
      "    As for notable players in the 2021 fantasy football season, some of the top performers included:\n",
      "\n",
      "    * Quarterbacks: Patrick Mahomes of the Kansas City Chiefs, Justin Herbert of the Los Angeles Chargers, and Tom Brady of the Tampa Bay Buccaneers.\n",
      "    * Running Backs: Christian McCaffery of the Carolina Panthers, Alvin Kamara of the New Orleans Saints, and Dalvin Cook of the Minnesota Vikings.\n",
      "    * Wide Receivers: Tyreek Hill of the Kansas City Chiefs, Stefon Diggs of the Buffalo Bills, and DeAndre Hopkins of the Arizona Cardinals.\n",
      "    * Tight Ends: Travis Kelce of the Kansas City Chiefs, George Kittle of the San Francisco 49ers, and Tyler Higbee of the Los Angeles Rams.\n",
      "\n",
      "    In terms of team performance, the Tampa Bay Buccaneers won the Super Bowl LVI, defeating the Kansas City Chiefs 31-9. The Green Bay Packers finished the regular season with the best record (13-3), but were eliminated in the divisional round of the playoffs by the Los Angeles Rams. The Oakland Raiders, who moved to Las Vegas in 2020, had a strong season, finishing with a record of 10-6 and making it to the playoffs for the first time since 2016.</s>  [INST] How many points did Maholmes score that season? [/INST]Patrick Mahomes, the quarterback for the Kansas City Chiefs, scored a total of 456 points in the regular season of the 2021 fantasy football season. This made him the top scoring quarterback in the PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards.</s>  [INST] Can you tell me how many points he scored in week 3 of that season? [/INST]Patrick Mahomes scored 35 points in week 3 of the 2021 fantasy football season. This was a strong performance, as Mahomes completed 18 of 29 passes for 283 yards and three touchdowns in a win over the Indianapolis Colts.</s>  [INST] Did anyone score more than him in that week? [/INST] No, Patrick Mahomes did not score more than any other player in week 3 of the 2021 fantasy football season. He was the top scoring quarterback in that week, and no other player had a higher point total.</s>\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What can you tell me about the 2021 fantasy football season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"The 2021 fantasy football season began on August 17th, 2021, with the first games of the NFL Preseason. The regular season started on September 11th, 2021 and ended on January 9th, 2022. The Super Bowl LVI, which was the 56th Super Bowl, was held on February 6th, 2022, at SoFi Stadium in Los Angeles, California.\n",
    "\n",
    "    Due to the COVID-19 pandemic, the 2021 fantasy football season was played with some changes, including a reduced preseason schedule, the elimination of in-person attendance at games, and the use of virtual meetings for teams.\n",
    "\n",
    "    In terms of fantasy football leagues, many leagues opted to use a PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards. The use of PPR has become increasingly popular in recent years, as it provides more opportunities for players to score points.\n",
    "\n",
    "    As for notable players in the 2021 fantasy football season, some of the top performers included:\n",
    "\n",
    "    * Quarterbacks: Patrick Mahomes of the Kansas City Chiefs, Justin Herbert of the Los Angeles Chargers, and Tom Brady of the Tampa Bay Buccaneers.\n",
    "    * Running Backs: Christian McCaffery of the Carolina Panthers, Alvin Kamara of the New Orleans Saints, and Dalvin Cook of the Minnesota Vikings.\n",
    "    * Wide Receivers: Tyreek Hill of the Kansas City Chiefs, Stefon Diggs of the Buffalo Bills, and DeAndre Hopkins of the Arizona Cardinals.\n",
    "    * Tight Ends: Travis Kelce of the Kansas City Chiefs, George Kittle of the San Francisco 49ers, and Tyler Higbee of the Los Angeles Rams.\n",
    "\n",
    "    In terms of team performance, the Tampa Bay Buccaneers won the Super Bowl LVI, defeating the Kansas City Chiefs 31-9. The Green Bay Packers finished the regular season with the best record (13-3), but were eliminated in the divisional round of the playoffs by the Los Angeles Rams. The Oakland Raiders, who moved to Las Vegas in 2020, had a strong season, finishing with a record of 10-6 and making it to the playoffs for the first time since 2016.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"How many points did Maholmes score that season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Patrick Mahomes, the quarterback for the Kansas City Chiefs, scored a total of 456 points in the regular season of the 2021 fantasy football season. This made him the top scoring quarterback in the PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me how many points he scored in week 3 of that season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Patrick Mahomes scored 35 points in week 3 of the 2021 fantasy football season. This was a strong performance, as Mahomes completed 18 of 29 passes for 283 yards and three touchdowns in a win over the Indianapolis Colts.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Did anyone score more than him in that week?\"}\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "model\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a01d3a-f434-44b9-a3b0-dc9ef03fac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   733, 16289, 28793,  1824,   541,   368,  1912,   528,   684,\n",
       "           272, 28705, 28750, 28734, 28750, 28740, 17393,  6569,  3302, 28804,\n",
       "           733, 28748, 16289, 28793,  1014, 28705, 28750, 28734, 28750, 28740,\n",
       "         17393,  6569,  3302,  3125,   356,  3628, 28705, 28740, 28787,   362,\n",
       "         28725, 28705, 28750, 28734, 28750, 28740, 28725,   395,   272,   907,\n",
       "          3897,   302,   272, 17868,  4258, 17956, 28723,   415,  4392,  3302,\n",
       "          2774,   356,  4074, 28705, 28740, 28740,   362, 28725, 28705, 28750,\n",
       "         28734, 28750, 28740,   304,  7054,   356,  4624, 28705, 28774,   362,\n",
       "         28725, 28705, 28750, 28734, 28750, 28750, 28723,   415,  6077, 21484,\n",
       "           393, 17102, 28725,   690,   403,   272, 28705, 28782, 28784,   362,\n",
       "          6077, 21484, 28725,   403,  3336,   356,  5353, 28705, 28784,   362,\n",
       "         28725, 28705, 28750, 28734, 28750, 28750, 28725,   438,  1537, 12705,\n",
       "          8993,   297,  5729,  9479, 28725,  6247, 28723,    13,    13,  2287,\n",
       "         16043,   298,   272, 11747, 28733, 28740, 28774, 15749, 28725,   272,\n",
       "         28705, 28750, 28734, 28750, 28740, 17393,  6569,  3302,   403,  4226,\n",
       "           395,   741,  4435, 28725,  2490,   264,  9397,   710, 17956,  9442,\n",
       "         28725,   272,  8663,  2235,   302,   297, 28733,  9701, 25269,   438,\n",
       "          3897, 28725,   304,   272,   938,   302,  8252, 13251,   354,  6941,\n",
       "         28723,    13,    13,  2287,   560,  3471,   302, 17393,  6569,   462,\n",
       "         11723, 28725,  1287,   462, 11723,  3158,   286,   298,   938,   264,\n",
       "           367,  4402,   325,  4164,   367,   930, 10742, 28731,  5032, 28725,\n",
       "           690, 22989,  5117,   354, 11864,  9720, 11107,   297,  4518,   298,\n",
       "         27441, 11107, 28723,   415,   938,   302,   367,  4402,   659,  2727,\n",
       "         13107,  4387,   297,  5391,  1267, 28725,   390,   378,  5312,   680,\n",
       "          8812,   354,  5117,   298,  7420,  3569, 28723,    13,    13,  2287,\n",
       "          1136,   354, 19225,  5117,   297,   272, 28705, 28750, 28734, 28750,\n",
       "         28740, 17393,  6569,  3302, 28725,   741,   302,   272,  1830,  2225,\n",
       "           404,  4658, 28747,    13,    13,  2287,   398, 24391, 19076, 28747,\n",
       "         13687, 10947, 28548,   302,   272, 17778,  3805,   689, 25495, 28725,\n",
       "         21252, 24112,   302,   272,  5729,  9479,   689,   926,   404, 28725,\n",
       "           304,  4660,  1896,  4425,   302,   272,   320, 20797,  6644, 10944,\n",
       "           588,  1564,   404, 28723,    13,  2287,   398, 28588,   365,  6507,\n",
       "         28747,  5899, 10040,  2146,  1193,   302,   272, 11434,  7687,  2199,\n",
       "         28725,   976,  8830, 15346,  2923,   302,   272,  1450, 21604,   318,\n",
       "          6520, 28725,   304, 12732,  8830, 13092,   302,   272, 17849, 20820,\n",
       "           742, 28723,    13,  2287,   398,   394,   547,  1298,   358,  1588,\n",
       "         28747, 10084,  6857,  7442,   302,   272, 17778,  3805,   689, 25495,\n",
       "         28725,  2349, 27544, 10104,  2626,   302,   272, 28100,   365,  2767,\n",
       "         28725,   304,  1343,  2467,   267, 15406,  8298,   302,   272, 17289,\n",
       "          8564, 15658, 28723,    13,  2287,   398,   320,   454,  5764, 28713,\n",
       "         28747,  1319, 19677, 21564,   358,   302,   272, 17778,  3805,   689,\n",
       "         25495, 28725,  5163,   524,  1490,   302,   272,  3652,  9686, 28705,\n",
       "         28781, 28774,   404, 28725,   304, 23307, 14327, 28255,   302,   272,\n",
       "          5729,  9479,   399,  5322, 28723,    13,    13,  2287,   560,  3471,\n",
       "           302,  1918,  4397, 28725,   272,   320, 20797,  6644, 10944,   588,\n",
       "          1564,   404,  1747,   272,  6077, 21484,   393, 17102, 28725,  8464,\n",
       "          1077,   272, 17778,  3805,   689, 25495, 28705, 28770, 28740, 28733,\n",
       "         28774, 28723,   415,  6248,  6644, 11676,   404,  5967,   272,  4392,\n",
       "          3302,   395,   272,  1489,  2395,   325, 28740, 28770, 28733, 28770,\n",
       "           557,   562,   654, 27546,   297,   272, 21707,  1479,  3713,   302,\n",
       "           272,  1156, 14567,   486,   272,  5729,  9479,   399,  5322, 28723,\n",
       "           415, 18005,  1207,   399,  3439,   404, 28725,   693,  4142,   298,\n",
       "          9134, 18233,   297, 28705, 28750, 28734, 28750, 28734, 28725,   553,\n",
       "           264,  2967,  3302, 28725, 19564,   395,   264,  2395,   302, 28705,\n",
       "         28740, 28734, 28733, 28784,   304,  2492,   378,   298,   272,  1156,\n",
       "         14567,   354,   272,   907,   727,  1854, 28705, 28750, 28734, 28740,\n",
       "         28784, 28723,     2, 28705,   733, 16289, 28793,  1602,  1287,  3569,\n",
       "           863, 10947,   328,  4137,  7420,   369,  3302, 28804,   733, 28748,\n",
       "         16289, 28793,  8243,  9450, 10947, 28548, 28725,   272,  8249,  1435,\n",
       "           354,   272, 17778,  3805,   689, 25495, 28725, 13969,   264,  3102,\n",
       "           302, 28705, 28781, 28782, 28784,  3569,   297,   272,  4392,  3302,\n",
       "           302,   272, 28705, 28750, 28734, 28750, 28740, 17393,  6569,  3302,\n",
       "         28723,   851,  1269,   713,   272,  1830, 20310,  8249,  1435,   297,\n",
       "           272,   367,  4402,   325,  4164,   367,   930, 10742, 28731,  5032,\n",
       "         28725,   690, 22989,  5117,   354, 11864,  9720, 11107,   297,  4518,\n",
       "           298, 27441, 11107, 28723,     2, 28705,   733, 16289, 28793,  2418,\n",
       "           368,  1912,   528,   910,  1287,  3569,   400, 13969,   297,  1819,\n",
       "         28705, 28770,   302,   369,  3302, 28804,   733, 28748, 16289, 28793,\n",
       "          8243,  9450, 10947, 28548, 13969, 28705, 28770, 28782,  3569,   297,\n",
       "          1819, 28705, 28770,   302,   272, 28705, 28750, 28734, 28750, 28740,\n",
       "         17393,  6569,  3302, 28723,   851,   403,   264,  2967,  4397, 28725,\n",
       "           390, 10947, 28548,  7368, 28705, 28740, 28783,   302, 28705, 28750,\n",
       "         28774, 15167,   354, 28705, 28750, 28783, 28770, 11107,   304,  1712,\n",
       "         27866, 28713,   297,   264,  3108,   754,   272,  6735, 20389,  1888,\n",
       "          1074, 28723,     2, 28705,   733, 16289, 28793,  7164,  3637,  7420,\n",
       "           680,   821,   713,   297,   369,  1819, 28804,   733, 28748, 16289,\n",
       "         28793]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b7c55d-26e2-43ed-982e-e10776b028b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] Tell me about fantasy football? [/INST] Fantasy football is a popular online game where participants create their own fictional teams by selecting players from real-life sports teams. The goal of the game is to score points based on the performance of the players on the field, such as touchdowns, interceptions, and fumbles. Fantasy football typically involves a draft where players are selected and then a season where they play games and score points. There are also various leagues and formats for fantasy football, including PPR (points per reception) and PTS (points per touchdown). Fantasy football is a fun way to combine sports and gaming and to test your knowledge of football and strategy.</s>\n"
     ]
    }
   ],
   "source": [
    "inputs_not_chat = tokenizer.encode_plus(\"[INST] Tell me about fantasy football? [/INST]\", return_tensors=\"pt\")['input_ids'].to(device)\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04528bc9-a21c-44e0-a89e-6adf7e27cfae",
   "metadata": {},
   "source": [
    "### RAG RAG RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc9b45f-91f0-4340-b411-61a2ba6fc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcc6409-d423-4699-804a-72341332efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4865d5fa-dae3-41fb-81d2-5659e631cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "mistral_llm_0_temp = HuggingFacePipeline(pipeline=text_generation_pipeline_0_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5654ae72-31a9-4c54-84cc-9cc3e5e4864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question based on your fantasy football knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c95f07-2802-4cda-ba5e-06b16a9592c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "995e4561-2139-4424-b959-635be93e1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader, UnstructuredURLLoader, PlaywrightURLLoader\n",
    "from langchain.document_loaders.blob_loaders.schema import Blob\n",
    "from langchain.document_loaders.parsers.txt import TextParser\n",
    "from langchain.document_loaders.url_selenium import SeleniumURLLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00665637-892a-4f91-ab45-302a119a07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document = \"\"\"\n",
    "ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\n",
    "\n",
    "Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\n",
    "\n",
    "Veteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\n",
    "\n",
    "Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\n",
    "\n",
    "\"He's right where I thought he would be, he's right where he should be coming along at at this time,\" Scottie Montgomery said.\n",
    "\n",
    "\"We don't judge players based off of anything else besides achievement. Like there is success and there is expectations and I want people outside the building to put those expectations on him because, guess what, whether we believe it or not it motivates him. It does and that's a really, really good tool.\"\n",
    "\n",
    "Meanwhile, rookie safety Brian Branch, who has an ankle injury, is also set to miss his second consecutive game. The second-round pick out of Alabama was held out of practice for the entire week. With 25 tackles, a pick-six and 4 passes defended, he is Detroit's fourth-leading tackler.\n",
    "\n",
    "Rookie tight end Sam LaPorta is questionable with a calf strain that flared up Wednesday, forcing him to miss Thursday's practice. He said it likely stemmed from Sunday's win over Carolina, and he intends to play Sunday.\n",
    "\n",
    "\"It's football, things happen, we certainly work our bodies pretty hard so I'm feeling a lot better today,\" LaPorta said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81769cb4-2ba8-44ea-9fd3-ce6d24be6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextParser().parse(Blob(data=test_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a859fbf6-9c34-46e0-8dcc-8b1099771752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 258, which is longer than the specified 100\n",
      "Created a chunk of size 233, which is longer than the specified 100\n",
      "Created a chunk of size 158, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 307, which is longer than the specified 100\n",
      "Created a chunk of size 286, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49383a-4cd9-41cd-b5e2-f5053ed15eb8",
   "metadata": {},
   "source": [
    "```python\n",
    "HuggingFaceEmbeddings(\n",
    "    *,\n",
    "    client: Any = None,\n",
    "    model_name: str = 'sentence-transformers/all-mpnet-base-v2',\n",
    "    cache_folder: Optional[str] = None,\n",
    "    model_kwargs: Dict[str, Any] = None,\n",
    "    encode_kwargs: Dict[str, Any] = None,\n",
    "    multi_process: bool = False,\n",
    ") -> None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50e90fe7-589a-410e-90be-4e2ccf5003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72927abd-3a71-4f3b-8eed-89bb8719ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\", metadata={'source': None}),\n",
       " Document(page_content=\"Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\", metadata={'source': None}),\n",
       " Document(page_content=\"Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\", metadata={'source': None}),\n",
       " Document(page_content='\"He\\'s right where I thought he would be, he\\'s right where he should be coming along at at this time,\" Scottie Montgomery said.', metadata={'source': None})]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"who is gibbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d7e5e98-0ef3-4818-b9bb-3cfdedba351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d468cb09-607d-4d1e-b600-79bebbfad736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"It's football, things happen, we certainly work our bodies pretty hard so I'm feeling a lot better today,\" LaPorta said.\n"
     ]
    }
   ],
   "source": [
    "query = \"What did Laporta say?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56639e02-77e0-4272-9143-d9ee70adcc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': '',\n",
       " 'question': 'Did Gibbs start this week?',\n",
       " 'text': \" I'm sorry, but I don't have access to real-time information about specific players in fantasy football. Can you please provide me with more context or a specific date and time frame so that I can give you an accurate answer?\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"context\":\"\", \"question\": \"Did Gibbs start this week?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ffb904c2-ffde-4652-9dfc-c8039af0eec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='\"It\\'s football, things happen, we certainly work our bodies pretty hard so I\\'m feeling a lot better today,\" LaPorta said.', metadata={'source': None}),\n",
       "  Document(page_content=\"Rookie tight end Sam LaPorta is questionable with a calf strain that flared up Wednesday, forcing him to miss Thursday's practice. He said it likely stemmed from Sunday's win over Carolina, and he intends to play Sunday.\", metadata={'source': None}),\n",
       "  Document(page_content='\"We don\\'t judge players based off of anything else besides achievement. Like there is success and there is expectations and I want people outside the building to put those expectations on him because, guess what, whether we believe it or not it motivates him. It does and that\\'s a really, really good tool.\"', metadata={'source': None}),\n",
       "  Document(page_content='\"He\\'s right where I thought he would be, he\\'s right where he should be coming along at at this time,\" Scottie Montgomery said.', metadata={'source': None})],\n",
       " 'question': 'What did Laporta say?',\n",
       " 'text': \"\\nSam LaPorta said that he is questionable for Sunday's game due to a calf strain that flared up on Wednesday, causing him to miss Thursday's practice. He stated that it likely occurred during Sunday's win over Carolina and he plans to play on Sunday.\"}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What did Laporta say?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1744a11-d48d-4b77-91b6-c5962402be52",
   "metadata": {},
   "source": [
    "#### Let's try to load the same article with LangChains web crawler loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acbfe18a-6add-489f-8b89-c75957a4b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15bbffac-c547-4507-b066-e918e6553e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = AsyncChromiumLoader([\"https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs\"])\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31966ec9-96cb-4dda-8ff2-0c671aa785fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "575756a1-52d2-4716-9a59-96b4ab27b397",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 191, which is longer than the specified 100\n",
      "Created a chunk of size 274, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 161, which is longer than the specified 100\n",
      "Created a chunk of size 1775, which is longer than the specified 100\n",
      "Created a chunk of size 1985, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 195, which is longer than the specified 100\n",
      "Created a chunk of size 343, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 1685, which is longer than the specified 100\n",
      "Created a chunk of size 1649, which is longer than the specified 100\n",
      "Created a chunk of size 117, which is longer than the specified 100\n",
      "Created a chunk of size 421, which is longer than the specified 100\n",
      "Created a chunk of size 410, which is longer than the specified 100\n",
      "Created a chunk of size 270, which is longer than the specified 100\n",
      "Created a chunk of size 961, which is longer than the specified 100\n",
      "Created a chunk of size 536, which is longer than the specified 100\n",
      "Created a chunk of size 299, which is longer than the specified 100\n",
      "Created a chunk of size 107, which is longer than the specified 100\n",
      "Created a chunk of size 589, which is longer than the specified 100\n",
      "Created a chunk of size 109, which is longer than the specified 100\n",
      "Created a chunk of size 197, which is longer than the specified 100\n",
      "Created a chunk of size 209, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 113, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 151, which is longer than the specified 100\n",
      "Created a chunk of size 1288, which is longer than the specified 100\n",
      "Created a chunk of size 138, which is longer than the specified 100\n",
      "Created a chunk of size 330, which is longer than the specified 100\n",
      "Created a chunk of size 455, which is longer than the specified 100\n",
      "Created a chunk of size 233, which is longer than the specified 100\n",
      "Created a chunk of size 258, which is longer than the specified 100\n",
      "Created a chunk of size 233, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 158, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 307, which is longer than the specified 100\n",
      "Created a chunk of size 286, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 265, which is longer than the specified 100\n",
      "Created a chunk of size 337, which is longer than the specified 100\n",
      "Created a chunk of size 438, which is longer than the specified 100\n",
      "Created a chunk of size 1819, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(docs_transformed)\n",
    "db = FAISS.from_documents(documents, HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44431600-fdd2-4a53-a85c-78603d454efc",
   "metadata": {},
   "source": [
    "What do these documents look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c2b2675-3704-440b-b0eb-fb3c6c2cfcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Skip to main content  Skip to navigation', metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content=\"Top Events  NCAAF  MLB  NFL  WNBA  F1  NHL  NBA  PGA Tour  NASCAR  Tennis (W)\\nLPGA Tour  NCAAM  Tennis (M)  UFC  NCAAW  Top Soccer  PLL (Lacrosse)  ICC\\nCricket World Cup  Men's NCAA Ice Hockey\", metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content='NFL', metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content=\"* Top Events \\n  * NCAAF \\n  * MLB \\n  * NFL \\n  * WNBA \\n  * F1 \\n  * NHL \\n  * NBA \\n  * PGA Tour \\n  * NASCAR \\n  * Tennis (W) \\n  * LPGA Tour \\n  * NCAAM \\n  * Tennis (M) \\n  * UFC \\n  * NCAAW \\n  * Top Soccer \\n  * PLL (Lacrosse) \\n  * ICC Cricket World Cup \\n  * Men's NCAA Ice Hockey\", metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content='Week 6\\n\\n  * Week 5 \\n  * Week 6 \\n  * Week 7 \\n\\n<\\n\\nFull Scoreboard »\\n\\n>\\n\\n  * Gamecast  Box Score', metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c05f00-a339-44ce-b985-cff6df8930ea",
   "metadata": {},
   "source": [
    "Super noisy but let's still see how it performs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19dbb99e-71b0-4cf7-b59c-f4112898dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': '',\n",
       " 'question': 'What number was Gibbs selected for the Lions?',\n",
       " 'text': '\\nGibbs was not selected by the Detroit Lions in the 2021 NFL Draft.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"context\":\"\", \"question\": \"What number was Gibbs selected for the Lions?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c6174df-7599-4d01-bd02-7f4b451da1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content=\"Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\", metadata={'source': None}),\n",
       "  Document(page_content=\"ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\", metadata={'source': None}),\n",
       "  Document(page_content=\"Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\", metadata={'source': None}),\n",
       "  Document(page_content='Veteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.', metadata={'source': None})],\n",
       " 'question': 'Should I start Gibbs next week for fantasy?',\n",
       " 'text': ' Based on the information provided, it seems that Gibbs may be out for another game due to his hamstring injury. While he has shown promise in his four appearances so far, it may be best to wait until he is fully healthy before starting him in your fantasy lineup. In the meantime, you could consider starting David Montgomery or another running back who has been performing well for the Lions.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Should I start Gibbs next week for fantasy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d24ce6-ed21-4a50-bd63-68bea318940d",
   "metadata": {},
   "source": [
    "Sweet, still gives the right answer! This may cause issues as we add more docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f976ad-7b7e-420a-871e-c70d78fd65de",
   "metadata": {},
   "source": [
    "### Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0156d5c-091f-46c8-b08e-9be394ca62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.schema import format_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f597679-51a8-48ed-a5bb-36fa7a985fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"[INST] Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\n",
    "[/INST]\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ff5d234-27ff-4bf1-b1d1-8f6710b7e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"[INST]Answer the question based only on the following context and chat history:\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question: {question}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35b8f9af-b67d-4a7e-9f0a-e10c3417fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create llm chain \n",
    "llm_chain_cq = LLMChain(llm=mistral_llm_0_temp, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain_a = LLMChain(llm=mistral_llm, prompt=ANSWER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d7e1676-88a6-497c-a614-24475050d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "def _combine_documents(docs, document_prompt = DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dc451df-c7bd-4a21-8297-bf85bbc05c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"Me: \" + dialogue_turn[0]\n",
    "        ai = \"Assistant: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b06ac007-0d4a-47c4-b146-5144274c8571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  standalone_question: RunnableAssign(mapper={\n",
       "                         chat_history: RunnableLambda(...)\n",
       "                       })\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnableMap(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x['chat_history']))\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72c5ad79-13e6-42e5-8491-63fc86fbc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_standalone_question(data):\n",
    "    return data['standalone_question']['text']\n",
    "\n",
    "def get_chathistory_from_standalone_question(data):\n",
    "    return data['standalone_question']['chat_history']\n",
    "\n",
    "_inputs = RunnableMap(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x['chat_history'])\n",
    "    ) | llm_chain_cq ,\n",
    ")\n",
    "_context = {\n",
    "    \"chat_history\": get_chathistory_from_standalone_question,\n",
    "    \"context\": get_text_from_standalone_question  | retriever | _combine_documents,\n",
    "    \"question\": get_text_from_standalone_question\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | llm_chain_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f64a3186-2f1b-4782-ba0c-34f5d3b72d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'standalone_question': {'question': 'What was Gibbs injury?',\n",
       "  'chat_history': '',\n",
       "  'text': \" What was Gibbs' injury?\"}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs.invoke({\n",
    "    \"question\": \"What was Gibbs injury?\",\n",
    "    \"chat_history\": [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0da6e8b-9c1a-4209-8293-ec9bdbb815dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': '',\n",
       " 'context': \"Meanwhile, rookie safety Brian Branch, who has an ankle injury, is also set to miss his second consecutive game. The second-round pick out of Alabama was held out of practice for the entire week. With 25 tackles, a pick-six and 4 passes defended, he is Detroit's fourth-leading tackler.\\n\\nVeteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\\n\\nGibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\\n\\nALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\",\n",
       " 'question': ' What is the definition of an active roster in the NFL?',\n",
       " 'text': '\\nThe definition of an active roster in the NFL refers to the group of players that are currently available to participate in games for a particular team. Each NFL team is allowed to have a maximum of 53 players on its active roster at any given time during the regular season. These players are typically the ones who will be suiting up for games and playing on the field. However, teams can also have a smaller number of players on their active roster if they choose to use roster spots for other purposes, such as practice squad players or injured reserve designations.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke({\n",
    "    \"question\": \"What does active roster mean in NFL?\",\n",
    "    \"chat_history\": [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5350d7dc-b5b0-4eda-b16a-98a263cc5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': '\\nMe: What was Gibbs injury?\\nAssistant: Gibbs suffered a hamstring injury.\\nMe: W\\nAssistant: h\\nMe: G\\nAssistant: i',\n",
       " 'context': \"Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\\n\\nGibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\\n\\nALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\\n\\nVeteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\",\n",
       " 'question': \" Who is Gibbs' running back coach?\",\n",
       " 'text': \"Gibbs' running back coach is Scottie Montgomery.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke({\n",
    "    \"question\": \"Who is his running back coach?\",\n",
    "    \"chat_history\": [(\"What was Gibbs injury?\", \"Gibbs suffered a hamstring injury.\"),\n",
    "                     (\"Who are we talking about?\"),(\"Gibbs is a running back for the Detroit Lions. He was their No. 12 overall selection in the 2021 NFL Draft and has been ruled out of their upcoming game against the Tampa Bay Buccaneers due to a hamstring injury. Despite high expectations, running back coach Scottie Montgomery is helping him develop at his own pace.\")],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc391b-9616-4a18-b51f-c7c9d556ca2c",
   "metadata": {},
   "source": [
    "### Add Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec9b30-af90-42ae-9868-6734810ae891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
