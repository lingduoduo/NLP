{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "750bb189-2cdf-43be-973e-74e4c56250b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75310d90-7477-435f-858c-c48c211ff3cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Embeddings, Vector Databases, and Search\n",
    "\n",
    "Converting text into embedding vectors is the first step to any text processing pipeline. As the amount of text gets larger, there is often a need to save these embedding vectors into a dedicated vector index or library, so that developers won't have to recompute the embeddings and the retrieval process is faster. We can then search for documents based on our intended query and pass these relevant documents into a language model (LM) as additional context. We also refer to this context as supplying the LM with \"state\" or \"memory\". The LM then generates a response based on the additional context it receives! \n",
    "\n",
    "In this notebook, we will implement the full workflow of text vectorization, vector search, and question answering workflow. While we use [FAISS](https://faiss.ai/) (vector library) and [ChromaDB](https://docs.trychroma.com/) (vector database), and a Hugging Face model, know that you can easily swap these tools out for your preferred tools or models!\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/llm/updated_vector_search.png\" width=1000 target=\"_blank\" > \n",
    "\n",
    "### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n",
    "1. Implement the workflow of reading text, converting text to embeddings, saving them to FAISS and ChromaDB \n",
    "2. Query for similar documents using FAISS and ChromaDB \n",
    "3. Apply a Hugging Face language model for question answering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e5d057-865a-453e-af48-bca63383d538",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting faiss-cpu==1.7.4\n  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.6/17.6 MB 57.8 MB/s eta 0:00:00\nCollecting chromadb==0.3.21\n  Downloading chromadb-0.3.21-py3-none-any.whl (46 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.4/46.4 kB 7.7 MB/s eta 0:00:00\nCollecting duckdb>=0.7.1\n  Downloading duckdb-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 64.2 MB/s eta 0:00:00\nRequirement already satisfied: sentence-transformers>=2.2.2 in /databricks/python3/lib/python3.10/site-packages (from chromadb==0.3.21) (2.2.2)\nRequirement already satisfied: pandas>=1.3 in /databricks/python3/lib/python3.10/site-packages (from chromadb==0.3.21) (1.4.4)\nCollecting numpy>=1.21.6\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 72.3 MB/s eta 0:00:00\nCollecting hnswlib>=0.7\n  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: requests>=2.28 in /databricks/python3/lib/python3.10/site-packages (from chromadb==0.3.21) (2.28.1)\nCollecting clickhouse-connect>=0.5.7\n  Downloading clickhouse_connect-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (964 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 964.5/964.5 kB 80.7 MB/s eta 0:00:00\nCollecting posthog>=2.4.0\n  Downloading posthog-3.4.0-py2.py3-none-any.whl (41 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.1/41.1 kB 7.4 MB/s eta 0:00:00\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /databricks/python3/lib/python3.10/site-packages (from chromadb==0.3.21) (0.23.2)\nRequirement already satisfied: pydantic>=1.9 in /databricks/python3/lib/python3.10/site-packages (from chromadb==0.3.21) (1.10.6)\nRequirement already satisfied: fastapi>=0.85.1 in /databricks/python3/lib/python3.10/site-packages (from chromadb==0.3.21) (0.98.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2022.9.14)\nCollecting zstandard\n  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 91.8 MB/s eta 0:00:00\nRequirement already satisfied: urllib3>=1.26 in /databricks/python3/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (1.26.11)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2022.1)\nCollecting lz4\n  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 83.8 MB/s eta 0:00:00\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /databricks/python3/lib/python3.10/site-packages (from fastapi>=0.85.1->chromadb==0.3.21) (0.27.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.3->chromadb==0.3.21) (2.8.2)\nCollecting backoff>=1.10.0\n  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from posthog>=2.4.0->chromadb==0.3.21) (1.16.0)\nCollecting monotonic>=1.5\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb==0.3.21) (4.3.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.3.21) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.3.21) (3.3)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (4.30.2)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.1.1)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (0.14.1+cu117)\nRequirement already satisfied: torch>=1.6.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.13.1+cu117)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (4.64.1)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.9.1)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (0.16.4)\nRequirement already satisfied: sentencepiece in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (0.1.99)\nRequirement already satisfied: nltk in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (3.7)\nRequirement already satisfied: click>=7.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (8.0.4)\nRequirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.14.0)\nRequirement already satisfied: watchfiles>=0.13 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.19.0)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (6.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.17.0)\nRequirement already satisfied: python-dotenv>=0.13 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (1.0.0)\nRequirement already satisfied: websockets>=10.4 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (11.0.3)\nRequirement already satisfied: httptools>=0.5.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.6.0)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (21.3)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.6.0)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (2022.7.1)\nRequirement already satisfied: anyio<5,>=3.4.0 in /databricks/python3/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.21) (3.5.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (0.13.3)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (2022.7.9)\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (0.3.2)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb==0.3.21) (2.2.0)\nCollecting numpy>=1.21.6\n  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 81.4 MB/s eta 0:00:00\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb==0.3.21) (9.2.0)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.21) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.0.9)\nBuilding wheels for collected packages: hnswlib\n  Building wheel for hnswlib (pyproject.toml): started\n  Building wheel for hnswlib (pyproject.toml): finished with status 'done'\n  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2287918 sha256=ee0434b047b3aa565ceeb421b64b4dbc94e70afeb4f52948c1fde91c4749e485\n  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\nSuccessfully built hnswlib\nInstalling collected packages: monotonic, faiss-cpu, zstandard, numpy, lz4, duckdb, backoff, posthog, hnswlib, clickhouse-connect, chromadb\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1ddad8bf-cd9a-47bc-b456-fb05e4eebc4f\n    Can't uninstall 'numpy'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-store 0.14.3 requires pyspark<4,>=3.1.2, which is not installed.\nydata-profiling 4.2.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.4 which is incompatible.\nnumba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.4 which is incompatible.\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 1.1.1 which is incompatible.\nSuccessfully installed backoff-2.2.1 chromadb-0.3.21 clickhouse-connect-0.7.0 duckdb-0.9.2 faiss-cpu-1.7.4 hnswlib-0.8.0 lz4-4.3.3 monotonic-1.6 numpy-1.24.4 posthog-3.4.0 zstandard-0.22.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu==1.7.4 chromadb==0.3.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f398bac1-46bd-4106-9df0-0af155fc3084",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Search Semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1fe8992-2b24-4887-8278-99017807307b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2d4b35c-3ebe-4334-9c58-a8fc848a82a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:27: UserWarning: This dataset can not be stored in DBFS because either `cache_dir` or the environment variable `HF_DATASETS_CACHE` is set to a non-DBFS path. If this cluster restarts, all saved dataset information will be lost.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc614f15db547e89ccde0f266bd10dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572e1e6124d8487a8cee82af3ee5fa5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xsum/default to /root/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcb6f221914462b9cf24e061ddd3ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a48203b9b8429a8bfa250fdf9a1c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb88adbd63254d229678054659e22b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a097acd45941a18f23a3c74b6027ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0f6a81c9454dc9ae5af73242fd7dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a2a69d764649caaedc946dd9eb657b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xsum downloaded and prepared to /root/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5203e109327a439987bf77fe1d493471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_dataset = load_dataset(\n",
    "    \"xsum\", version=\"1.2.0\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86a05a9-357a-4a99-a261-11e3f47e272b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Taking a sample of 100 rows\n",
    "xsum_sample = xsum_dataset[\"train\"].select(range(1000)).to_pandas()\n",
    "\n",
    "# Combining 'document' and 'summary' columns\n",
    "xsum_sample[\"combined\"] = (\n",
    "    \"Document: \" + xsum_sample.document.str.strip() + \"; Summary: \" + xsum_sample.summary.str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "737b6169-b102-482e-bf53-56a477111e26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1c547e150a4ade87adccbd226b1096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bf357b7ad7461488229abe96c7ca2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4821d3f95804460090d70f1aaf0b8e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/3.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ba3457f976469dbdbf223479a12190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf290c69e6942f8a768991c352eb1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2295d9094fb494db1663d9f0e281ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f9a850fdff450186e0192d75090437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b4168063064c4a8584ff8a7db2acb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b21903f6ca9469abe158aef20c830b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7818f30e57814f0cba58e7ed9f6ef0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672eb0a7ae30496bb6c798e599fbc09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d195710fc4ecda8e55532eef126fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#encoding the data\n",
    "encoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n",
    "encoded_data = encoder.encode(xsum_sample[\"combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7316af40-909c-4409-9ff7-885adf42de58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe9e819-19d6-4dcc-8360-1632ae5b1182",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d509ad44-cd6f-45f0-99ac-691d5e1f37f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "faiss.normalize_L2(encoded_data)\n",
    "index.add_with_ids(encoded_data, np.arange(len(encoded_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb83221-2800-4a8b-94da-af20853c8983",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_text = \"harry potter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f16c7d96-1227-4379-931e-f3e1c4ccf9c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_vector = encoder.encode(search_text)\n",
    "_vector = np.array([search_vector])\n",
    "faiss.normalize_L2(_vector)\n",
    "\n",
    "k = 2\n",
    "distances, ann = index.search(_vector, k=k)\n",
    "results = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3119850-b102-4a1d-a701-7f53a5d78687",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distances  ann\n0   0.598044  269\n1   0.379589  514\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f65983f1-5dd6-4617-99a5-e6aaf8d00003",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Harry Potter and the Cursed Child has won five-star reviews from critics, with one describing it as \"a game-changing production\".'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c8ff1d-0a0d-46aa-93ef-7d13743d1a4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'The play, written by Jack Thorne, is set 19 years after the seventh and final book in the series by JK Rowling.\\nIt opens officially at the Palace Theatre, in London\\'s West End, on Saturday.\\nAudiences have been urged to \"keep the secrets\" since the play began previews in early June.\\nPresented in two parts, the play - showing the stars of the wizarding saga as adults in their mid-30s as their own children head off to school - stretches over five hours.\\nDaily Telegraph critic Dominic Cavendish awarded the play five stars, writing: \"British theatre hasn\\'t known anything like it for decades and I haven\\'t seen anything directly comparable in all my reviewing days.\"\\nHe said \"those involved can give themselves a pat on the back\", adding: \"It\\'s a triumph. Not an unqualified one - there are some quibbles - but in all key respects, it grips, it stirs, it delights.\"\\nCavendish praises the \"thrill-a-minute\" stage craft which sees pupils heading to Hogwarts, at the start of the play, change into school uniforms \"in the blink of an eye\" as they head to the infamous Platform 9Â¾ to make their way to school.\\nThe Stage also gives a five-star review, with Mark Shenton describing Harry Potter and the Cursed Child - co-devised by Rowling, with director John Tiffany and playwright Jack Thorne - as a \"truly game-changing production and a thrilling theatrical endeavour\".\\nIt is an \"entirely original\" piece of work, with \"Dickensian sweep and momentum to the storytelling\", writes Shenton, adding: \"It earns its place on the stage, feeling distinct from both the books and the screen adaptations.\\n\"By turns playful and gripping, disturbing and detailed, poignant and powerful, it is superb family entertainment.\"\\nShenton also praises \"the theatrical wizards who\\'ve created this stunningly-realised alternative universe deliver one coup de theatre after another\".\\nIn a nod to the Kings Cross platform number, Ann Treneman gives the play four and three-quarters stars in The Times, saying the \"wizardry on display\" is \"out of this world\".\\nShe says the plot is complex (\"there are mazes that are more straightforward\") but adds: \"It\\'s a raunchless Game of Thrones with heart. Crucially, it\\'s authentic Potter but, most importantly, it\\'s new.\\n\"It\\'s not the movie of the book. It\\'s the real deal, live in front of you, so much better than any film could be.\"\\nIn The Guardian, Michael Billington noted the Cursed Child will make more sense to \"hardened Potterheads\", but applauded Tiffany for directing a \"thrilling theatrical spectacle\", giving it four stars.\\nHe praised the strong performances that meant acting was central to the story, despite the dazzling special effects, singling out Sam Clemmett as Harry\\'s son Albus, \"wonderfully quirky\" Anthony Boyle as his friend Scorpius Malfoy, and the adult Harry (Jamie Parker), \"authoritative\" Hermione (Noma Dumezweni) and \"bluntly commonsensical\" Ron (Paul Thornley).\\nIt\\'s another five stars from The Independent, with Jack Shepherd describing it as \"magical\". He argues Part One should be billed as a magic show, due to the effects used, also praising its moments of comedy.\\nShepherd adds: \"It\\'s quite apparent this isn\\'t written to be either a book or a tie-in film; it\\'s a spectacle for the theatre, one that is filled to the brim with fan service and magical imagery that will amaze.\"\\nQuentin Letts grumbles about the length of the play in the Daily Mail, noting: \"There were moments I could have done with a glug of gurdyroot infusion to keep me alert.\"\\nBut he admits: \"Potter addicts will love it. JK Rowling is going to make (another) fortune. The West End\\'s ornate Palace Theatre, itself a little like Hogwarts, has a hit probably for years.\"\\nVariety describes it as \"spellbinding\", Matt Trueman writing that it is: \"The Show That Lived Up to Expectations â€” and Then Some.\"\\nHe says the relationship between Albus and Scorpius is \"the friendship of two bullied boys bound together, and it\\'s a beautiful, tender thing\", adding: \"The script by Jack Thorne recognizes that rejection breeds resentment, and outsiders stew into outcasts.\\n\"No one\\'s born a villain, nor sees themselves as such, and where the books gave us stock baddies, Cursed Child fleshes them out.\"\\nChris Jones, in the Chicago Tribune, says that \"heretical as this may sound\", the play left him \"quietly lamenting that the movies were ever made\".\\nBen Brantley in the New York Times writes: \"Like the novels that preceded it, The Cursed Child is stuffed with arcana-filled plots that defy diagrams and baldly wrought sentimental life lessons, along with anguished dives into the earnest, tortured solipsism of adolescence.\\n\"By rights, such a combination should try the patience of any grown-up. But like Ms Rowling\\'s books, the play vanquishes resistance.\"\\nThe Harry Potter books have sold more than 450 million copies since 1997 and been adapted into eight films.\\nThe script of Harry Potter and the Cursed Child is published this weekend.\\nFollow us on Twitter @BBCNewsEnts, on Instagram at bbcnewsents, or email entertainment.news@bbc.co.uk.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"document\"][results['ann'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3786b682-3db2-4402-98cd-c5aea5c75619",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Author Patrick Ness is in the running to become the first author to win the Carnegie Medal three times.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cf0480-357a-4e92-aaef-2c1548a6d191",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'He has been shortlisted for the children\\'s book award for The Rest of Us Just Live Here, which follows the lives of a group of teenagers.\\nFrancis Hardinge, who won the Costa Book of the Year award for The Lie Tree, is also shortlisted.\\nThree illustrators are also in with a chance of winning the Kate Greenaway Medal for a record third time.\\nChildren\\'s Laureate Chris Riddell, former Children\\'s Laureate Anthony Browne and Helen Oxenbury - who first won the award for outstanding illustration in a book for children in 1969 - have all made the shortlist, which is dominated by traditional picture books this year.\\nBrowne first won the medal in 1983, while Riddell won for the first time in 2001.\\nHardinge\\'s Victorian murder mystery joins Lies We Tell Ourselves, author Robin Talley\\'s first book which tells of two teenage girls falling in love across the race divide in 1950s America.\\nSarah Crossan\\'s One, about conjoined twins; Marcus Sedgwick\\'s The Ghosts of Heaven, which looks at the search for the true meaning of life; Jenny Valentine\\'s Fire Colour One, which looks at issues of authenticity and honesty; Kate Saunders\\'s Five Children on the Western Front, about the impact of war on a family; and Nick Lake\\'s There Will Be Lies, which sees a young girl reassessing her identity, make up the shortlist.\\nSioned Jacques, chair of the judging panel for both awards, said: \"These exceptionally strong shortlists reflect the huge range of writing and illustrating talent in children\\'s publishing at the moment.\\n\"The lists are a true celebration of the longevity of these wonderful talents, with Helen Oxenbury and Anthony Browne showing that they are still delivering incredible work decades after first winning a medal.\"\\n• One by Sarah Crossan\\n• The Lie Tree by Frances Hardinge\\n• There Will Be Lies by Nick Lake\\n• The Rest of Us Just Live Here by Patrick Ness\\n• Five Children on the Western Front by Kate Saunders\\n• The Ghosts of Heaven by Marcus Sedgwick\\n• Lies We Tell Ourselves by Robin Talley\\n• Fire Colour One by Jenny Valentine\\n• Willy\\'s Stories illustrated and written by Anthony Browne\\n• There\\'s a Bear on My Chair illustrated and written by Ross Collins\\n• Once Upon an Alphabet illustrated and written by Oliver Jeffers\\n• Sam & Dave Dig a Hole illustrated by Jon Klassen, written by Mac Barnett\\n• Something About a Bear illustrated and written by Jackie Morris\\n• Captain Jack and the Pirates illustrated by Helen Oxenbury, written by Peter Bently\\n• The Sleeper and the Spindle illustrated by Chris Riddell, written by Neil Gaiman\\n• Footpath Flowers illustrated by Sydney Smith, written by JonArno Lawson\\nCILIP president Dawn Finch said: \"We are without doubt in a golden age of children\\'s books. From stories set in Victorian times and World War One to a modern day library, from fantasy worlds to the future, these shortlists showcase the enormous talent and unlimited imagination currently to be found in children\\'s storytelling.\"\\nThe winners for the two medals will be announced on 20 June at the British Library.\\nThe Kate Greenaway Medal winner has been awarded the £5,000 Colin Mears Award cash prize since 2000 - this year, the Carnegie Medal winner will also be awarded the same amount, from the same fund.\\nOne title from each shortlist will also win the Amnesty CILIP honour, which is a new commendation for a book which celebrates freedom.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"document\"][results['ann'][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd4b52f2-661e-4bce-86ca-7938046c2709",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d04e3ef2-2b2b-48e8-9f20-b7576154905e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=60,\n",
    "    truncation=True,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5e51ed-627c-424e-8220-e4752b83dda3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Harry Potter and the Cursed Child has won five-star reviews from critics, with one describing it as \"a game-changing production\".'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_sample[\"summary\"][results['ann'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5786919-c686-476a-b90f-e7508544a990",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'summary_text': 'the play, written by Jack Thorne, is set 19 years after the seventh and final book in the series by JK Rowling . it opens officially at the palace theatre, in London\\'s west end, on Saturday . critics have been urged to \"keep the'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(xsum_sample[\"document\"][results['ann'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b96b9fb-059e-4f05-a0ab-4ffb1e20e9c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'summary_text': 'the play, written by Jack Thorne, is set 19 years after the seventh book in the series by JK Rowling . it opens officially at the palace theatre, in London\\'s west end, on sunday . critics have been urged to \"keep the secrets'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can instead do a beam search by specifying num_beams.\n",
    "summarizer(xsum_sample[\"document\"][results['ann'][0]], num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "218a9729-743f-488a-9850-d17c711e4a04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'summary_text': 'the play, written by Jack Thorne, is set 19 years after the seventh and final book in the series by JK Rowling . it opens officially at the palace theatre, in London\\'s west end, on Saturday . critics have been urged to \"keep the'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we could use sampling.\n",
    "summarizer(xsum_sample[\"document\"][results['ann'][0]], do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6d8d37d-c43a-4969-9421-6a53f54da00e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'summary_text': 'the play, written by Jack Thorne, opens at the palace theatre on saturday . it shows the stars of the wizarding saga as adults in their mid-30s as their own children head off to school . critics have been urged to \"keep'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\n",
    "summarizer(xsum_sample[\"document\"][results['ann'][0]], do_sample=True, top_k=10, top_p=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d637e5e-ed35-4963-876c-c53130149eff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e93b9fe-910c-4b2a-a678-ba716f2302be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "615e428f-f6b0-4f35-9699-27c7416326cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 1: Reading data\n",
    "\n",
    "In this section, we are going to use the data on <a href=\"https://newscatcherapi.com/\" target=\"_blank\">news topics collected by the NewsCatcher team</a>, who collect and index news articles and release them to the open-source community. The dataset can be downloaded from <a href=\"https://www.kaggle.com/kotartemiy/topic-labeled-news-dataset\" target=\"_blank\">Kaggle</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "065591e9-5331-45b5-9b59-598ae5df7849",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = pd.read_csv(f\"{DA.paths.datasets}/news/labelled_newscatcher_dataset.csv\", sep=\";\")\n",
    "pdf[\"id\"] = pdf.index\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f270b4bf-7970-4251-956c-396e5ab1154e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Vector Library: FAISS\n",
    "\n",
    "Vector libraries are often sufficient for small, static data. Since it's not a full-fledged database solution, it doesn't have the CRUD (Create, Read, Update, Delete) support. Once the index has been built, if there are more vectors that need to be added/removed/edited, the index has to be rebuilt from scratch. \n",
    "\n",
    "That said, vector libraries are easy, lightweight, and fast to use. Examples of vector libraries are [FAISS](https://faiss.ai/), [ScaNN](https://github.com/google-research/google-research/tree/master/scann), [ANNOY](https://github.com/spotify/annoy), and [HNSM](https://arxiv.org/abs/1603.09320).\n",
    "\n",
    "FAISS has several ways for similarity search: L2 (Euclidean distance), cosine similarity. You can read more about their implementation on their [GitHub](https://github.com/facebookresearch/faiss/wiki/Getting-started#searching) page or [blog post](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/). They also published their own [best practice guide here](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index).\n",
    "\n",
    "If you'd like to read up more on the comparisons between vector libraries and databases, [here is a good blog post](https://weaviate.io/blog/vector-library-vs-vector-database#feature-comparison---library-versus-database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "613bfdd3-4e80-4827-a820-73a81b137895",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The overall workflow of FAISS is captured in the diagram below. \n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*ouf0eyQskPeGWIGm\" width=700>\n",
    "\n",
    "Source: [How to use FAISS to build your first similarity search by Asna Shafiq](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb519cf1-88a3-4542-8612-43ac7a729256",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "pdf_subset = pdf.head(1000)\n",
    "\n",
    "def example_create_fn(doc1: pd.Series) -> InputExample:\n",
    "    \"\"\"\n",
    "    Helper function that outputs a sentence_transformer guid, label, and text\n",
    "    \"\"\"\n",
    "    return InputExample(texts=[doc1])\n",
    "\n",
    "faiss_train_examples = pdf_subset.apply(\n",
    "    lambda x: example_create_fn(x[\"title\"]), axis=1\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "834d82b1-52f2-42ec-9245-57c1e7cbeccc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Step 2: Vectorize text into embedding vectors\n",
    "We will be using `Sentence-Transformers` [library](https://www.sbert.net/) to load a language model to vectorize our text into embeddings. The library hosts some of the most popular transformers on [Hugging Face Model Hub](https://huggingface.co/sentence-transformers).\n",
    "Here, we are using the `model = SentenceTransformer(\"all-MiniLM-L6-v2\")` to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a259129b-2fa2-4bda-bf15-464ad08ac7e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\", \n",
    "    # cache_folder=DA.paths.datasets\n",
    ")  # Use a pre-cached model\n",
    "faiss_title_embedding = model.encode(pdf_subset.title.values.tolist())\n",
    "len(faiss_title_embedding), len(faiss_title_embedding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff7fe15c-2a03-4482-bf2d-d984f21ab6a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Step 3: Saving embedding vectors to FAISS index\n",
    "Below, we create the FAISS index object based on our embedding vectors, normalize vectors, and add these vectors to the FAISS index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c806e18-ac21-403e-ab09-e202bb30f092",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "pdf_to_index = pdf_subset.set_index([\"id\"], drop=False)\n",
    "id_index = np.array(pdf_to_index.id.values).flatten().astype(\"int\")\n",
    "\n",
    "content_encoded_normalized = faiss_title_embedding.copy()\n",
    "faiss.normalize_L2(content_encoded_normalized)\n",
    "\n",
    "# Index1DMap translates search results to IDs: https://faiss.ai/cpp_api/file/IndexIDMap_8h.html#_CPPv4I0EN5faiss18IndexIDMapTemplateE\n",
    "# The IndexFlatIP below builds index\n",
    "index_content = faiss.IndexIDMap(faiss.IndexFlatIP(len(faiss_title_embedding[0])))\n",
    "index_content.add_with_ids(content_encoded_normalized, id_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5495febf-3524-427c-ae8a-1100227a3663",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 4: Search for relevant documents\n",
    "\n",
    "We define a search function below to first vectorize our query text, and then search for the vectors with the closest distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e49f88d4-6e27-4f9a-9388-82c8973f0e43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def search_content(query, pdf_to_index, k=3):\n",
    "    query_vector = model.encode([query])\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    # We set k to limit the number of vectors we want to return\n",
    "    top_k = index_content.search(query_vector, k)\n",
    "    ids = top_k[1][0].tolist()\n",
    "    similarities = top_k[0][0].tolist()\n",
    "    results = pdf_to_index.loc[ids]\n",
    "    results[\"similarities\"] = similarities\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fe4bca0-df16-4193-a90f-5589e71d0b1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Tada! Now you can query for similar content! Notice that you did not have to configure any database networks beforehand nor pass in any credentials. FAISS works locally with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d20a3778-9fd8-4a81-b3a6-bfcac8d6b238",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(search_content(\"animal\", pdf_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e65e27c1-b460-4a49-a3e9-35ba3a8c3c71",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Up until now, we haven't done the last step of conducting Q/A with a language model yet. We are going to demonstrate this with Chroma, a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c6be80a-4274-4e21-9ca2-6d83bf86c689",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Vector Database: Chroma\n",
    "\n",
    "Chroma is an open-source embedding database. The company just raised its [seed funding in April 2023](https://www.trychroma.com/blog/seed) and is quickly becoming popular to support LLM-based applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e63b058c-2b7c-4e47-9cf5-cdffa9124660",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "chroma_client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=DA.paths.user_db,  # this is an optional argument. If you don't supply this, the data will be ephemeral\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd59e0c5-5332-49f2-aeb7-4718ec228358",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Chroma Concept: Collection\n",
    "\n",
    "Chroma `collection` is akin to an index that stores one set of your documents. \n",
    "\n",
    "According to the [docs](https://docs.trychroma.com/getting-started): \n",
    "> Collections are where you will store your embeddings, documents, and additional metadata\n",
    "\n",
    "The nice thing about ChromaDB is that if you don't supply a model to vectorize text into embeddings, it will automatically load a default embedding function, i.e. `SentenceTransformerEmbeddingFunction`. It can handle tokenization, embedding, and indexing automatically for you. If you would like to change the embedding model, read [here on how to do that](https://docs.trychroma.com/embeddings). TLDR: you can add an optional `model_name` argument. \n",
    "\n",
    "You can read [the documentation here](https://docs.trychroma.com/usage-guide#using-collections) on rules for collection names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dda5f31-0c99-4923-afc0-a6906c2c8ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection_name = \"my_news\"\n",
    "\n",
    "# If you have created the collection before, you need to delete the collection first\n",
    "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "\n",
    "print(f\"Creating collection: '{collection_name}'\")\n",
    "collection = chroma_client.create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57fed64b-de8c-4f89-966c-0fe4f810deb6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1: Add data to collection\n",
    "\n",
    "Since we are re-using the same data, we can skip the step of reading data. As mentioned in the text above, Chroma can take care of text vectorization for us, so we can directly add text to the collection and Chroma will convert the text into embeddings behind the scene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "908feb6b-833c-4aee-af85-2b507c886c83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(pdf_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1199fb6a-5b28-445d-a7e8-ebaf8e2dba50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Each document must have a unique `id` associated with it and it is up to you to check that there are no duplicate ids. \n",
    "\n",
    "Adding data to collection will take some time to run, especially when there is a lot of data. In the cell below, we intentionally write only a subset of data to the collection to speed things up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cacee77a-0362-41a6-9e4c-be85f36574b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=pdf_subset[\"title\"][:100].tolist(),\n",
    "    metadatas=[{\"topic\": topic} for topic in pdf_subset[\"topic\"][:100].tolist()],\n",
    "    ids=[f\"id{x}\" for x in range(100)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66181375-5de6-443c-9021-16baa7aab74c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2: Query for 10 relevant documents on \"space\"\n",
    "\n",
    "We will return 10 most relevant documents. You can think of `10` as 10 nearest neighbors. You can also change the number of results returned as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3f6e2b2-d091-4f3d-81aa-a826bb0c86ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = collection.query(query_texts=[\"space\"], n_results=10)\n",
    "\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6696ccb-a850-4e60-925f-0bbf7eea1641",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Bonus: Add filter statement\n",
    "\n",
    "In addition to conducting relevancy search, we can also add filter statements. Refer to the [documentation](https://docs.trychroma.com/usage-guide#using-where-filters) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "873084e8-0574-4a37-99e5-e67f3322a8d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.query(query_texts=[\"space\"], where={\"topic\": \"SCIENCE\"}, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed2843d-e860-46f6-a2aa-550572c1eb63",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Bonus: Update data in a collection\n",
    "\n",
    "Unlike a vector library, vector databases support changes to the data so we can update or delete data. \n",
    "\n",
    "Indeed, we can update or delete data in a Chroma collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b277b08-49e1-4e53-92d3-67da944638de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.delete(ids=[\"id0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27d497b1-3335-487e-bcd8-31761a911165",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The record with `ids=0` is no longer present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5077017-527b-4a6a-b368-5a161959a05f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.get(\n",
    "    ids=[\"id0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5368850-8a5f-45f1-8081-0c6de6ecc310",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can also update a specific data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "227fb274-e9d4-477a-98ef-d257430849c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.get(\n",
    "    ids=[\"id2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39004b5b-de2a-4878-a476-372f7f333f05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection.update(\n",
    "    ids=[\"id2\"],\n",
    "    metadatas=[{\"topic\": \"TECHNOLOGY\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52073da8-9846-4edb-80aa-73dc25ec353c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Prompt engineering for question answering \n",
    "\n",
    "Now that we have identified documents about space from the news dataset, we can pass these documents as additional context for a language model to generate a response based on them! \n",
    "\n",
    "We first need to pick a `text-generation` model. Below, we use a Hugging Face model. You can also use OpenAI as well, but you will need to get an Open AI token and [pay based on the number of tokens](https://openai.com/pricing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79d886e1-a550-4455-baad-adc3b056e2da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=DA.paths.datasets)\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir=DA.paths.datasets)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=lm_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d626fa81-fa31-429b-bb20-194182fbddcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here's where prompt engineering, which is developing prompts, comes in. We pass in the context in our `prompt_template` but there are numerous ways to write a prompt. Some prompts may generate better results than the others and it requires some experimentation to figure out how best to talk to the model. Each language model behaves differently to prompts. \n",
    "\n",
    "Our prompt template below is inspired from a [2023 paper on program-aided language model](https://arxiv.org/pdf/2211.10435.pdf). The authors have provided their sample prompt template [here](https://github.com/reasoning-machines/pal/blob/main/pal/prompt/date_understanding_prompt.py).\n",
    "\n",
    "The following links also provide some helpful guidance on prompt engineering: \n",
    "- [Prompt engineering with OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
    "- [GitHub repo that compiles best practices to interact with ChatGPT](https://github.com/f/awesome-chatgpt-prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd986185-7e4f-419a-8383-0939d2391486",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "question = \"What's the latest news on space development?\"\n",
    "context = \" \".join([f\"#{str(i)}\" for i in results[\"documents\"][0]])\n",
    "prompt_template = f\"Relevant context: {context}\\n\\n The user's question: {question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b7a669f-f637-4d42-9a58-b9d913ffc2aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lm_response = pipe(prompt_template)\n",
    "print(lm_response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "798f02c5-334e-422e-8d07-bc5aac338c62",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Yay, you have just completed the implementation of your first text vectorization, search, and question answering workflow (that requires prompt engineering)!\n",
    "\n",
    "In the lab, you will apply your newly gained knowledge to a different dataset. You can also check out the optional modules on Pinecone and Weaviate to learn how to set up vector databases that offer enterprise offerings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a7dc8cf-5826-4c21-90cd-cf37c3394fe6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LLM 02 - Embeddings, Vector Databases, and Search",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
